{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CVx2nAWMfWwp"
      },
      "source": [
        "## Importing libraries\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "TSXXQ3aVnaZi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6781c4f2-4b1d-4897-ab6d-300385aa4310"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# mount the google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BI1T0m6bvKVi",
        "outputId": "90377401-8eaf-4875-fb04-08b7b179e5a6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: lightgbm in /usr/local/lib/python3.7/dist-packages (2.2.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from lightgbm) (1.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from lightgbm) (1.4.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from lightgbm) (1.21.6)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->lightgbm) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->lightgbm) (3.1.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install lightgbm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "8LgszbVDdSPX"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime, date, timedelta\n",
        "from tqdm import tqdm\n",
        "import calendar as ca\n",
        "from os import listdir\n",
        "from os.path import join\n",
        "\n",
        "import time\n",
        "import gc\n",
        "import pickle\n",
        "\n",
        "import lightgbm as lgb\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Activation\n",
        "from tensorflow.keras.layers import PReLU\n",
        "# from keras.layers.normalization import BatchNormalization\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.layers import LSTM\n",
        "from tensorflow.keras import callbacks\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import matplotlib.style\n",
        "import matplotlib as mpl\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "mpl.style.use('classic')\n",
        "%matplotlib inline\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bhvd0iAkHsrM"
      },
      "source": [
        "## Loading the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C_CgblJCGsT7",
        "outputId": "3d3a9857-b343-413f-e8d1-2a4575fc1158"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pandas/util/_decorators.py:311: ParserWarning: Both a converter and dtype were specified for column unit_sales - only the converter will be used\n",
            "  return func(*args, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "# load train data starting from 01.01.2016 from gdrive\n",
        "types = {'id': 'int64',\n",
        "                'item_nbr': 'int32',\n",
        "                'store_nbr': 'int8',\n",
        "                'unit_sales': 'float32'\n",
        "            }\n",
        "data_folder = \"drive/My Drive/favorita/data/\"\n",
        "\n",
        "train_large = pd.read_csv(f\"{data_folder}/train.csv\", parse_dates = ['date'], dtype = types, \n",
        "                           converters={'unit_sales': lambda u: np.log1p(float(u)) if float(u) > 0 else 0}\n",
        "                          , infer_datetime_format = True, low_memory = True, skiprows=range(1, 66458909))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 125,
      "metadata": {
        "id": "YTpABW1rPB8C"
      },
      "outputs": [],
      "source": [
        "# load other data\n",
        "items = pd.read_csv(f\"{data_folder}/items.csv\")\n",
        "holiday_events = pd.read_csv(f\"{data_folder}/holidays_events.csv\", parse_dates=['date'])\n",
        "stores = pd.read_csv(f\"{data_folder}/stores.csv\")\n",
        "oil = pd.read_csv(f\"{data_folder}/oil.csv\", parse_dates=['date'])\n",
        "transactions = pd.read_csv(f\"{data_folder}/transactions.csv\", parse_dates=['date'])\n",
        "weather = pd.read_csv(f\"{data_folder}/weather.csv\", parse_dates=['Date'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 126,
      "metadata": {
        "id": "78UlSdi8JiF1"
      },
      "outputs": [],
      "source": [
        "weather.rename(columns={'Date':'date', 'location':'city'}, inplace=True)\n",
        "# dropping ALL duplicte values \n",
        "weather.drop_duplicates(keep = 'first', inplace = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 127,
      "metadata": {
        "id": "OMFpY3qngA2x"
      },
      "outputs": [],
      "source": [
        "stores['city'] = stores.city.str.lower()\n",
        "weather_store = pd.merge(stores[['store_nbr', 'city']], weather[['date', 'AvgTemp', 'city']], on='city',how=\"left\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 128,
      "metadata": {
        "id": "I5E9--gFO8hV"
      },
      "outputs": [],
      "source": [
        "# encode the categorical values\n",
        "le = LabelEncoder()\n",
        "items['family_en'] = le.fit_transform(items['family'].values)\n",
        "\n",
        "stores['city_en'] = le.fit_transform(stores['city'].values)\n",
        "stores['state_en'] = le.fit_transform(stores['state'].values)\n",
        "stores['type_en'] = le.fit_transform(stores['type'].values)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C_BojhGE00PK"
      },
      "source": [
        "## Data transformation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "VZr-WBEdI3PU"
      },
      "outputs": [],
      "source": [
        "# filter out only the 20 stores for the anlysis for colab( if running for 54 stores may need to run in separate server)\n",
        "SELECTED_STORES = [i for i in range(1, 20)]\n",
        "train_selected = train_large.loc[(train_large.store_nbr.isin(SELECTED_STORES)) & (train_large.date >= datetime(2017, 1, 1))]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "XxMhEwX8c6Ma"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "POLPRGdkWFkR"
      },
      "outputs": [],
      "source": [
        "# merge and transform the AvgTemp to format of temporal sequence\n",
        "train_selected_ext = pd.merge(train_selected, weather_store[['date', 'store_nbr',  'AvgTemp']],on=[\"store_nbr\",'date'],how=\"left\")  # Merge weather\n",
        "train_selected_ext.rename(columns={'AvgTemp': 'avg_temp'}, inplace=True)\n",
        "train_selected_temp = train_selected_ext.set_index([\"store_nbr\", \"item_nbr\", \"date\"])[[\"avg_temp\"]].unstack(level=-1).fillna(0)\n",
        "train_selected_temp.columns = train_selected_temp.columns.get_level_values(1)\n",
        "del train_selected_ext"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "I3Q4FqF1R9ov"
      },
      "outputs": [],
      "source": [
        "# merge and transform the promotion to format of temporal sequence\n",
        "train_selected_promotion = train_selected.set_index([\"store_nbr\", \"item_nbr\", \"date\"])[[\"onpromotion\"]].unstack(level=-1).fillna(False)\n",
        "train_selected_promotion.columns = train_selected_promotion.columns.get_level_values(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "IyR6y-ZXJMfT"
      },
      "outputs": [],
      "source": [
        "# merge and transform the unit_sales to format of temporal sequence\n",
        "# this is used to create mean encoding/target encoding/historic unit sales\n",
        "train_selected_sales = train_selected.set_index([\"store_nbr\", \"item_nbr\", \"date\"])[[\"unit_sales\"]].unstack(level=-1).fillna(0)\n",
        "train_selected_sales.columns = train_selected_sales.columns.get_level_values(1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "glXoa2siCMXF"
      },
      "outputs": [],
      "source": [
        "# Item dataframe reindex with transformed indexes from unit_sales\n",
        "items_reindexed = items.set_index('item_nbr')\n",
        "items_reindexed = items_reindexed.reindex(train_selected_sales.index.get_level_values(1))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "items_reindexed"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "id": "einS0BQtzqRX",
        "outputId": "0fe2b73d-bd4d-4675-dc9c-44cdb38cc51f"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                family  class  perishable  family_en\n",
              "item_nbr                                            \n",
              "96995        GROCERY I   1093           0         12\n",
              "99197        GROCERY I   1067           0         12\n",
              "103520       GROCERY I   1028           0         12\n",
              "103665    BREAD/BAKERY   2712           1          5\n",
              "105574       GROCERY I   1045           0         12\n",
              "...                ...    ...         ...        ...\n",
              "2110456      BEVERAGES   1120           0          3\n",
              "2111684      BEVERAGES   1120           0          3\n",
              "2113343      BEVERAGES   1114           0          3\n",
              "2113914       CLEANING   3040           0          7\n",
              "2116416      GROCERY I   1060           0         12\n",
              "\n",
              "[57000 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-12a2bce9-f484-40ed-abcf-79dd261edb82\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>family</th>\n",
              "      <th>class</th>\n",
              "      <th>perishable</th>\n",
              "      <th>family_en</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>item_nbr</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>96995</th>\n",
              "      <td>GROCERY I</td>\n",
              "      <td>1093</td>\n",
              "      <td>0</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99197</th>\n",
              "      <td>GROCERY I</td>\n",
              "      <td>1067</td>\n",
              "      <td>0</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>103520</th>\n",
              "      <td>GROCERY I</td>\n",
              "      <td>1028</td>\n",
              "      <td>0</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>103665</th>\n",
              "      <td>BREAD/BAKERY</td>\n",
              "      <td>2712</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>105574</th>\n",
              "      <td>GROCERY I</td>\n",
              "      <td>1045</td>\n",
              "      <td>0</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2110456</th>\n",
              "      <td>BEVERAGES</td>\n",
              "      <td>1120</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2111684</th>\n",
              "      <td>BEVERAGES</td>\n",
              "      <td>1120</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2113343</th>\n",
              "      <td>BEVERAGES</td>\n",
              "      <td>1114</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2113914</th>\n",
              "      <td>CLEANING</td>\n",
              "      <td>3040</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2116416</th>\n",
              "      <td>GROCERY I</td>\n",
              "      <td>1060</td>\n",
              "      <td>0</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>57000 rows × 4 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-12a2bce9-f484-40ed-abcf-79dd261edb82')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-12a2bce9-f484-40ed-abcf-79dd261edb82 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-12a2bce9-f484-40ed-abcf-79dd261edb82');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "PUtM_ifcr7nM"
      },
      "outputs": [],
      "source": [
        "# stores dataframe reindex with transformed indexes from unit_sales\n",
        "stores_reindexed = stores.set_index('store_nbr')\n",
        "stores_reindexed = stores_reindexed.reindex(train_selected_sales.index.get_level_values(0))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Utility Methods"
      ],
      "metadata": {
        "id": "vigPhjErBWkP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "uUGrAK7s3wPW"
      },
      "outputs": [],
      "source": [
        "# get timespan for feature creation\n",
        "def get_timespan(df, dt, minus, periods, freq='D'):\n",
        "    return df[pd.date_range(dt - timedelta(days=minus), periods=periods, freq=freq)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "4PZipKOc3wNt"
      },
      "outputs": [],
      "source": [
        "# prepare features with seasonal patterns/ mean encoding\n",
        "def prepare_dataset_1(t2017, is_train=True):\n",
        "    X = pd.DataFrame({\n",
        "        \"perishable\": items_reindexed[\"perishable\"].values,\n",
        "        \"perishable\": items_reindexed[\"perishable\"].values,\n",
        "        \"family\": items_reindexed[\"family_en\"].values,\n",
        "        \"item_class\": items_reindexed[\"class\"].values,\n",
        "        \"type\": stores_reindexed[\"type_en\"].values,\n",
        "        \"cluster\": stores_reindexed[\"cluster\"].values,\n",
        "        \"state\": stores_reindexed[\"state_en\"].values,\n",
        "        \"day_1_2017\": get_timespan(train_selected_sales, t2017, 1, 1).values.ravel(),\n",
        "        \"mean_3_2017\": get_timespan(train_selected_sales, t2017, 3, 3).mean(axis=1).values,\n",
        "        \"mean_7_2017\": get_timespan(train_selected_sales, t2017, 7, 7).mean(axis=1).values,\n",
        "        \"mean_14_2017\": get_timespan(train_selected_sales, t2017, 14, 14).mean(axis=1).values,\n",
        "        \"mean_30_2017\": get_timespan(train_selected_sales, t2017, 30, 30).mean(axis=1).values,\n",
        "        \"mean_60_2017\": get_timespan(train_selected_sales, t2017, 60, 60).mean(axis=1).values,\n",
        "        \"mean_140_2017\": get_timespan(train_selected_sales, t2017, 140, 140).mean(axis=1).values,\n",
        "        \"promo_14_2017\": get_timespan(train_selected_promotion, t2017, 14, 14).sum(axis=1).values,\n",
        "        \"promo_60_2017\": get_timespan(train_selected_promotion, t2017, 60, 60).sum(axis=1).values,\n",
        "        \"promo_140_2017\": get_timespan(train_selected_promotion, t2017, 140, 140).sum(axis=1).values,\n",
        "        \"day_1_temp\": get_timespan(train_selected_temp, t2017, 1, 1).values.ravel(),\n",
        "        \"mean_3_temp\": get_timespan(train_selected_temp, t2017, 3, 3).mean(axis=1).values,\n",
        "        \"mean_7_temp\": get_timespan(train_selected_temp, t2017, 7, 7).mean(axis=1).values\n",
        "    })\n",
        "    for i in range(7):\n",
        "        X['mean_4_dow{}_2017'.format(i)] = get_timespan(train_selected_sales, t2017, 28-i, 4, freq='7D').mean(axis=1).values\n",
        "        X['mean_20_dow{}_2017'.format(i)] = get_timespan(train_selected_sales, t2017, 140-i, 20, freq='7D').mean(axis=1).values\n",
        "    # for i in range(16):\n",
        "    #     X[\"promo_{}\".format(i)] = train_selected_promotion[t2017 + timedelta(days=i)].values.astype(np.uint8)\n",
        "    #     # X[\"holiday_{}\".format(i)] = holiday_2017[t2017 + timedelta(days=i)].values.astype(np.uint8)\n",
        "    if is_train:\n",
        "        y = train_selected_sales[\n",
        "            pd.date_range(t2017, periods=16)\n",
        "        ].values\n",
        "        return X, y\n",
        "    return X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "-2zLZpg7eLjQ"
      },
      "outputs": [],
      "source": [
        "# basic features from existing data\n",
        "def prepare_dataset_basic(t2017, is_train=True):\n",
        "    X = pd.DataFrame({\n",
        "        \"temp\": train_selected_temp[t2017.strftime('%Y-%m-%d')].values,\n",
        "        \"promotion\": train_selected_promotion[t2017.strftime('%Y-%m-%d')],\n",
        "        \"perishable\": items_reindexed[\"perishable\"].values,\n",
        "        \"family\": items_reindexed[\"family_en\"].values,\n",
        "        \"item_class\": items_reindexed[\"class\"].values,\n",
        "        \"type\": stores_reindexed[\"type_en\"].values,\n",
        "        \"cluster\": stores_reindexed[\"cluster\"].values,\n",
        "        \"state\": stores_reindexed[\"state_en\"].values,\n",
        "\n",
        "\n",
        "    })\n",
        "    if is_train:\n",
        "        y = train_selected_sales[\n",
        "            pd.date_range(t2017, periods=16)\n",
        "        ].values\n",
        "        return X, y\n",
        "    return X"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "\n",
        "def get_error(weights, true_val, pred_val, predict_days_ahead=16):\n",
        "\n",
        "    mse = mean_squared_error(true_val, pred_val, sample_weight=weights)\n",
        "    rmse = np.sqrt(mse)\n",
        "\n",
        "    mae = mean_absolute_error(true_val, pred_val, sample_weight=weights)\n",
        "\n",
        "    #mape = np.mean(np.abs((true_val - pred_val) / true_val)) * 100\n",
        "\n",
        "    try:\n",
        "        err = (true_val - pred_val) ** 2\n",
        "        err = err.sum(axis=1) * weights\n",
        "        nwrmsle = np.sqrt(err.sum() / weights.sum() / predict_days_ahead)\n",
        "    except:\n",
        "        nwrmsle = rmse\n",
        "\n",
        "    return mse, rmse, nwrmsle, mae"
      ],
      "metadata": {
        "id": "cIifMqLn_2Mv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plotImp(model, X , num = 20):\n",
        "    feature_imp = pd.DataFrame({'Value':model.feature_importance(),'Feature':X.columns})\n",
        "    sns.barplot(x=\"Value\", y=\"Feature\", data=feature_imp.sort_values(by=\"Value\", \n",
        "                                                        ascending=False)[0:num])\n",
        "    plt.title('LightGBM Features')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('lgbm_importances-01.png')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "Y2YYltix_9-5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Baseline Model"
      ],
      "metadata": {
        "id": "GkMIWVvSPw2z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "t2017 = date(2017, 5, 8)\n",
        "test2017 = date(2017, 7, 31)"
      ],
      "metadata": {
        "id": "_Db_un00QWdt"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MA_train_set = train_selected[train_selected[\"date\"]<=t2017.strftime('%Y-%m-%d')].reset_index()\n",
        "MA_test_set = train_selected[train_selected[\"date\"]>=test2017.strftime('%Y-%m-%d')].reset_index().set_index(['item_nbr', 'store_nbr'])"
      ],
      "metadata": {
        "id": "cO4Eu6KdQRoG"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Item dataframe reindex with transformed indexes from unit_sales\n",
        "items_reindexed_base = items.set_index('item_nbr')\n",
        "items_reindexed_base = items_reindexed_base.reindex(MA_test_set.index.get_level_values(0))"
      ],
      "metadata": {
        "id": "TIZX8JMdy4U3"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MA_train_set.loc[:, \"unit_sales\"].fillna(0, inplace=True)"
      ],
      "metadata": {
        "id": "RxqoSwhKd0Dm"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Moving Averages\n",
        "for i in [28]:\n",
        "    val='MA'+str(i)\n",
        "    tmp = MA_train_set[MA_train_set.date>(t2017-timedelta(int(i))).strftime('%Y-%m-%d')]\n",
        "    tmp1 = tmp.groupby(['item_nbr', 'store_nbr'])['unit_sales'].mean().to_frame(val)\n",
        "    MA_test_set = MA_test_set.join(tmp1, how='left')\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "bCIBlBTjP1cl"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Median of MAs\n",
        "MA_test_set['unit_sales_pred']=MA_test_set.iloc[:,5:].median(axis=1)\n",
        "MA_test_set.loc[:, \"unit_sales_pred\"].fillna(0, inplace=True)"
      ],
      "metadata": {
        "id": "2Rkq5TJleJtJ"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MA_test_set['unit_sales_actual'] = MA_test_set['unit_sales'].apply(pd.np.expm1) # restoring unit values\n",
        "MA_test_set['unit_sales_pred_actual'] = MA_test_set['unit_sales_pred'].apply(pd.np.expm1) # restoring unit values"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QwxoMdK7UFyD",
        "outputId": "076916bf-f31c-422f-eccc-bd0af6a71240"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead\n",
            "  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MA_test_set"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "id": "qmpYNTmVsJy1",
        "outputId": "2673fe04-27e3-401a-94d5-42641e666486"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                       index         id       date  unit_sales  onpromotion  \\\n",
              "item_nbr store_nbr                                                            \n",
              "96995    1          57360788  123819696 2017-07-31    1.098612        False   \n",
              "         1          57576551  124035459 2017-08-02    0.693147        False   \n",
              "         1          57683958  124142866 2017-08-03    1.098612        False   \n",
              "         1          58001260  124460168 2017-08-06    1.098612        False   \n",
              "         1          58112102  124571010 2017-08-07    1.098612        False   \n",
              "...                      ...        ...        ...         ...          ...   \n",
              "2127114  8          58533907  124992815 2017-08-11    1.098612        False   \n",
              "         8          58638899  125097807 2017-08-12    1.609438        False   \n",
              "         8          58744016  125202924 2017-08-13    2.079442        False   \n",
              "         8          58850430  125309338 2017-08-14    0.693147        False   \n",
              "         8          58952882  125411790 2017-08-15    0.693147        False   \n",
              "\n",
              "                        MA28  unit_sales_pred  unit_sales_actual  \\\n",
              "item_nbr store_nbr                                                 \n",
              "96995    1          0.876249         0.876249                2.0   \n",
              "         1          0.876249         0.876249                1.0   \n",
              "         1          0.876249         0.876249                2.0   \n",
              "         1          0.876249         0.876249                2.0   \n",
              "         1          0.876249         0.876249                2.0   \n",
              "...                      ...              ...                ...   \n",
              "2127114  8               NaN         0.000000                2.0   \n",
              "         8               NaN         0.000000                4.0   \n",
              "         8               NaN         0.000000                7.0   \n",
              "         8               NaN         0.000000                1.0   \n",
              "         8               NaN         0.000000                1.0   \n",
              "\n",
              "                    unit_sales_pred_actual  \n",
              "item_nbr store_nbr                          \n",
              "96995    1                        1.401874  \n",
              "         1                        1.401874  \n",
              "         1                        1.401874  \n",
              "         1                        1.401874  \n",
              "         1                        1.401874  \n",
              "...                                    ...  \n",
              "2127114  8                        0.000000  \n",
              "         8                        0.000000  \n",
              "         8                        0.000000  \n",
              "         8                        0.000000  \n",
              "         8                        0.000000  \n",
              "\n",
              "[570959 rows x 9 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e3876039-36b2-4b91-b6fd-465b3eaf8350\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>id</th>\n",
              "      <th>date</th>\n",
              "      <th>unit_sales</th>\n",
              "      <th>onpromotion</th>\n",
              "      <th>MA28</th>\n",
              "      <th>unit_sales_pred</th>\n",
              "      <th>unit_sales_actual</th>\n",
              "      <th>unit_sales_pred_actual</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>item_nbr</th>\n",
              "      <th>store_nbr</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th rowspan=\"5\" valign=\"top\">96995</th>\n",
              "      <th>1</th>\n",
              "      <td>57360788</td>\n",
              "      <td>123819696</td>\n",
              "      <td>2017-07-31</td>\n",
              "      <td>1.098612</td>\n",
              "      <td>False</td>\n",
              "      <td>0.876249</td>\n",
              "      <td>0.876249</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.401874</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>57576551</td>\n",
              "      <td>124035459</td>\n",
              "      <td>2017-08-02</td>\n",
              "      <td>0.693147</td>\n",
              "      <td>False</td>\n",
              "      <td>0.876249</td>\n",
              "      <td>0.876249</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.401874</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>57683958</td>\n",
              "      <td>124142866</td>\n",
              "      <td>2017-08-03</td>\n",
              "      <td>1.098612</td>\n",
              "      <td>False</td>\n",
              "      <td>0.876249</td>\n",
              "      <td>0.876249</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.401874</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>58001260</td>\n",
              "      <td>124460168</td>\n",
              "      <td>2017-08-06</td>\n",
              "      <td>1.098612</td>\n",
              "      <td>False</td>\n",
              "      <td>0.876249</td>\n",
              "      <td>0.876249</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.401874</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>58112102</td>\n",
              "      <td>124571010</td>\n",
              "      <td>2017-08-07</td>\n",
              "      <td>1.098612</td>\n",
              "      <td>False</td>\n",
              "      <td>0.876249</td>\n",
              "      <td>0.876249</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.401874</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"5\" valign=\"top\">2127114</th>\n",
              "      <th>8</th>\n",
              "      <td>58533907</td>\n",
              "      <td>124992815</td>\n",
              "      <td>2017-08-11</td>\n",
              "      <td>1.098612</td>\n",
              "      <td>False</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>58638899</td>\n",
              "      <td>125097807</td>\n",
              "      <td>2017-08-12</td>\n",
              "      <td>1.609438</td>\n",
              "      <td>False</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>58744016</td>\n",
              "      <td>125202924</td>\n",
              "      <td>2017-08-13</td>\n",
              "      <td>2.079442</td>\n",
              "      <td>False</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>7.0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>58850430</td>\n",
              "      <td>125309338</td>\n",
              "      <td>2017-08-14</td>\n",
              "      <td>0.693147</td>\n",
              "      <td>False</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>58952882</td>\n",
              "      <td>125411790</td>\n",
              "      <td>2017-08-15</td>\n",
              "      <td>0.693147</td>\n",
              "      <td>False</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>570959 rows × 9 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e3876039-36b2-4b91-b6fd-465b3eaf8350')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e3876039-36b2-4b91-b6fd-465b3eaf8350 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e3876039-36b2-4b91-b6fd-465b3eaf8350');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "FU8gd_yZWd08"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# errors for model\n",
        "weights = items_reindexed_base[\"perishable\"].values * 0.25 + 1\n",
        "print('Unit', get_error(weights, MA_test_set['unit_sales_actual'].values, MA_test_set[\"unit_sales_pred_actual\"].values))\n",
        "print('Log', get_error(weights, MA_test_set['unit_sales'].values, MA_test_set[\"unit_sales_pred\"].values))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vHVvKcXkWe1r",
        "outputId": "7c71ff40-c222-4159-8f6d-aa29522bf895"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unit (139.02818907874033, 11.791021545173273, 11.791021545173273, 3.5338068575593717, nan)\n",
            "Log (0.3868461208515245, 0.621969549778383, 0.621969549778383, 0.4595248600458542, nan)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:10: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  # Remove the CWD from sys.path while we load stuff.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:10: RuntimeWarning: invalid value encountered in true_divide\n",
            "  # Remove the CWD from sys.path while we load stuff.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:10: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  # Remove the CWD from sys.path while we load stuff.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:10: RuntimeWarning: invalid value encountered in true_divide\n",
            "  # Remove the CWD from sys.path while we load stuff.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "out_filename = 'drive/My Drive/favorita/model_outputs/' + 'MA_log_scaled_out_base.pkl'\n",
        "MA_test_set.to_pickle(out_filename)"
      ],
      "metadata": {
        "id": "CvX44BiHyD1y"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Basic Model"
      ],
      "metadata": {
        "id": "3Y8KFHMfm_a9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# date range use for training data\n",
        "t2017 = date(2017, 5, 8)\n",
        "for i in range(6):\n",
        "    delta = timedelta(days=7 * i)\n",
        "    print(t2017 + delta)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RAaIgJS-ZNu2",
        "outputId": "0fa5090c-f944-4099-d97a-798c54100467"
      },
      "execution_count": 192,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2017-05-08\n",
            "2017-05-15\n",
            "2017-05-22\n",
            "2017-05-29\n",
            "2017-06-05\n",
            "2017-06-12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q5q7cntxRjaB",
        "outputId": "fda6721e-fb10-4328-df26-0edb68df72be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Preparing dataset...basic\n"
          ]
        }
      ],
      "source": [
        "print(\"Preparing dataset...basic\")\n",
        "\n",
        "t2017 = date(2017, 5, 8)\n",
        "X_l, y_l = [], []\n",
        "for i in range(6):\n",
        "    delta = timedelta(days=7 * i)\n",
        "    X_tmp, y_tmp = prepare_dataset_basic(t2017 + delta)\n",
        "    X_l.append(X_tmp)\n",
        "    y_l.append(y_tmp)\n",
        "\n",
        "X_train = pd.concat(X_l, axis=0)\n",
        "y_train = np.concatenate(y_l, axis=0)\n",
        "del X_l, y_l\n",
        "X_val, y_val = prepare_dataset_basic(date(2017, 7, 10))\n",
        "X_test, y_test = prepare_dataset_basic(date(2017, 7, 31))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "2c3OcYQoCqOp"
      },
      "outputs": [],
      "source": [
        "params = {\n",
        "    'num_leaves': 60,\n",
        "    'objective': 'regression_l2',\n",
        "    'max_depth': 10,\n",
        "    'min_data_per_leaf': 300,\n",
        "    'learning_rate': 0.05,\n",
        "    'boosting_type': 'gbdt',\n",
        "    'colsample_bytree': 0.4,\n",
        "    'feature_fraction': 0.75,\n",
        "    'bagging_fraction': 0.75,\n",
        "    'bagging_freq': 1,\n",
        "    'metric': 'l2',\n",
        "    'num_threads': 4\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d_BE-BAVCqVC",
        "outputId": "07e10299-fc19-4b67-bb9f-28f8d847c7bb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==================================================\n",
            "Step 1\n",
            "==================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/lightgbm/basic.py:1205: UserWarning: Using categorical_feature in Dataset.\n",
            "  warnings.warn('Using categorical_feature in Dataset.')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training until validation scores don't improve for 50 rounds.\n",
            "[50]\ttraining's l2: 0.374876\tvalid_1's l2: 0.371112\n",
            "[100]\ttraining's l2: 0.342725\tvalid_1's l2: 0.342637\n",
            "[150]\ttraining's l2: 0.337634\tvalid_1's l2: 0.339156\n",
            "[200]\ttraining's l2: 0.334711\tvalid_1's l2: 0.337473\n",
            "[250]\ttraining's l2: 0.332868\tvalid_1's l2: 0.336221\n",
            "[300]\ttraining's l2: 0.3314\tvalid_1's l2: 0.335401\n",
            "[350]\ttraining's l2: 0.330198\tvalid_1's l2: 0.334875\n",
            "[400]\ttraining's l2: 0.329338\tvalid_1's l2: 0.334393\n",
            "[450]\ttraining's l2: 0.3286\tvalid_1's l2: 0.33399\n",
            "[500]\ttraining's l2: 0.327837\tvalid_1's l2: 0.333547\n",
            "[550]\ttraining's l2: 0.327269\tvalid_1's l2: 0.333331\n",
            "[600]\ttraining's l2: 0.326748\tvalid_1's l2: 0.333224\n",
            "[650]\ttraining's l2: 0.326271\tvalid_1's l2: 0.333136\n",
            "[700]\ttraining's l2: 0.32588\tvalid_1's l2: 0.332906\n",
            "[750]\ttraining's l2: 0.325456\tvalid_1's l2: 0.332827\n",
            "[800]\ttraining's l2: 0.325105\tvalid_1's l2: 0.332788\n",
            "[850]\ttraining's l2: 0.324798\tvalid_1's l2: 0.332655\n",
            "[900]\ttraining's l2: 0.324507\tvalid_1's l2: 0.332593\n",
            "[950]\ttraining's l2: 0.324256\tvalid_1's l2: 0.332461\n",
            "[1000]\ttraining's l2: 0.323982\tvalid_1's l2: 0.332397\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1000]\ttraining's l2: 0.323982\tvalid_1's l2: 0.332397\n",
            "==================================================\n",
            "Step 2\n",
            "==================================================\n",
            "Training until validation scores don't improve for 50 rounds.\n",
            "[50]\ttraining's l2: 0.643454\tvalid_1's l2: 0.637132\n",
            "[100]\ttraining's l2: 0.617782\tvalid_1's l2: 0.615542\n",
            "[150]\ttraining's l2: 0.6116\tvalid_1's l2: 0.611371\n",
            "[200]\ttraining's l2: 0.607139\tvalid_1's l2: 0.608478\n",
            "[250]\ttraining's l2: 0.604346\tvalid_1's l2: 0.607036\n",
            "[300]\ttraining's l2: 0.602154\tvalid_1's l2: 0.605854\n",
            "[350]\ttraining's l2: 0.600383\tvalid_1's l2: 0.604891\n",
            "[400]\ttraining's l2: 0.598949\tvalid_1's l2: 0.60426\n",
            "[450]\ttraining's l2: 0.597797\tvalid_1's l2: 0.603784\n",
            "[500]\ttraining's l2: 0.596746\tvalid_1's l2: 0.603293\n",
            "[550]\ttraining's l2: 0.595849\tvalid_1's l2: 0.602925\n",
            "[600]\ttraining's l2: 0.59492\tvalid_1's l2: 0.602661\n",
            "[650]\ttraining's l2: 0.594149\tvalid_1's l2: 0.602478\n",
            "[700]\ttraining's l2: 0.593507\tvalid_1's l2: 0.60227\n",
            "[750]\ttraining's l2: 0.592827\tvalid_1's l2: 0.602053\n",
            "[800]\ttraining's l2: 0.592224\tvalid_1's l2: 0.602005\n",
            "Early stopping, best iteration is:\n",
            "[797]\ttraining's l2: 0.592265\tvalid_1's l2: 0.601949\n",
            "==================================================\n",
            "Step 3\n",
            "==================================================\n",
            "Training until validation scores don't improve for 50 rounds.\n",
            "[50]\ttraining's l2: 0.666664\tvalid_1's l2: 0.640371\n",
            "[100]\ttraining's l2: 0.639566\tvalid_1's l2: 0.617619\n",
            "[150]\ttraining's l2: 0.632536\tvalid_1's l2: 0.612648\n",
            "[200]\ttraining's l2: 0.627747\tvalid_1's l2: 0.609555\n",
            "[250]\ttraining's l2: 0.62481\tvalid_1's l2: 0.60775\n",
            "[300]\ttraining's l2: 0.622424\tvalid_1's l2: 0.606366\n",
            "[350]\ttraining's l2: 0.620612\tvalid_1's l2: 0.605452\n",
            "[400]\ttraining's l2: 0.61917\tvalid_1's l2: 0.604789\n",
            "[450]\ttraining's l2: 0.618043\tvalid_1's l2: 0.604155\n",
            "[500]\ttraining's l2: 0.616841\tvalid_1's l2: 0.603672\n",
            "[550]\ttraining's l2: 0.615991\tvalid_1's l2: 0.603271\n",
            "[600]\ttraining's l2: 0.615098\tvalid_1's l2: 0.602895\n",
            "[650]\ttraining's l2: 0.614398\tvalid_1's l2: 0.602767\n",
            "[700]\ttraining's l2: 0.613771\tvalid_1's l2: 0.602501\n",
            "[750]\ttraining's l2: 0.613089\tvalid_1's l2: 0.60224\n",
            "[800]\ttraining's l2: 0.612522\tvalid_1's l2: 0.601985\n",
            "[850]\ttraining's l2: 0.612031\tvalid_1's l2: 0.601841\n",
            "[900]\ttraining's l2: 0.611571\tvalid_1's l2: 0.601714\n",
            "[950]\ttraining's l2: 0.611142\tvalid_1's l2: 0.601646\n",
            "[1000]\ttraining's l2: 0.610732\tvalid_1's l2: 0.601446\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1000]\ttraining's l2: 0.610732\tvalid_1's l2: 0.601446\n",
            "==================================================\n",
            "Step 4\n",
            "==================================================\n",
            "Training until validation scores don't improve for 50 rounds.\n",
            "[50]\ttraining's l2: 0.653121\tvalid_1's l2: 0.634903\n",
            "[100]\ttraining's l2: 0.630288\tvalid_1's l2: 0.61766\n",
            "[150]\ttraining's l2: 0.623268\tvalid_1's l2: 0.613691\n",
            "[200]\ttraining's l2: 0.618986\tvalid_1's l2: 0.61155\n",
            "[250]\ttraining's l2: 0.61594\tvalid_1's l2: 0.610245\n",
            "[300]\ttraining's l2: 0.613725\tvalid_1's l2: 0.609225\n",
            "[350]\ttraining's l2: 0.611906\tvalid_1's l2: 0.608629\n",
            "[400]\ttraining's l2: 0.610483\tvalid_1's l2: 0.60803\n",
            "[450]\ttraining's l2: 0.609338\tvalid_1's l2: 0.60772\n",
            "[500]\ttraining's l2: 0.60822\tvalid_1's l2: 0.607221\n",
            "[550]\ttraining's l2: 0.607325\tvalid_1's l2: 0.606991\n",
            "[600]\ttraining's l2: 0.606507\tvalid_1's l2: 0.60669\n",
            "[650]\ttraining's l2: 0.605795\tvalid_1's l2: 0.606355\n",
            "[700]\ttraining's l2: 0.605174\tvalid_1's l2: 0.606225\n",
            "[750]\ttraining's l2: 0.604516\tvalid_1's l2: 0.606064\n",
            "[800]\ttraining's l2: 0.603966\tvalid_1's l2: 0.605896\n",
            "[850]\ttraining's l2: 0.603522\tvalid_1's l2: 0.605787\n",
            "[900]\ttraining's l2: 0.603093\tvalid_1's l2: 0.605746\n",
            "[950]\ttraining's l2: 0.602683\tvalid_1's l2: 0.605722\n",
            "Early stopping, best iteration is:\n",
            "[916]\ttraining's l2: 0.60296\tvalid_1's l2: 0.60569\n",
            "==================================================\n",
            "Step 5\n",
            "==================================================\n",
            "Training until validation scores don't improve for 50 rounds.\n",
            "[50]\ttraining's l2: 0.698633\tvalid_1's l2: 0.670636\n",
            "[100]\ttraining's l2: 0.672811\tvalid_1's l2: 0.649318\n",
            "[150]\ttraining's l2: 0.664562\tvalid_1's l2: 0.643854\n",
            "[200]\ttraining's l2: 0.659926\tvalid_1's l2: 0.641668\n",
            "[250]\ttraining's l2: 0.657087\tvalid_1's l2: 0.640798\n",
            "[300]\ttraining's l2: 0.654669\tvalid_1's l2: 0.639642\n",
            "[350]\ttraining's l2: 0.65272\tvalid_1's l2: 0.638672\n",
            "[400]\ttraining's l2: 0.651191\tvalid_1's l2: 0.63821\n",
            "[450]\ttraining's l2: 0.649984\tvalid_1's l2: 0.637763\n",
            "[500]\ttraining's l2: 0.648878\tvalid_1's l2: 0.637283\n",
            "[550]\ttraining's l2: 0.647976\tvalid_1's l2: 0.637167\n",
            "[600]\ttraining's l2: 0.647075\tvalid_1's l2: 0.63678\n",
            "[650]\ttraining's l2: 0.646329\tvalid_1's l2: 0.636559\n",
            "[700]\ttraining's l2: 0.645632\tvalid_1's l2: 0.636269\n",
            "[750]\ttraining's l2: 0.644937\tvalid_1's l2: 0.635955\n",
            "[800]\ttraining's l2: 0.644393\tvalid_1's l2: 0.63575\n",
            "[850]\ttraining's l2: 0.643931\tvalid_1's l2: 0.635643\n",
            "[900]\ttraining's l2: 0.643468\tvalid_1's l2: 0.635529\n",
            "[950]\ttraining's l2: 0.643011\tvalid_1's l2: 0.635479\n",
            "[1000]\ttraining's l2: 0.642561\tvalid_1's l2: 0.635361\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1000]\ttraining's l2: 0.642561\tvalid_1's l2: 0.635361\n",
            "==================================================\n",
            "Step 6\n",
            "==================================================\n",
            "Training until validation scores don't improve for 50 rounds.\n",
            "[50]\ttraining's l2: 0.759115\tvalid_1's l2: 0.729573\n",
            "[100]\ttraining's l2: 0.731024\tvalid_1's l2: 0.709427\n",
            "[150]\ttraining's l2: 0.721833\tvalid_1's l2: 0.704274\n",
            "[200]\ttraining's l2: 0.716604\tvalid_1's l2: 0.70212\n",
            "[250]\ttraining's l2: 0.712978\tvalid_1's l2: 0.700618\n",
            "[300]\ttraining's l2: 0.71008\tvalid_1's l2: 0.699415\n",
            "[350]\ttraining's l2: 0.707809\tvalid_1's l2: 0.698637\n",
            "[400]\ttraining's l2: 0.705991\tvalid_1's l2: 0.698074\n",
            "[450]\ttraining's l2: 0.704592\tvalid_1's l2: 0.697711\n",
            "[500]\ttraining's l2: 0.703286\tvalid_1's l2: 0.697208\n",
            "[550]\ttraining's l2: 0.702246\tvalid_1's l2: 0.696812\n",
            "[600]\ttraining's l2: 0.701133\tvalid_1's l2: 0.696578\n",
            "[650]\ttraining's l2: 0.700289\tvalid_1's l2: 0.696291\n",
            "[700]\ttraining's l2: 0.69943\tvalid_1's l2: 0.69604\n",
            "[750]\ttraining's l2: 0.698645\tvalid_1's l2: 0.695791\n",
            "[800]\ttraining's l2: 0.697896\tvalid_1's l2: 0.695481\n",
            "[850]\ttraining's l2: 0.697313\tvalid_1's l2: 0.6954\n",
            "[900]\ttraining's l2: 0.696762\tvalid_1's l2: 0.695217\n",
            "[950]\ttraining's l2: 0.696288\tvalid_1's l2: 0.695149\n",
            "[1000]\ttraining's l2: 0.695753\tvalid_1's l2: 0.695008\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1000]\ttraining's l2: 0.695753\tvalid_1's l2: 0.695008\n",
            "==================================================\n",
            "Step 7\n",
            "==================================================\n",
            "Training until validation scores don't improve for 50 rounds.\n",
            "[50]\ttraining's l2: 0.781014\tvalid_1's l2: 0.752432\n",
            "[100]\ttraining's l2: 0.752741\tvalid_1's l2: 0.729903\n",
            "[150]\ttraining's l2: 0.744927\tvalid_1's l2: 0.726001\n",
            "[200]\ttraining's l2: 0.740022\tvalid_1's l2: 0.724092\n",
            "[250]\ttraining's l2: 0.736601\tvalid_1's l2: 0.723202\n",
            "[300]\ttraining's l2: 0.733803\tvalid_1's l2: 0.721784\n",
            "[350]\ttraining's l2: 0.731647\tvalid_1's l2: 0.721336\n",
            "[400]\ttraining's l2: 0.729968\tvalid_1's l2: 0.720795\n",
            "[450]\ttraining's l2: 0.728668\tvalid_1's l2: 0.720461\n",
            "[500]\ttraining's l2: 0.727408\tvalid_1's l2: 0.720008\n",
            "[550]\ttraining's l2: 0.726373\tvalid_1's l2: 0.7197\n",
            "[600]\ttraining's l2: 0.725404\tvalid_1's l2: 0.71962\n",
            "[650]\ttraining's l2: 0.724609\tvalid_1's l2: 0.719425\n",
            "[700]\ttraining's l2: 0.723851\tvalid_1's l2: 0.719228\n",
            "[750]\ttraining's l2: 0.723175\tvalid_1's l2: 0.719188\n",
            "[800]\ttraining's l2: 0.722556\tvalid_1's l2: 0.718987\n",
            "[850]\ttraining's l2: 0.722043\tvalid_1's l2: 0.719065\n",
            "Early stopping, best iteration is:\n",
            "[800]\ttraining's l2: 0.722556\tvalid_1's l2: 0.718987\n",
            "==================================================\n",
            "Step 8\n",
            "==================================================\n",
            "Training until validation scores don't improve for 50 rounds.\n",
            "[50]\ttraining's l2: 0.706634\tvalid_1's l2: 0.697059\n",
            "[100]\ttraining's l2: 0.682014\tvalid_1's l2: 0.674868\n",
            "[150]\ttraining's l2: 0.674109\tvalid_1's l2: 0.66971\n",
            "[200]\ttraining's l2: 0.669586\tvalid_1's l2: 0.667405\n",
            "[250]\ttraining's l2: 0.666842\tvalid_1's l2: 0.666179\n",
            "[300]\ttraining's l2: 0.66451\tvalid_1's l2: 0.665127\n",
            "[350]\ttraining's l2: 0.662537\tvalid_1's l2: 0.664442\n",
            "[400]\ttraining's l2: 0.661084\tvalid_1's l2: 0.663816\n",
            "[450]\ttraining's l2: 0.660004\tvalid_1's l2: 0.663541\n",
            "[500]\ttraining's l2: 0.658863\tvalid_1's l2: 0.66307\n",
            "[550]\ttraining's l2: 0.657926\tvalid_1's l2: 0.662928\n",
            "[600]\ttraining's l2: 0.657087\tvalid_1's l2: 0.662761\n",
            "[650]\ttraining's l2: 0.656357\tvalid_1's l2: 0.662457\n",
            "[700]\ttraining's l2: 0.655756\tvalid_1's l2: 0.662342\n",
            "[750]\ttraining's l2: 0.655073\tvalid_1's l2: 0.662111\n",
            "[800]\ttraining's l2: 0.654523\tvalid_1's l2: 0.6618\n",
            "[850]\ttraining's l2: 0.654096\tvalid_1's l2: 0.661812\n",
            "[900]\ttraining's l2: 0.6537\tvalid_1's l2: 0.661732\n",
            "[950]\ttraining's l2: 0.653316\tvalid_1's l2: 0.661688\n",
            "Early stopping, best iteration is:\n",
            "[926]\ttraining's l2: 0.653495\tvalid_1's l2: 0.661633\n",
            "==================================================\n",
            "Step 9\n",
            "==================================================\n",
            "Training until validation scores don't improve for 50 rounds.\n",
            "[50]\ttraining's l2: 0.69691\tvalid_1's l2: 0.673832\n",
            "[100]\ttraining's l2: 0.672724\tvalid_1's l2: 0.654448\n",
            "[150]\ttraining's l2: 0.665749\tvalid_1's l2: 0.650537\n",
            "[200]\ttraining's l2: 0.661295\tvalid_1's l2: 0.648258\n",
            "[250]\ttraining's l2: 0.658723\tvalid_1's l2: 0.647179\n",
            "[300]\ttraining's l2: 0.656313\tvalid_1's l2: 0.645963\n",
            "[350]\ttraining's l2: 0.654496\tvalid_1's l2: 0.645231\n",
            "[400]\ttraining's l2: 0.65311\tvalid_1's l2: 0.644655\n",
            "[450]\ttraining's l2: 0.651998\tvalid_1's l2: 0.644448\n",
            "[500]\ttraining's l2: 0.650914\tvalid_1's l2: 0.643904\n",
            "[550]\ttraining's l2: 0.650016\tvalid_1's l2: 0.643554\n",
            "[600]\ttraining's l2: 0.64914\tvalid_1's l2: 0.64331\n",
            "[650]\ttraining's l2: 0.648438\tvalid_1's l2: 0.643082\n",
            "[700]\ttraining's l2: 0.647814\tvalid_1's l2: 0.642777\n",
            "[750]\ttraining's l2: 0.647182\tvalid_1's l2: 0.642605\n",
            "[800]\ttraining's l2: 0.646645\tvalid_1's l2: 0.6423\n",
            "[850]\ttraining's l2: 0.6462\tvalid_1's l2: 0.642341\n",
            "[900]\ttraining's l2: 0.645746\tvalid_1's l2: 0.64199\n",
            "[950]\ttraining's l2: 0.645342\tvalid_1's l2: 0.641964\n",
            "Early stopping, best iteration is:\n",
            "[943]\ttraining's l2: 0.645406\tvalid_1's l2: 0.641907\n",
            "==================================================\n",
            "Step 10\n",
            "==================================================\n",
            "Training until validation scores don't improve for 50 rounds.\n",
            "[50]\ttraining's l2: 0.700438\tvalid_1's l2: 0.680807\n",
            "[100]\ttraining's l2: 0.674266\tvalid_1's l2: 0.65953\n",
            "[150]\ttraining's l2: 0.666571\tvalid_1's l2: 0.65498\n",
            "[200]\ttraining's l2: 0.661719\tvalid_1's l2: 0.652911\n",
            "[250]\ttraining's l2: 0.658765\tvalid_1's l2: 0.651578\n",
            "[300]\ttraining's l2: 0.656295\tvalid_1's l2: 0.650621\n",
            "[350]\ttraining's l2: 0.654466\tvalid_1's l2: 0.650106\n",
            "[400]\ttraining's l2: 0.652925\tvalid_1's l2: 0.649649\n",
            "[450]\ttraining's l2: 0.651763\tvalid_1's l2: 0.649401\n",
            "[500]\ttraining's l2: 0.650682\tvalid_1's l2: 0.649129\n",
            "[550]\ttraining's l2: 0.649778\tvalid_1's l2: 0.648802\n",
            "[600]\ttraining's l2: 0.648899\tvalid_1's l2: 0.648551\n",
            "[650]\ttraining's l2: 0.648157\tvalid_1's l2: 0.648472\n",
            "[700]\ttraining's l2: 0.647499\tvalid_1's l2: 0.648296\n",
            "[750]\ttraining's l2: 0.646852\tvalid_1's l2: 0.648139\n",
            "[800]\ttraining's l2: 0.646222\tvalid_1's l2: 0.647956\n",
            "[850]\ttraining's l2: 0.64576\tvalid_1's l2: 0.647986\n",
            "Early stopping, best iteration is:\n",
            "[805]\ttraining's l2: 0.64618\tvalid_1's l2: 0.647916\n",
            "==================================================\n",
            "Step 11\n",
            "==================================================\n",
            "Training until validation scores don't improve for 50 rounds.\n",
            "[50]\ttraining's l2: 0.670455\tvalid_1's l2: 0.664739\n",
            "[100]\ttraining's l2: 0.64738\tvalid_1's l2: 0.642615\n",
            "[150]\ttraining's l2: 0.640734\tvalid_1's l2: 0.63814\n",
            "[200]\ttraining's l2: 0.636737\tvalid_1's l2: 0.635853\n",
            "[250]\ttraining's l2: 0.633967\tvalid_1's l2: 0.634853\n",
            "[300]\ttraining's l2: 0.631833\tvalid_1's l2: 0.634069\n",
            "[350]\ttraining's l2: 0.630276\tvalid_1's l2: 0.63348\n",
            "[400]\ttraining's l2: 0.628926\tvalid_1's l2: 0.632901\n",
            "[450]\ttraining's l2: 0.627921\tvalid_1's l2: 0.632441\n",
            "[500]\ttraining's l2: 0.626864\tvalid_1's l2: 0.632214\n",
            "[550]\ttraining's l2: 0.626076\tvalid_1's l2: 0.631838\n",
            "[600]\ttraining's l2: 0.625282\tvalid_1's l2: 0.631728\n",
            "[650]\ttraining's l2: 0.624615\tvalid_1's l2: 0.631404\n",
            "[700]\ttraining's l2: 0.623973\tvalid_1's l2: 0.631431\n",
            "[750]\ttraining's l2: 0.623368\tvalid_1's l2: 0.631323\n",
            "[800]\ttraining's l2: 0.622832\tvalid_1's l2: 0.631222\n",
            "[850]\ttraining's l2: 0.622399\tvalid_1's l2: 0.631132\n",
            "[900]\ttraining's l2: 0.621987\tvalid_1's l2: 0.631075\n",
            "[950]\ttraining's l2: 0.62162\tvalid_1's l2: 0.631005\n",
            "[1000]\ttraining's l2: 0.62122\tvalid_1's l2: 0.631283\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1000]\ttraining's l2: 0.62122\tvalid_1's l2: 0.631283\n",
            "==================================================\n",
            "Step 12\n",
            "==================================================\n",
            "Training until validation scores don't improve for 50 rounds.\n",
            "[50]\ttraining's l2: 0.719641\tvalid_1's l2: 0.695747\n",
            "[100]\ttraining's l2: 0.69277\tvalid_1's l2: 0.672341\n",
            "[150]\ttraining's l2: 0.684916\tvalid_1's l2: 0.668048\n",
            "[200]\ttraining's l2: 0.680496\tvalid_1's l2: 0.665992\n",
            "[250]\ttraining's l2: 0.677623\tvalid_1's l2: 0.664615\n",
            "[300]\ttraining's l2: 0.675198\tvalid_1's l2: 0.663888\n",
            "[350]\ttraining's l2: 0.673402\tvalid_1's l2: 0.663185\n",
            "[400]\ttraining's l2: 0.67194\tvalid_1's l2: 0.662677\n",
            "[450]\ttraining's l2: 0.670798\tvalid_1's l2: 0.662452\n",
            "[500]\ttraining's l2: 0.66965\tvalid_1's l2: 0.662058\n",
            "[550]\ttraining's l2: 0.668722\tvalid_1's l2: 0.661845\n",
            "[600]\ttraining's l2: 0.667921\tvalid_1's l2: 0.661638\n",
            "[650]\ttraining's l2: 0.667147\tvalid_1's l2: 0.661515\n",
            "[700]\ttraining's l2: 0.666472\tvalid_1's l2: 0.661252\n",
            "[750]\ttraining's l2: 0.665809\tvalid_1's l2: 0.661227\n",
            "[800]\ttraining's l2: 0.66526\tvalid_1's l2: 0.661047\n",
            "[850]\ttraining's l2: 0.664777\tvalid_1's l2: 0.661216\n",
            "Early stopping, best iteration is:\n",
            "[800]\ttraining's l2: 0.66526\tvalid_1's l2: 0.661047\n",
            "==================================================\n",
            "Step 13\n",
            "==================================================\n",
            "Training until validation scores don't improve for 50 rounds.\n",
            "[50]\ttraining's l2: 0.775466\tvalid_1's l2: 0.736441\n",
            "[100]\ttraining's l2: 0.747982\tvalid_1's l2: 0.71582\n",
            "[150]\ttraining's l2: 0.739351\tvalid_1's l2: 0.710858\n",
            "[200]\ttraining's l2: 0.734346\tvalid_1's l2: 0.708515\n",
            "[250]\ttraining's l2: 0.73087\tvalid_1's l2: 0.706804\n",
            "[300]\ttraining's l2: 0.727987\tvalid_1's l2: 0.705708\n",
            "[350]\ttraining's l2: 0.725829\tvalid_1's l2: 0.705008\n",
            "[400]\ttraining's l2: 0.724112\tvalid_1's l2: 0.704215\n",
            "[450]\ttraining's l2: 0.722745\tvalid_1's l2: 0.703782\n",
            "[500]\ttraining's l2: 0.721446\tvalid_1's l2: 0.703447\n",
            "[550]\ttraining's l2: 0.720395\tvalid_1's l2: 0.703046\n",
            "[600]\ttraining's l2: 0.719374\tvalid_1's l2: 0.702781\n",
            "[650]\ttraining's l2: 0.718445\tvalid_1's l2: 0.702694\n",
            "[700]\ttraining's l2: 0.717697\tvalid_1's l2: 0.702393\n",
            "[750]\ttraining's l2: 0.716859\tvalid_1's l2: 0.70213\n",
            "[800]\ttraining's l2: 0.716167\tvalid_1's l2: 0.701935\n",
            "[850]\ttraining's l2: 0.715643\tvalid_1's l2: 0.701851\n",
            "[900]\ttraining's l2: 0.715094\tvalid_1's l2: 0.701794\n",
            "[950]\ttraining's l2: 0.714598\tvalid_1's l2: 0.701668\n",
            "[1000]\ttraining's l2: 0.714071\tvalid_1's l2: 0.701606\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1000]\ttraining's l2: 0.714071\tvalid_1's l2: 0.701606\n",
            "==================================================\n",
            "Step 14\n",
            "==================================================\n",
            "Training until validation scores don't improve for 50 rounds.\n",
            "[50]\ttraining's l2: 0.8064\tvalid_1's l2: 0.762229\n",
            "[100]\ttraining's l2: 0.778426\tvalid_1's l2: 0.746655\n",
            "[150]\ttraining's l2: 0.769563\tvalid_1's l2: 0.743047\n",
            "[200]\ttraining's l2: 0.763667\tvalid_1's l2: 0.740876\n",
            "[250]\ttraining's l2: 0.759785\tvalid_1's l2: 0.739771\n",
            "[300]\ttraining's l2: 0.756892\tvalid_1's l2: 0.738821\n",
            "[350]\ttraining's l2: 0.754638\tvalid_1's l2: 0.738573\n",
            "Early stopping, best iteration is:\n",
            "[345]\ttraining's l2: 0.754883\tvalid_1's l2: 0.738331\n",
            "==================================================\n",
            "Step 15\n",
            "==================================================\n",
            "Training until validation scores don't improve for 50 rounds.\n",
            "[50]\ttraining's l2: 0.719826\tvalid_1's l2: 0.701705\n",
            "[100]\ttraining's l2: 0.696341\tvalid_1's l2: 0.683118\n",
            "[150]\ttraining's l2: 0.68918\tvalid_1's l2: 0.679805\n",
            "[200]\ttraining's l2: 0.684924\tvalid_1's l2: 0.677826\n",
            "[250]\ttraining's l2: 0.681942\tvalid_1's l2: 0.677242\n",
            "[300]\ttraining's l2: 0.679671\tvalid_1's l2: 0.676887\n",
            "[350]\ttraining's l2: 0.677862\tvalid_1's l2: 0.676323\n",
            "[400]\ttraining's l2: 0.67645\tvalid_1's l2: 0.676151\n",
            "Early stopping, best iteration is:\n",
            "[377]\ttraining's l2: 0.677045\tvalid_1's l2: 0.676061\n",
            "==================================================\n",
            "Step 16\n",
            "==================================================\n",
            "Training until validation scores don't improve for 50 rounds.\n",
            "[50]\ttraining's l2: 0.705056\tvalid_1's l2: 0.684659\n",
            "[100]\ttraining's l2: 0.681323\tvalid_1's l2: 0.666672\n",
            "[150]\ttraining's l2: 0.674447\tvalid_1's l2: 0.66375\n",
            "[200]\ttraining's l2: 0.669932\tvalid_1's l2: 0.662094\n",
            "[250]\ttraining's l2: 0.667194\tvalid_1's l2: 0.661094\n",
            "[300]\ttraining's l2: 0.665012\tvalid_1's l2: 0.6606\n",
            "[350]\ttraining's l2: 0.663345\tvalid_1's l2: 0.659861\n",
            "[400]\ttraining's l2: 0.661962\tvalid_1's l2: 0.659476\n",
            "[450]\ttraining's l2: 0.660795\tvalid_1's l2: 0.659179\n",
            "[500]\ttraining's l2: 0.659684\tvalid_1's l2: 0.658982\n",
            "[550]\ttraining's l2: 0.658816\tvalid_1's l2: 0.658933\n",
            "[600]\ttraining's l2: 0.657973\tvalid_1's l2: 0.658698\n",
            "[650]\ttraining's l2: 0.657252\tvalid_1's l2: 0.658436\n",
            "[700]\ttraining's l2: 0.656608\tvalid_1's l2: 0.658254\n",
            "[750]\ttraining's l2: 0.655956\tvalid_1's l2: 0.658117\n",
            "[800]\ttraining's l2: 0.655414\tvalid_1's l2: 0.658011\n",
            "Early stopping, best iteration is:\n",
            "[799]\ttraining's l2: 0.655429\tvalid_1's l2: 0.658005\n"
          ]
        }
      ],
      "source": [
        "MAX_ROUNDS = 1000\n",
        "val_pred = []\n",
        "test_pred = []\n",
        "cate_vars = []\n",
        "feature_importance_data = []\n",
        "\n",
        "for i in range(16):\n",
        "\n",
        "    print(\"=\" * 50)\n",
        "    print(\"Step %d\" % (i+1))\n",
        "    print(\"=\" * 50)\n",
        "\n",
        "    dtrain = lgb.Dataset(\n",
        "        X_train, label=y_train[:, i],\n",
        "        categorical_feature=cate_vars,\n",
        "        weight=pd.concat([items_reindexed[\"perishable\"]]*6) * 0.25 + 1\n",
        "    )\n",
        "    dval = lgb.Dataset(\n",
        "        X_val, label=y_val[:, i], reference=dtrain,\n",
        "        weight=items_reindexed[\"perishable\"].values * 0.25 + 1,\n",
        "        categorical_feature=cate_vars)\n",
        "    bst = lgb.train(\n",
        "        params, dtrain, num_boost_round=MAX_ROUNDS,\n",
        "        valid_sets=[dtrain, dval], early_stopping_rounds=50, verbose_eval=50\n",
        "    )\n",
        "\n",
        "    f_importance = [\"Step {}\".format(i)] + [fx for fx in bst.feature_importance(\"gain\")]\n",
        "    feature_importance_data.append(f_importance)\n",
        "\n",
        "    val_pred.append(bst.predict(\n",
        "        X_val, num_iteration=bst.best_iteration or MAX_ROUNDS))\n",
        "    test_pred.append(bst.predict(\n",
        "        X_test, num_iteration=bst.best_iteration or MAX_ROUNDS))\n",
        "\n",
        "    # Save model\n",
        "    with open('lgb_step_{}.pickle'.format(i), 'wb') as file:\n",
        "        pickle.dump(bst, file)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "8uVVuIMO5Am9",
        "outputId": "88d82270-2929-418a-af2e-1bd33898a44c"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "\n",
        "# feature importance graph\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "plt.style.use('seaborn-whitegrid')\n",
        "\n",
        "plotImp(bst,X_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2xOlrS4OQxL5",
        "outputId": "ab34441b-e3e1-4f13-fcb2-feb29b5cf50b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation LOG mse: 0.638039143942974\n",
            "Test LOG mse: 0.6420420039587773\n",
            "Validation mse: 135.167216491934\n",
            "Test mse: 147.66461261703074\n"
          ]
        }
      ],
      "source": [
        "print(\"Validation LOG mse:\", mean_squared_error(y_val, np.array(val_pred).transpose(), sample_weight=(items_reindexed[\"perishable\"].values * 0.25 + 1)))\n",
        "print(\"Test LOG mse:\", mean_squared_error(y_test, np.array(test_pred).transpose(), sample_weight=(items_reindexed[\"perishable\"].values * 0.25 + 1)))\n",
        "\n",
        "print(\"Validation mse:\", mean_squared_error(np.clip(np.expm1(y_val), 0, 1000), np.clip(np.expm1(np.array(val_pred).transpose()), 0, 1000), sample_weight=(items_reindexed[\"perishable\"].values * 0.25 + 1)))\n",
        "print(\"Test mse:\", mean_squared_error(np.clip(np.expm1(y_test), 0, 1000), np.clip(np.expm1(np.array(test_pred).transpose()), 0, 1000), sample_weight=(items_reindexed[\"perishable\"].values * 0.25 + 1)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cuhPACgWCqLf",
        "outputId": "4efe4e41-e16b-48e6-ee91-be941b26527a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Combine with the test data split...\n"
          ]
        }
      ],
      "source": [
        "print(\"Combine with the test data split...\")\n",
        "\n",
        "df_preds_lg = pd.DataFrame(\n",
        "    np.array(test_pred).transpose(), index=train_selected_sales.index,\n",
        "    columns=pd.date_range(\"2017-07-31\", periods=16)\n",
        ").stack().to_frame(\"log_predicted_unit_sales\")\n",
        "df_preds_lg.index.set_names([\"store_nbr\", \"item_nbr\", \"date\"], inplace=True)\n",
        "\n",
        "df_test_lg = pd.DataFrame(\n",
        "    y_test, index=train_selected_sales.index,\n",
        "    columns=pd.date_range(\"2017-07-31\", periods=16)\n",
        ").stack().to_frame(\"log_actual_unit_sales\")\n",
        "df_test_lg.index.set_names([\"store_nbr\", \"item_nbr\", \"date\"], inplace=True)\n",
        "\n",
        "\n",
        "comb_df = pd.concat([df_preds_lg, df_test_lg], axis=1)\n",
        "comb_df['predicted_unit_sales'] = np.clip(np.expm1(comb_df[\"log_predicted_unit_sales\"]), 0, 1000)\n",
        "comb_df['actual_unit_sales'] = np.clip(np.expm1(comb_df[\"log_actual_unit_sales\"]), 0, 1000)\n",
        "# comb_df['perishable'] = df_items_2017[\"perishable\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "BPZfHW_0csxP"
      },
      "outputs": [],
      "source": [
        "out_filename = 'drive/My Drive/favorita/model_outputs/' + 'lgbm_log_scaled_out_base.pkl'\n",
        "merge_df = pd.merge(comb_df.reset_index(), items.reset_index(), on='item_nbr',how=\"left\")\n",
        "merge_df.to_pickle(out_filename)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 215,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nN0aSeogIUxY",
        "outputId": "f8468b48-83ae-4b15-deff-461558f47a94"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 14632384 entries, 0 to 14632383\n",
            "Data columns (total 10 columns):\n",
            " #   Column                    Dtype         \n",
            "---  ------                    -----         \n",
            " 0   store_nbr                 int64         \n",
            " 1   item_nbr                  int64         \n",
            " 2   date                      datetime64[ns]\n",
            " 3   log_predicted_unit_sales  float64       \n",
            " 4   log_actual_unit_sales     float64       \n",
            " 5   predicted_unit_sales      float64       \n",
            " 6   actual_unit_sales         float64       \n",
            " 7   family                    int64         \n",
            " 8   class                     int64         \n",
            " 9   perishable                int64         \n",
            "dtypes: datetime64[ns](1), float64(4), int64(5)\n",
            "memory usage: 1.2 GB\n"
          ]
        }
      ],
      "source": [
        "merge_df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jGUHuogFJBjJ",
        "outputId": "c208dce6-c95f-4d7c-ca58-f066430dbed5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unit (147.6646126170308, 12.151732905928718, 12.151732905928718, 3.59257736530841, nan)\n",
            "Log (0.6420420039587776, 0.80127523608232, 0.80127523608232, 0.6211503262601399, inf)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:10: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  # Remove the CWD from sys.path while we load stuff.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:10: RuntimeWarning: invalid value encountered in true_divide\n",
            "  # Remove the CWD from sys.path while we load stuff.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:10: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  # Remove the CWD from sys.path while we load stuff.\n"
          ]
        }
      ],
      "source": [
        "# errors for model\n",
        "weights = merge_df[\"perishable\"].values * 0.25 + 1\n",
        "print('Unit', get_error(weights, merge_df['actual_unit_sales'].values, merge_df[\"predicted_unit_sales\"].values))\n",
        "print('Log', get_error(weights, merge_df['log_actual_unit_sales'].values, merge_df[\"log_predicted_unit_sales\"].values))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model 2 (with engineered features)"
      ],
      "metadata": {
        "id": "WRFoUJgrpzfA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Preparing dataset...1\")\n",
        "\n",
        "t2017 = date(2017, 5, 22)\n",
        "X_l, y_l = [], []\n",
        "for i in range(4):\n",
        "    delta = timedelta(days=7 * i)\n",
        "    X_tmp, y_tmp = prepare_dataset_1(t2017 + delta)\n",
        "    X_l.append(X_tmp)\n",
        "    y_l.append(y_tmp)\n",
        "\n",
        "X_train = pd.concat(X_l, axis=0)\n",
        "y_train = np.concatenate(y_l, axis=0)\n",
        "del X_l, y_l\n",
        "X_val, y_val = prepare_dataset_1(date(2017, 7, 10))\n",
        "X_test, y_test = prepare_dataset_1(date(2017, 7, 31))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U6sKU8VOg8g_",
        "outputId": "00e1b0fb-b850-4755-fc73-702d224784b3"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Preparing dataset...1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Preparing dataset...1\")\n",
        "\n",
        "t2017 = date(2017, 5, 24)\n",
        "X_l, y_l = [], []\n",
        "for i in range(6):\n",
        "    delta = timedelta(days=7 * i)\n",
        "    X_tmp, y_tmp = prepare_dataset_1(t2017 + delta)\n",
        "    X_l.append(X_tmp)\n",
        "    y_l.append(y_tmp)\n",
        "\n",
        "X_train = pd.concat(X_l, axis=0)\n",
        "y_train = np.concatenate(y_l, axis=0)\n",
        "del X_l, y_l\n",
        "X_val, y_val = prepare_dataset_1(date(2017, 7, 12))\n",
        "X_test, y_test = prepare_dataset_1(date(2017, 7, 31))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4mEmWrAip-To",
        "outputId": "bf973d94-a124-4ae1-8f75-e329848b79c5"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Preparing dataset...1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "M95kjHQy3jp5"
      },
      "outputs": [],
      "source": [
        "params = {\n",
        "    'num_leaves': 60,\n",
        "    'objective': 'regression_l2',\n",
        "    'max_depth': 10,\n",
        "    'min_data_per_leaf': 300,\n",
        "    'learning_rate': 0.05,\n",
        "    'boosting_type': 'gbdt',\n",
        "    'colsample_bytree': 0.4,\n",
        "    'feature_fraction': 0.75,\n",
        "    'bagging_fraction': 0.75,\n",
        "    'bagging_freq': 1,\n",
        "    'metric': 'l2',\n",
        "    'num_threads': 4\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_ROUNDS = 1000\n",
        "val_pred = []\n",
        "test_pred = []\n",
        "cate_vars = []\n",
        "feature_importance_data = []\n",
        "\n",
        "for i in range(16):\n",
        "\n",
        "    print(\"=\" * 50)\n",
        "    print(\"Step %d\" % (i+1))\n",
        "    print(\"=\" * 50)\n",
        "\n",
        "    dtrain = lgb.Dataset(\n",
        "        X_train, label=y_train[:, i],\n",
        "        categorical_feature=cate_vars,\n",
        "        weight=pd.concat([items_reindexed[\"perishable\"]]*4) * 0.25 + 1\n",
        "    )\n",
        "    dval = lgb.Dataset(\n",
        "        X_val, label=y_val[:, i], reference=dtrain,\n",
        "        weight=items_reindexed[\"perishable\"].values * 0.25 + 1,\n",
        "        categorical_feature=cate_vars)\n",
        "    bst = lgb.train(\n",
        "        params, dtrain, num_boost_round=MAX_ROUNDS,\n",
        "        valid_sets=[dtrain, dval], early_stopping_rounds=50, verbose_eval=50\n",
        "    )\n",
        "\n",
        "    f_importance = [\"Step {}\".format(i)] + [fx for fx in bst.feature_importance(\"gain\")]\n",
        "    feature_importance_data.append(f_importance)\n",
        "\n",
        "    val_pred.append(bst.predict(\n",
        "        X_val, num_iteration=bst.best_iteration or MAX_ROUNDS))\n",
        "    test_pred.append(bst.predict(\n",
        "        X_test, num_iteration=bst.best_iteration or MAX_ROUNDS))\n",
        "\n",
        "    # Save model\n",
        "    with open('lgb_step_{}.pickle'.format(i), 'wb') as file:\n",
        "        pickle.dump(bst, file)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kwwg_sa6p5m_",
        "outputId": "a9f8e75e-a7bf-43eb-8dc2-42cfe3032b51"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==================================================\n",
            "Step 1\n",
            "==================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/lightgbm/basic.py:1205: UserWarning: Using categorical_feature in Dataset.\n",
            "  warnings.warn('Using categorical_feature in Dataset.')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training until validation scores don't improve for 50 rounds.\n",
            "[50]\ttraining's l2: 0.340534\tvalid_1's l2: 0.327607\n",
            "[100]\ttraining's l2: 0.327159\tvalid_1's l2: 0.321024\n",
            "[150]\ttraining's l2: 0.322415\tvalid_1's l2: 0.320646\n",
            "[200]\ttraining's l2: 0.318979\tvalid_1's l2: 0.320614\n",
            "Early stopping, best iteration is:\n",
            "[162]\ttraining's l2: 0.321555\tvalid_1's l2: 0.320603\n",
            "==================================================\n",
            "Step 2\n",
            "==================================================\n",
            "Training until validation scores don't improve for 50 rounds.\n",
            "[50]\ttraining's l2: 0.348013\tvalid_1's l2: 0.34148\n",
            "[100]\ttraining's l2: 0.335602\tvalid_1's l2: 0.33507\n",
            "[150]\ttraining's l2: 0.33091\tvalid_1's l2: 0.3348\n",
            "[200]\ttraining's l2: 0.327364\tvalid_1's l2: 0.334733\n",
            "Early stopping, best iteration is:\n",
            "[178]\ttraining's l2: 0.328781\tvalid_1's l2: 0.334715\n",
            "==================================================\n",
            "Step 3\n",
            "==================================================\n",
            "Training until validation scores don't improve for 50 rounds.\n",
            "[50]\ttraining's l2: 0.356839\tvalid_1's l2: 0.337571\n",
            "[100]\ttraining's l2: 0.343918\tvalid_1's l2: 0.33412\n",
            "Early stopping, best iteration is:\n",
            "[86]\ttraining's l2: 0.345902\tvalid_1's l2: 0.333861\n",
            "==================================================\n",
            "Step 4\n",
            "==================================================\n",
            "Training until validation scores don't improve for 50 rounds.\n",
            "[50]\ttraining's l2: 0.360675\tvalid_1's l2: 0.363351\n",
            "[100]\ttraining's l2: 0.34846\tvalid_1's l2: 0.368926\n",
            "Early stopping, best iteration is:\n",
            "[54]\ttraining's l2: 0.358536\tvalid_1's l2: 0.363141\n",
            "==================================================\n",
            "Step 5\n",
            "==================================================\n",
            "Training until validation scores don't improve for 50 rounds.\n",
            "[50]\ttraining's l2: 0.375986\tvalid_1's l2: 0.373133\n",
            "[100]\ttraining's l2: 0.362015\tvalid_1's l2: 0.375243\n",
            "Early stopping, best iteration is:\n",
            "[56]\ttraining's l2: 0.372586\tvalid_1's l2: 0.372017\n",
            "==================================================\n",
            "Step 6\n",
            "==================================================\n",
            "Training until validation scores don't improve for 50 rounds.\n",
            "[50]\ttraining's l2: 0.383689\tvalid_1's l2: 0.380066\n",
            "[100]\ttraining's l2: 0.369853\tvalid_1's l2: 0.386145\n",
            "Early stopping, best iteration is:\n",
            "[55]\ttraining's l2: 0.380647\tvalid_1's l2: 0.379812\n",
            "==================================================\n",
            "Step 7\n",
            "==================================================\n",
            "Training until validation scores don't improve for 50 rounds.\n",
            "[50]\ttraining's l2: 0.386548\tvalid_1's l2: 0.390854\n",
            "[100]\ttraining's l2: 0.371477\tvalid_1's l2: 0.398707\n",
            "Early stopping, best iteration is:\n",
            "[54]\ttraining's l2: 0.383729\tvalid_1's l2: 0.390627\n",
            "==================================================\n",
            "Step 8\n",
            "==================================================\n",
            "Training until validation scores don't improve for 50 rounds.\n",
            "[50]\ttraining's l2: 0.38768\tvalid_1's l2: 0.37928\n",
            "[100]\ttraining's l2: 0.374777\tvalid_1's l2: 0.377026\n",
            "Early stopping, best iteration is:\n",
            "[79]\ttraining's l2: 0.378028\tvalid_1's l2: 0.376564\n",
            "==================================================\n",
            "Step 9\n",
            "==================================================\n",
            "Training until validation scores don't improve for 50 rounds.\n",
            "[50]\ttraining's l2: 0.383812\tvalid_1's l2: 0.376919\n",
            "[100]\ttraining's l2: 0.371103\tvalid_1's l2: 0.373888\n",
            "Early stopping, best iteration is:\n",
            "[84]\ttraining's l2: 0.37351\tvalid_1's l2: 0.373732\n",
            "==================================================\n",
            "Step 10\n",
            "==================================================\n",
            "Training until validation scores don't improve for 50 rounds.\n",
            "[50]\ttraining's l2: 0.387901\tvalid_1's l2: 0.381681\n",
            "[100]\ttraining's l2: 0.374883\tvalid_1's l2: 0.378868\n",
            "Early stopping, best iteration is:\n",
            "[86]\ttraining's l2: 0.376934\tvalid_1's l2: 0.378511\n",
            "==================================================\n",
            "Step 11\n",
            "==================================================\n",
            "Training until validation scores don't improve for 50 rounds.\n",
            "[50]\ttraining's l2: 0.384073\tvalid_1's l2: 0.37862\n",
            "[100]\ttraining's l2: 0.371886\tvalid_1's l2: 0.374496\n",
            "Early stopping, best iteration is:\n",
            "[89]\ttraining's l2: 0.373426\tvalid_1's l2: 0.374234\n",
            "==================================================\n",
            "Step 12\n",
            "==================================================\n",
            "Training until validation scores don't improve for 50 rounds.\n",
            "[50]\ttraining's l2: 0.396386\tvalid_1's l2: 0.387641\n",
            "[100]\ttraining's l2: 0.382458\tvalid_1's l2: 0.38267\n",
            "[150]\ttraining's l2: 0.376559\tvalid_1's l2: 0.382877\n",
            "Early stopping, best iteration is:\n",
            "[104]\ttraining's l2: 0.381918\tvalid_1's l2: 0.382587\n",
            "==================================================\n",
            "Step 13\n",
            "==================================================\n",
            "Training until validation scores don't improve for 50 rounds.\n",
            "[50]\ttraining's l2: 0.412192\tvalid_1's l2: 0.404279\n",
            "[100]\ttraining's l2: 0.39848\tvalid_1's l2: 0.40338\n",
            "Early stopping, best iteration is:\n",
            "[67]\ttraining's l2: 0.40452\tvalid_1's l2: 0.402611\n",
            "==================================================\n",
            "Step 14\n",
            "==================================================\n",
            "Training until validation scores don't improve for 50 rounds.\n",
            "[50]\ttraining's l2: 0.413768\tvalid_1's l2: 0.407995\n",
            "[100]\ttraining's l2: 0.398077\tvalid_1's l2: 0.410518\n",
            "Early stopping, best iteration is:\n",
            "[58]\ttraining's l2: 0.408725\tvalid_1's l2: 0.407263\n",
            "==================================================\n",
            "Step 15\n",
            "==================================================\n",
            "Training until validation scores don't improve for 50 rounds.\n",
            "[50]\ttraining's l2: 0.406599\tvalid_1's l2: 0.403333\n",
            "[100]\ttraining's l2: 0.393856\tvalid_1's l2: 0.400041\n",
            "Early stopping, best iteration is:\n",
            "[92]\ttraining's l2: 0.394841\tvalid_1's l2: 0.399931\n",
            "==================================================\n",
            "Step 16\n",
            "==================================================\n",
            "Training until validation scores don't improve for 50 rounds.\n",
            "[50]\ttraining's l2: 0.400192\tvalid_1's l2: 0.398524\n",
            "[100]\ttraining's l2: 0.387746\tvalid_1's l2: 0.395777\n",
            "Early stopping, best iteration is:\n",
            "[88]\ttraining's l2: 0.389525\tvalid_1's l2: 0.395664\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "HUMsc21vqIsx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "outputId": "fe8e211d-6aea-4f77-ee30-b3c5b5ab3ff9",
        "id": "DxWXE1smryhI"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# feature importance graph\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "plt.style.use('seaborn-whitegrid')\n",
        "\n",
        "plotImp(bst,X_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d05b4d6e-1b7d-4e01-b1db-e551dc67c1d6",
        "id": "OKJG7d5LryhQ"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation LOG mse: 0.3741170495951862\n",
            "Test LOG mse: 0.3777183866496703\n",
            "Validation mse: 63.35742517845878\n",
            "Test mse: 76.36082252571566\n"
          ]
        }
      ],
      "source": [
        "print(\"Validation LOG mse:\", mean_squared_error(y_val, np.array(val_pred).transpose(), sample_weight=(items_reindexed[\"perishable\"].values * 0.25 + 1)))\n",
        "print(\"Test LOG mse:\", mean_squared_error(y_test, np.array(test_pred).transpose(), sample_weight=(items_reindexed[\"perishable\"].values * 0.25 + 1)))\n",
        "\n",
        "print(\"Validation mse:\", mean_squared_error(np.clip(np.expm1(y_val), 0, 1000), np.clip(np.expm1(np.array(val_pred).transpose()), 0, 1000), sample_weight=(items_reindexed[\"perishable\"].values * 0.25 + 1)))\n",
        "print(\"Test mse:\", mean_squared_error(np.clip(np.expm1(y_test), 0, 1000), np.clip(np.expm1(np.array(test_pred).transpose()), 0, 1000), sample_weight=(items_reindexed[\"perishable\"].values * 0.25 + 1)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "febc8beb-1138-4136-aa7b-ed57c70dc35a",
        "id": "d3Y3N5D9qq-d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Combine with the test data split...\n"
          ]
        }
      ],
      "source": [
        "print(\"Combine with the test data split...\")\n",
        "\n",
        "df_preds_lg = pd.DataFrame(\n",
        "    np.array(test_pred).transpose(), index=train_selected_sales.index,\n",
        "    columns=pd.date_range(\"2017-07-31\", periods=16)\n",
        ").stack().to_frame(\"log_predicted_unit_sales\")\n",
        "df_preds_lg.index.set_names([\"store_nbr\", \"item_nbr\", \"date\"], inplace=True)\n",
        "\n",
        "df_test_lg = pd.DataFrame(\n",
        "    y_test, index=train_selected_sales.index,\n",
        "    columns=pd.date_range(\"2017-07-31\", periods=16)\n",
        ").stack().to_frame(\"log_actual_unit_sales\")\n",
        "df_test_lg.index.set_names([\"store_nbr\", \"item_nbr\", \"date\"], inplace=True)\n",
        "\n",
        "\n",
        "comb_df = pd.concat([df_preds_lg, df_test_lg], axis=1)\n",
        "comb_df['predicted_unit_sales'] = np.clip(np.expm1(comb_df[\"log_predicted_unit_sales\"]), 0, 1000)\n",
        "comb_df['actual_unit_sales'] = np.clip(np.expm1(comb_df[\"log_actual_unit_sales\"]), 0, 1000)\n",
        "# comb_df['perishable'] = df_items_2017[\"perishable\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "UrJgrwYhqq-l"
      },
      "outputs": [],
      "source": [
        "# save data to file\n",
        "out_filename = 'drive/My Drive/favorita/model_outputs/' + 'lgbm_log_scaled_out_fe_model.pkl'\n",
        "merge_df = pd.merge(comb_df.reset_index(), items.reset_index(), on='item_nbr',how=\"left\")\n",
        "merge_df.to_pickle(out_filename)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "23083c66-4446-48d6-813e-babf2995cfe1",
        "id": "RCkGwkWiqq-l"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(Timestamp('2017-07-31 00:00:00'), Timestamp('2017-08-15 00:00:00'))"
            ]
          },
          "execution_count": 90,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "merge_df.date.min(), merge_df.date.max()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "weights = merge_df[\"perishable\"].values * 0.25 + 1\n",
        "print('Unit', get_error(weights, merge_df['actual_unit_sales'].values, merge_df[\"predicted_unit_sales\"].values))\n",
        "print('Log', get_error(weights, merge_df['log_actual_unit_sales'].values, merge_df[\"log_predicted_unit_sales\"].values))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qYdhdVIVuqBf",
        "outputId": "619d06d7-17e1-4ca9-e822-78c66a67cd5c"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unit (76.3608225257157, 8.738467973604738, 8.738467973604738, 2.4528014516036087, nan)\n",
            "Log (0.37771838664967045, 0.6145879812115352, 0.6145879812115352, 0.4610471297511819, inf)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:10: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  # Remove the CWD from sys.path while we load stuff.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:10: RuntimeWarning: invalid value encountered in true_divide\n",
            "  # Remove the CWD from sys.path while we load stuff.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:10: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  # Remove the CWD from sys.path while we load stuff.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model 3 NN (engineered features)"
      ],
      "metadata": {
        "id": "b2fcZb50vYu3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Preparing dataset...1\")\n",
        "\n",
        "t2017 = date(2017, 5, 22)\n",
        "X_l, y_l = [], []\n",
        "for i in range(4):\n",
        "    delta = timedelta(days=7 * i)\n",
        "    X_tmp, y_tmp = prepare_dataset_1(t2017 + delta)\n",
        "    X_l.append(X_tmp)\n",
        "    y_l.append(y_tmp)\n",
        "\n",
        "X_train = pd.concat(X_l, axis=0)\n",
        "y_train = np.concatenate(y_l, axis=0)\n",
        "del X_l, y_l\n",
        "X_val, y_val = prepare_dataset_1(date(2017, 7, 12))\n",
        "X_test, y_test = prepare_dataset_1(date(2017, 7, 31))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b23b421-2019-4ad7-d12c-37bbbfe829ba",
        "id": "Y75IQofyvj8h"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Preparing dataset...1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "6Zn5zmhRvj8i"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "30_oFm7dcg_d"
      },
      "outputs": [],
      "source": [
        "# transform the data for NN model\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(pd.concat([X_train, X_val, X_test]))\n",
        "X_train[:] = scaler.transform(X_train)\n",
        "X_val[:] = scaler.transform(X_val)\n",
        "X_test[:] = scaler.transform(X_test)\n",
        "\n",
        "X_train = X_train.values\n",
        "X_test = X_test.values\n",
        "X_val = X_val.values\n",
        "X_train = X_train.reshape((X_train.shape[0], 1, X_train.shape[1]))\n",
        "X_test = X_test.reshape((X_test.shape[0], 1, X_test.shape[1]))\n",
        "X_val = X_val.reshape((X_val.shape[0], 1, X_val.shape[1]))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "tga2ksNlyKVR"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "XG9LQkjZvCNy"
      },
      "outputs": [],
      "source": [
        "def build_model():\n",
        "\n",
        "    model = Sequential()\n",
        "\n",
        "    model.add(LSTM(32, input_shape=(X_train.shape[1],X_train.shape[2])))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(.1))\n",
        "\n",
        "    model.add(Dense(32, activation='relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(.2))\n",
        "\n",
        "    model.add(Dense(1))\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wK8e3AnUvCUX",
        "outputId": "739d2642-bee2-4c3f-80aa-16c06f6a2095"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==================================================\n",
            "Step 1\n",
            "==================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "4/4 - 1s - loss: 0.6499 - mse: 0.6146 - val_loss: 0.6444 - val_mse: 0.6444 - lr: 0.0010 - 694ms/epoch - 173ms/step\n",
            "Epoch 33/1000\n",
            "4/4 - 1s - loss: 0.6445 - mse: 0.6093 - val_loss: 0.6392 - val_mse: 0.6392 - lr: 0.0010 - 709ms/epoch - 177ms/step\n",
            "Epoch 34/1000\n",
            "4/4 - 1s - loss: 0.6351 - mse: 0.6009 - val_loss: 0.6342 - val_mse: 0.6342 - lr: 0.0010 - 711ms/epoch - 178ms/step\n",
            "Epoch 35/1000\n",
            "4/4 - 1s - loss: 0.6293 - mse: 0.5952 - val_loss: 0.6293 - val_mse: 0.6293 - lr: 0.0010 - 700ms/epoch - 175ms/step\n",
            "Epoch 36/1000\n",
            "4/4 - 1s - loss: 0.6229 - mse: 0.5890 - val_loss: 0.6233 - val_mse: 0.6233 - lr: 0.0010 - 702ms/epoch - 176ms/step\n",
            "Epoch 37/1000\n",
            "4/4 - 1s - loss: 0.6198 - mse: 0.5861 - val_loss: 0.6180 - val_mse: 0.6180 - lr: 0.0010 - 712ms/epoch - 178ms/step\n",
            "Epoch 38/1000\n",
            "4/4 - 1s - loss: 0.6140 - mse: 0.5806 - val_loss: 0.6133 - val_mse: 0.6133 - lr: 0.0010 - 710ms/epoch - 178ms/step\n",
            "Epoch 39/1000\n",
            "4/4 - 1s - loss: 0.6084 - mse: 0.5752 - val_loss: 0.6082 - val_mse: 0.6082 - lr: 0.0010 - 705ms/epoch - 176ms/step\n",
            "Epoch 40/1000\n",
            "4/4 - 1s - loss: 0.5999 - mse: 0.5674 - val_loss: 0.6035 - val_mse: 0.6035 - lr: 0.0010 - 701ms/epoch - 175ms/step\n",
            "Epoch 41/1000\n",
            "4/4 - 1s - loss: 0.5949 - mse: 0.5624 - val_loss: 0.5986 - val_mse: 0.5986 - lr: 0.0010 - 698ms/epoch - 174ms/step\n",
            "Epoch 42/1000\n",
            "4/4 - 1s - loss: 0.5900 - mse: 0.5579 - val_loss: 0.5932 - val_mse: 0.5932 - lr: 0.0010 - 801ms/epoch - 200ms/step\n",
            "Epoch 43/1000\n",
            "4/4 - 1s - loss: 0.5860 - mse: 0.5541 - val_loss: 0.5870 - val_mse: 0.5870 - lr: 0.0010 - 867ms/epoch - 217ms/step\n",
            "Epoch 44/1000\n",
            "4/4 - 1s - loss: 0.5784 - mse: 0.5469 - val_loss: 0.5809 - val_mse: 0.5809 - lr: 0.0010 - 710ms/epoch - 177ms/step\n",
            "Epoch 45/1000\n",
            "4/4 - 1s - loss: 0.5728 - mse: 0.5416 - val_loss: 0.5762 - val_mse: 0.5762 - lr: 0.0010 - 728ms/epoch - 182ms/step\n",
            "Epoch 46/1000\n",
            "4/4 - 1s - loss: 0.5708 - mse: 0.5401 - val_loss: 0.5721 - val_mse: 0.5721 - lr: 0.0010 - 705ms/epoch - 176ms/step\n",
            "Epoch 47/1000\n",
            "4/4 - 1s - loss: 0.5665 - mse: 0.5357 - val_loss: 0.5678 - val_mse: 0.5678 - lr: 0.0010 - 698ms/epoch - 175ms/step\n",
            "Epoch 48/1000\n",
            "4/4 - 1s - loss: 0.5621 - mse: 0.5318 - val_loss: 0.5625 - val_mse: 0.5625 - lr: 0.0010 - 706ms/epoch - 177ms/step\n",
            "Epoch 49/1000\n",
            "4/4 - 1s - loss: 0.5567 - mse: 0.5266 - val_loss: 0.5575 - val_mse: 0.5575 - lr: 0.0010 - 702ms/epoch - 175ms/step\n",
            "Epoch 50/1000\n",
            "4/4 - 1s - loss: 0.5544 - mse: 0.5244 - val_loss: 0.5515 - val_mse: 0.5515 - lr: 0.0010 - 685ms/epoch - 171ms/step\n",
            "Epoch 51/1000\n",
            "4/4 - 1s - loss: 0.5490 - mse: 0.5192 - val_loss: 0.5464 - val_mse: 0.5464 - lr: 0.0010 - 699ms/epoch - 175ms/step\n",
            "Epoch 52/1000\n",
            "4/4 - 1s - loss: 0.5443 - mse: 0.5148 - val_loss: 0.5417 - val_mse: 0.5417 - lr: 0.0010 - 698ms/epoch - 174ms/step\n",
            "Epoch 53/1000\n",
            "4/4 - 1s - loss: 0.5418 - mse: 0.5124 - val_loss: 0.5373 - val_mse: 0.5373 - lr: 0.0010 - 694ms/epoch - 173ms/step\n",
            "Epoch 54/1000\n",
            "4/4 - 1s - loss: 0.5362 - mse: 0.5070 - val_loss: 0.5319 - val_mse: 0.5319 - lr: 0.0010 - 693ms/epoch - 173ms/step\n",
            "Epoch 55/1000\n",
            "4/4 - 1s - loss: 0.5330 - mse: 0.5041 - val_loss: 0.5266 - val_mse: 0.5266 - lr: 0.0010 - 689ms/epoch - 172ms/step\n",
            "Epoch 56/1000\n",
            "4/4 - 1s - loss: 0.5288 - mse: 0.5000 - val_loss: 0.5221 - val_mse: 0.5221 - lr: 0.0010 - 685ms/epoch - 171ms/step\n",
            "Epoch 57/1000\n",
            "4/4 - 1s - loss: 0.5257 - mse: 0.4971 - val_loss: 0.5177 - val_mse: 0.5177 - lr: 0.0010 - 693ms/epoch - 173ms/step\n",
            "Epoch 58/1000\n",
            "4/4 - 1s - loss: 0.5237 - mse: 0.4951 - val_loss: 0.5134 - val_mse: 0.5134 - lr: 0.0010 - 682ms/epoch - 170ms/step\n",
            "Epoch 59/1000\n",
            "4/4 - 1s - loss: 0.5184 - mse: 0.4903 - val_loss: 0.5090 - val_mse: 0.5090 - lr: 0.0010 - 688ms/epoch - 172ms/step\n",
            "Epoch 60/1000\n",
            "4/4 - 1s - loss: 0.5157 - mse: 0.4877 - val_loss: 0.5041 - val_mse: 0.5041 - lr: 0.0010 - 694ms/epoch - 173ms/step\n",
            "Epoch 61/1000\n",
            "4/4 - 1s - loss: 0.5140 - mse: 0.4858 - val_loss: 0.4994 - val_mse: 0.4994 - lr: 0.0010 - 698ms/epoch - 174ms/step\n",
            "Epoch 62/1000\n",
            "4/4 - 1s - loss: 0.5111 - mse: 0.4832 - val_loss: 0.4955 - val_mse: 0.4955 - lr: 0.0010 - 694ms/epoch - 174ms/step\n",
            "Epoch 63/1000\n",
            "4/4 - 1s - loss: 0.5072 - mse: 0.4794 - val_loss: 0.4919 - val_mse: 0.4919 - lr: 0.0010 - 700ms/epoch - 175ms/step\n",
            "Epoch 64/1000\n",
            "4/4 - 1s - loss: 0.5026 - mse: 0.4752 - val_loss: 0.4875 - val_mse: 0.4875 - lr: 0.0010 - 709ms/epoch - 177ms/step\n",
            "Epoch 65/1000\n",
            "4/4 - 1s - loss: 0.5012 - mse: 0.4738 - val_loss: 0.4831 - val_mse: 0.4831 - lr: 0.0010 - 701ms/epoch - 175ms/step\n",
            "Epoch 66/1000\n",
            "4/4 - 1s - loss: 0.4976 - mse: 0.4704 - val_loss: 0.4788 - val_mse: 0.4788 - lr: 0.0010 - 704ms/epoch - 176ms/step\n",
            "Epoch 67/1000\n",
            "4/4 - 1s - loss: 0.4970 - mse: 0.4697 - val_loss: 0.4744 - val_mse: 0.4744 - lr: 0.0010 - 709ms/epoch - 177ms/step\n",
            "Epoch 68/1000\n",
            "4/4 - 1s - loss: 0.4939 - mse: 0.4668 - val_loss: 0.4701 - val_mse: 0.4701 - lr: 0.0010 - 706ms/epoch - 176ms/step\n",
            "Epoch 69/1000\n",
            "4/4 - 1s - loss: 0.4906 - mse: 0.4640 - val_loss: 0.4663 - val_mse: 0.4663 - lr: 0.0010 - 721ms/epoch - 180ms/step\n",
            "Epoch 70/1000\n",
            "4/4 - 1s - loss: 0.4880 - mse: 0.4614 - val_loss: 0.4632 - val_mse: 0.4632 - lr: 0.0010 - 712ms/epoch - 178ms/step\n",
            "Epoch 71/1000\n",
            "4/4 - 1s - loss: 0.4838 - mse: 0.4575 - val_loss: 0.4603 - val_mse: 0.4603 - lr: 0.0010 - 699ms/epoch - 175ms/step\n",
            "Epoch 72/1000\n",
            "4/4 - 1s - loss: 0.4839 - mse: 0.4573 - val_loss: 0.4567 - val_mse: 0.4567 - lr: 0.0010 - 694ms/epoch - 173ms/step\n",
            "Epoch 73/1000\n",
            "4/4 - 1s - loss: 0.4830 - mse: 0.4564 - val_loss: 0.4527 - val_mse: 0.4527 - lr: 0.0010 - 709ms/epoch - 177ms/step\n",
            "Epoch 74/1000\n",
            "4/4 - 1s - loss: 0.4806 - mse: 0.4541 - val_loss: 0.4487 - val_mse: 0.4487 - lr: 0.0010 - 711ms/epoch - 178ms/step\n",
            "Epoch 75/1000\n",
            "4/4 - 1s - loss: 0.4770 - mse: 0.4507 - val_loss: 0.4452 - val_mse: 0.4452 - lr: 0.0010 - 694ms/epoch - 173ms/step\n",
            "Epoch 76/1000\n",
            "4/4 - 1s - loss: 0.4749 - mse: 0.4487 - val_loss: 0.4425 - val_mse: 0.4425 - lr: 0.0010 - 707ms/epoch - 177ms/step\n",
            "Epoch 77/1000\n",
            "4/4 - 1s - loss: 0.4720 - mse: 0.4461 - val_loss: 0.4400 - val_mse: 0.4400 - lr: 0.0010 - 704ms/epoch - 176ms/step\n",
            "Epoch 78/1000\n",
            "4/4 - 1s - loss: 0.4713 - mse: 0.4452 - val_loss: 0.4370 - val_mse: 0.4370 - lr: 0.0010 - 705ms/epoch - 176ms/step\n",
            "Epoch 79/1000\n",
            "4/4 - 1s - loss: 0.4681 - mse: 0.4422 - val_loss: 0.4336 - val_mse: 0.4336 - lr: 0.0010 - 704ms/epoch - 176ms/step\n",
            "Epoch 80/1000\n",
            "4/4 - 1s - loss: 0.4664 - mse: 0.4407 - val_loss: 0.4302 - val_mse: 0.4302 - lr: 0.0010 - 719ms/epoch - 180ms/step\n",
            "Epoch 81/1000\n",
            "4/4 - 1s - loss: 0.4656 - mse: 0.4397 - val_loss: 0.4275 - val_mse: 0.4275 - lr: 0.0010 - 717ms/epoch - 179ms/step\n",
            "Epoch 82/1000\n",
            "4/4 - 1s - loss: 0.4625 - mse: 0.4370 - val_loss: 0.4246 - val_mse: 0.4246 - lr: 0.0010 - 707ms/epoch - 177ms/step\n",
            "Epoch 83/1000\n",
            "4/4 - 1s - loss: 0.4613 - mse: 0.4358 - val_loss: 0.4220 - val_mse: 0.4220 - lr: 0.0010 - 720ms/epoch - 180ms/step\n",
            "Epoch 84/1000\n",
            "4/4 - 1s - loss: 0.4580 - mse: 0.4329 - val_loss: 0.4194 - val_mse: 0.4194 - lr: 0.0010 - 706ms/epoch - 177ms/step\n",
            "Epoch 85/1000\n",
            "4/4 - 1s - loss: 0.4596 - mse: 0.4341 - val_loss: 0.4171 - val_mse: 0.4171 - lr: 0.0010 - 705ms/epoch - 176ms/step\n",
            "Epoch 86/1000\n",
            "4/4 - 1s - loss: 0.4555 - mse: 0.4304 - val_loss: 0.4150 - val_mse: 0.4150 - lr: 0.0010 - 710ms/epoch - 178ms/step\n",
            "Epoch 87/1000\n",
            "4/4 - 1s - loss: 0.4539 - mse: 0.4287 - val_loss: 0.4131 - val_mse: 0.4131 - lr: 0.0010 - 721ms/epoch - 180ms/step\n",
            "Epoch 88/1000\n",
            "4/4 - 1s - loss: 0.4529 - mse: 0.4277 - val_loss: 0.4109 - val_mse: 0.4109 - lr: 0.0010 - 702ms/epoch - 175ms/step\n",
            "Epoch 89/1000\n",
            "4/4 - 1s - loss: 0.4517 - mse: 0.4267 - val_loss: 0.4085 - val_mse: 0.4085 - lr: 0.0010 - 706ms/epoch - 176ms/step\n",
            "Epoch 90/1000\n",
            "4/4 - 1s - loss: 0.4485 - mse: 0.4237 - val_loss: 0.4064 - val_mse: 0.4064 - lr: 0.0010 - 708ms/epoch - 177ms/step\n",
            "Epoch 91/1000\n",
            "4/4 - 1s - loss: 0.4472 - mse: 0.4224 - val_loss: 0.4044 - val_mse: 0.4044 - lr: 0.0010 - 704ms/epoch - 176ms/step\n",
            "Epoch 92/1000\n",
            "4/4 - 1s - loss: 0.4463 - mse: 0.4216 - val_loss: 0.4023 - val_mse: 0.4023 - lr: 0.0010 - 701ms/epoch - 175ms/step\n",
            "Epoch 93/1000\n",
            "4/4 - 1s - loss: 0.4453 - mse: 0.4206 - val_loss: 0.3999 - val_mse: 0.3999 - lr: 0.0010 - 717ms/epoch - 179ms/step\n",
            "Epoch 94/1000\n",
            "4/4 - 1s - loss: 0.4444 - mse: 0.4198 - val_loss: 0.3982 - val_mse: 0.3982 - lr: 0.0010 - 714ms/epoch - 179ms/step\n",
            "Epoch 95/1000\n",
            "4/4 - 1s - loss: 0.4412 - mse: 0.4168 - val_loss: 0.3969 - val_mse: 0.3969 - lr: 0.0010 - 698ms/epoch - 175ms/step\n",
            "Epoch 96/1000\n",
            "4/4 - 1s - loss: 0.4410 - mse: 0.4165 - val_loss: 0.3957 - val_mse: 0.3957 - lr: 0.0010 - 702ms/epoch - 175ms/step\n",
            "Epoch 97/1000\n",
            "4/4 - 1s - loss: 0.4392 - mse: 0.4148 - val_loss: 0.3937 - val_mse: 0.3937 - lr: 0.0010 - 708ms/epoch - 177ms/step\n",
            "Epoch 98/1000\n",
            "4/4 - 1s - loss: 0.4374 - mse: 0.4131 - val_loss: 0.3915 - val_mse: 0.3915 - lr: 0.0010 - 704ms/epoch - 176ms/step\n",
            "Epoch 99/1000\n",
            "4/4 - 1s - loss: 0.4365 - mse: 0.4121 - val_loss: 0.3897 - val_mse: 0.3897 - lr: 0.0010 - 700ms/epoch - 175ms/step\n",
            "Epoch 100/1000\n",
            "4/4 - 1s - loss: 0.4367 - mse: 0.4124 - val_loss: 0.3883 - val_mse: 0.3883 - lr: 0.0010 - 704ms/epoch - 176ms/step\n",
            "Epoch 101/1000\n",
            "4/4 - 1s - loss: 0.4342 - mse: 0.4100 - val_loss: 0.3869 - val_mse: 0.3869 - lr: 0.0010 - 713ms/epoch - 178ms/step\n",
            "Epoch 102/1000\n",
            "4/4 - 1s - loss: 0.4339 - mse: 0.4098 - val_loss: 0.3857 - val_mse: 0.3857 - lr: 0.0010 - 712ms/epoch - 178ms/step\n",
            "Epoch 103/1000\n",
            "4/4 - 1s - loss: 0.4323 - mse: 0.4082 - val_loss: 0.3848 - val_mse: 0.3848 - lr: 0.0010 - 722ms/epoch - 180ms/step\n",
            "Epoch 104/1000\n",
            "4/4 - 1s - loss: 0.4315 - mse: 0.4075 - val_loss: 0.3834 - val_mse: 0.3834 - lr: 0.0010 - 695ms/epoch - 174ms/step\n",
            "Epoch 105/1000\n",
            "4/4 - 1s - loss: 0.4305 - mse: 0.4065 - val_loss: 0.3818 - val_mse: 0.3818 - lr: 0.0010 - 715ms/epoch - 179ms/step\n",
            "Epoch 106/1000\n",
            "4/4 - 1s - loss: 0.4284 - mse: 0.4047 - val_loss: 0.3802 - val_mse: 0.3802 - lr: 0.0010 - 710ms/epoch - 177ms/step\n",
            "Epoch 107/1000\n",
            "4/4 - 1s - loss: 0.4281 - mse: 0.4042 - val_loss: 0.3793 - val_mse: 0.3793 - lr: 0.0010 - 720ms/epoch - 180ms/step\n",
            "Epoch 108/1000\n",
            "4/4 - 1s - loss: 0.4270 - mse: 0.4032 - val_loss: 0.3782 - val_mse: 0.3782 - lr: 0.0010 - 700ms/epoch - 175ms/step\n",
            "Epoch 109/1000\n",
            "4/4 - 1s - loss: 0.4261 - mse: 0.4021 - val_loss: 0.3773 - val_mse: 0.3773 - lr: 0.0010 - 728ms/epoch - 182ms/step\n",
            "Epoch 110/1000\n",
            "4/4 - 1s - loss: 0.4247 - mse: 0.4010 - val_loss: 0.3765 - val_mse: 0.3765 - lr: 0.0010 - 703ms/epoch - 176ms/step\n",
            "Epoch 111/1000\n",
            "4/4 - 1s - loss: 0.4254 - mse: 0.4016 - val_loss: 0.3758 - val_mse: 0.3758 - lr: 0.0010 - 708ms/epoch - 177ms/step\n",
            "Epoch 112/1000\n",
            "4/4 - 1s - loss: 0.4233 - mse: 0.3996 - val_loss: 0.3751 - val_mse: 0.3751 - lr: 0.0010 - 722ms/epoch - 180ms/step\n",
            "Epoch 113/1000\n",
            "4/4 - 1s - loss: 0.4227 - mse: 0.3991 - val_loss: 0.3743 - val_mse: 0.3743 - lr: 0.0010 - 706ms/epoch - 176ms/step\n",
            "Epoch 114/1000\n",
            "4/4 - 1s - loss: 0.4217 - mse: 0.3981 - val_loss: 0.3733 - val_mse: 0.3733 - lr: 0.0010 - 698ms/epoch - 175ms/step\n",
            "Epoch 115/1000\n",
            "4/4 - 1s - loss: 0.4215 - mse: 0.3980 - val_loss: 0.3726 - val_mse: 0.3726 - lr: 0.0010 - 708ms/epoch - 177ms/step\n",
            "Epoch 116/1000\n",
            "4/4 - 1s - loss: 0.4202 - mse: 0.3968 - val_loss: 0.3719 - val_mse: 0.3719 - lr: 0.0010 - 716ms/epoch - 179ms/step\n",
            "Epoch 117/1000\n",
            "4/4 - 1s - loss: 0.4198 - mse: 0.3962 - val_loss: 0.3713 - val_mse: 0.3713 - lr: 0.0010 - 714ms/epoch - 179ms/step\n",
            "Epoch 118/1000\n",
            "4/4 - 1s - loss: 0.4189 - mse: 0.3954 - val_loss: 0.3707 - val_mse: 0.3707 - lr: 0.0010 - 705ms/epoch - 176ms/step\n",
            "Epoch 119/1000\n",
            "4/4 - 1s - loss: 0.4180 - mse: 0.3946 - val_loss: 0.3703 - val_mse: 0.3703 - lr: 0.0010 - 715ms/epoch - 179ms/step\n",
            "Epoch 120/1000\n",
            "4/4 - 1s - loss: 0.4172 - mse: 0.3938 - val_loss: 0.3699 - val_mse: 0.3699 - lr: 0.0010 - 703ms/epoch - 176ms/step\n",
            "Epoch 121/1000\n",
            "4/4 - 1s - loss: 0.4163 - mse: 0.3931 - val_loss: 0.3692 - val_mse: 0.3692 - lr: 0.0010 - 701ms/epoch - 175ms/step\n",
            "Epoch 122/1000\n",
            "4/4 - 1s - loss: 0.4160 - mse: 0.3926 - val_loss: 0.3688 - val_mse: 0.3688 - lr: 0.0010 - 705ms/epoch - 176ms/step\n",
            "Epoch 123/1000\n",
            "4/4 - 1s - loss: 0.4154 - mse: 0.3921 - val_loss: 0.3685 - val_mse: 0.3685 - lr: 0.0010 - 711ms/epoch - 178ms/step\n",
            "Epoch 124/1000\n",
            "4/4 - 1s - loss: 0.4150 - mse: 0.3916 - val_loss: 0.3681 - val_mse: 0.3681 - lr: 0.0010 - 704ms/epoch - 176ms/step\n",
            "Epoch 125/1000\n",
            "4/4 - 1s - loss: 0.4136 - mse: 0.3905 - val_loss: 0.3677 - val_mse: 0.3677 - lr: 0.0010 - 691ms/epoch - 173ms/step\n",
            "Epoch 126/1000\n",
            "4/4 - 1s - loss: 0.4129 - mse: 0.3898 - val_loss: 0.3673 - val_mse: 0.3673 - lr: 0.0010 - 703ms/epoch - 176ms/step\n",
            "Epoch 127/1000\n",
            "4/4 - 1s - loss: 0.4119 - mse: 0.3889 - val_loss: 0.3670 - val_mse: 0.3670 - lr: 0.0010 - 704ms/epoch - 176ms/step\n",
            "Epoch 128/1000\n",
            "4/4 - 1s - loss: 0.4117 - mse: 0.3886 - val_loss: 0.3667 - val_mse: 0.3667 - lr: 0.0010 - 699ms/epoch - 175ms/step\n",
            "Epoch 129/1000\n",
            "4/4 - 1s - loss: 0.4102 - mse: 0.3872 - val_loss: 0.3664 - val_mse: 0.3664 - lr: 0.0010 - 712ms/epoch - 178ms/step\n",
            "Epoch 130/1000\n",
            "4/4 - 1s - loss: 0.4105 - mse: 0.3874 - val_loss: 0.3660 - val_mse: 0.3660 - lr: 0.0010 - 715ms/epoch - 179ms/step\n",
            "Epoch 131/1000\n",
            "4/4 - 1s - loss: 0.4095 - mse: 0.3866 - val_loss: 0.3658 - val_mse: 0.3658 - lr: 0.0010 - 695ms/epoch - 174ms/step\n",
            "Epoch 132/1000\n",
            "4/4 - 1s - loss: 0.4095 - mse: 0.3865 - val_loss: 0.3656 - val_mse: 0.3656 - lr: 0.0010 - 702ms/epoch - 175ms/step\n",
            "Epoch 133/1000\n",
            "4/4 - 1s - loss: 0.4095 - mse: 0.3865 - val_loss: 0.3654 - val_mse: 0.3654 - lr: 0.0010 - 695ms/epoch - 174ms/step\n",
            "Epoch 134/1000\n",
            "4/4 - 1s - loss: 0.4081 - mse: 0.3853 - val_loss: 0.3651 - val_mse: 0.3651 - lr: 0.0010 - 703ms/epoch - 176ms/step\n",
            "Epoch 135/1000\n",
            "4/4 - 1s - loss: 0.4078 - mse: 0.3849 - val_loss: 0.3651 - val_mse: 0.3651 - lr: 0.0010 - 717ms/epoch - 179ms/step\n",
            "Epoch 136/1000\n",
            "4/4 - 1s - loss: 0.4071 - mse: 0.3842 - val_loss: 0.3649 - val_mse: 0.3649 - lr: 0.0010 - 707ms/epoch - 177ms/step\n",
            "Epoch 137/1000\n",
            "4/4 - 1s - loss: 0.4064 - mse: 0.3836 - val_loss: 0.3646 - val_mse: 0.3646 - lr: 0.0010 - 693ms/epoch - 173ms/step\n",
            "Epoch 138/1000\n",
            "4/4 - 1s - loss: 0.4065 - mse: 0.3837 - val_loss: 0.3645 - val_mse: 0.3645 - lr: 0.0010 - 696ms/epoch - 174ms/step\n",
            "Epoch 139/1000\n",
            "4/4 - 1s - loss: 0.4064 - mse: 0.3835 - val_loss: 0.3646 - val_mse: 0.3646 - lr: 0.0010 - 696ms/epoch - 174ms/step\n",
            "Epoch 140/1000\n",
            "4/4 - 1s - loss: 0.4045 - mse: 0.3818 - val_loss: 0.3645 - val_mse: 0.3645 - lr: 0.0010 - 697ms/epoch - 174ms/step\n",
            "Epoch 141/1000\n",
            "4/4 - 1s - loss: 0.4050 - mse: 0.3822 - val_loss: 0.3643 - val_mse: 0.3643 - lr: 0.0010 - 772ms/epoch - 193ms/step\n",
            "Epoch 142/1000\n",
            "4/4 - 1s - loss: 0.4042 - mse: 0.3815 - val_loss: 0.3641 - val_mse: 0.3641 - lr: 0.0010 - 718ms/epoch - 179ms/step\n",
            "Epoch 143/1000\n",
            "4/4 - 1s - loss: 0.4042 - mse: 0.3815 - val_loss: 0.3639 - val_mse: 0.3639 - lr: 0.0010 - 699ms/epoch - 175ms/step\n",
            "Epoch 144/1000\n",
            "4/4 - 1s - loss: 0.4031 - mse: 0.3805 - val_loss: 0.3639 - val_mse: 0.3639 - lr: 0.0010 - 698ms/epoch - 175ms/step\n",
            "Epoch 145/1000\n",
            "4/4 - 1s - loss: 0.4031 - mse: 0.3805 - val_loss: 0.3640 - val_mse: 0.3640 - lr: 0.0010 - 693ms/epoch - 173ms/step\n",
            "Epoch 146/1000\n",
            "4/4 - 1s - loss: 0.4028 - mse: 0.3801 - val_loss: 0.3640 - val_mse: 0.3640 - lr: 0.0010 - 705ms/epoch - 176ms/step\n",
            "Epoch 147/1000\n",
            "4/4 - 1s - loss: 0.4019 - mse: 0.3793 - val_loss: 0.3641 - val_mse: 0.3641 - lr: 0.0010 - 690ms/epoch - 172ms/step\n",
            "Epoch 148/1000\n",
            "4/4 - 1s - loss: 0.4019 - mse: 0.3792 - val_loss: 0.3642 - val_mse: 0.3642 - lr: 0.0010 - 703ms/epoch - 176ms/step\n",
            "Epoch 149/1000\n",
            "4/4 - 1s - loss: 0.4022 - mse: 0.3796 - val_loss: 0.3640 - val_mse: 0.3640 - lr: 0.0010 - 701ms/epoch - 175ms/step\n",
            "Epoch 150/1000\n",
            "4/4 - 1s - loss: 0.4011 - mse: 0.3785 - val_loss: 0.3637 - val_mse: 0.3637 - lr: 0.0010 - 716ms/epoch - 179ms/step\n",
            "Epoch 151/1000\n",
            "4/4 - 1s - loss: 0.4007 - mse: 0.3781 - val_loss: 0.3637 - val_mse: 0.3637 - lr: 0.0010 - 704ms/epoch - 176ms/step\n",
            "Epoch 152/1000\n",
            "4/4 - 1s - loss: 0.4003 - mse: 0.3778 - val_loss: 0.3638 - val_mse: 0.3638 - lr: 0.0010 - 709ms/epoch - 177ms/step\n",
            "Epoch 153/1000\n",
            "4/4 - 1s - loss: 0.4005 - mse: 0.3781 - val_loss: 0.3636 - val_mse: 0.3636 - lr: 0.0010 - 691ms/epoch - 173ms/step\n",
            "Epoch 154/1000\n",
            "4/4 - 1s - loss: 0.3999 - mse: 0.3773 - val_loss: 0.3637 - val_mse: 0.3637 - lr: 0.0010 - 704ms/epoch - 176ms/step\n",
            "Epoch 155/1000\n",
            "4/4 - 1s - loss: 0.3999 - mse: 0.3774 - val_loss: 0.3636 - val_mse: 0.3636 - lr: 0.0010 - 714ms/epoch - 178ms/step\n",
            "Epoch 156/1000\n",
            "4/4 - 1s - loss: 0.3985 - mse: 0.3761 - val_loss: 0.3636 - val_mse: 0.3636 - lr: 0.0010 - 696ms/epoch - 174ms/step\n",
            "Epoch 157/1000\n",
            "4/4 - 1s - loss: 0.3982 - mse: 0.3758 - val_loss: 0.3642 - val_mse: 0.3642 - lr: 0.0010 - 692ms/epoch - 173ms/step\n",
            "Epoch 158/1000\n",
            "4/4 - 1s - loss: 0.3975 - mse: 0.3753 - val_loss: 0.3639 - val_mse: 0.3639 - lr: 0.0010 - 704ms/epoch - 176ms/step\n",
            "Epoch 159/1000\n",
            "4/4 - 1s - loss: 0.3982 - mse: 0.3759 - val_loss: 0.3632 - val_mse: 0.3632 - lr: 0.0010 - 693ms/epoch - 173ms/step\n",
            "Epoch 160/1000\n",
            "4/4 - 1s - loss: 0.3982 - mse: 0.3757 - val_loss: 0.3634 - val_mse: 0.3634 - lr: 0.0010 - 687ms/epoch - 172ms/step\n",
            "Epoch 161/1000\n",
            "4/4 - 1s - loss: 0.3976 - mse: 0.3753 - val_loss: 0.3635 - val_mse: 0.3635 - lr: 0.0010 - 719ms/epoch - 180ms/step\n",
            "Epoch 162/1000\n",
            "4/4 - 1s - loss: 0.3967 - mse: 0.3745 - val_loss: 0.3631 - val_mse: 0.3631 - lr: 0.0010 - 689ms/epoch - 172ms/step\n",
            "Epoch 163/1000\n",
            "4/4 - 1s - loss: 0.3966 - mse: 0.3743 - val_loss: 0.3633 - val_mse: 0.3633 - lr: 0.0010 - 691ms/epoch - 173ms/step\n",
            "Epoch 164/1000\n",
            "4/4 - 1s - loss: 0.3960 - mse: 0.3737 - val_loss: 0.3638 - val_mse: 0.3638 - lr: 0.0010 - 690ms/epoch - 172ms/step\n",
            "Epoch 165/1000\n",
            "4/4 - 1s - loss: 0.3969 - mse: 0.3745 - val_loss: 0.3639 - val_mse: 0.3639 - lr: 0.0010 - 696ms/epoch - 174ms/step\n",
            "Epoch 166/1000\n",
            "\n",
            "Epoch 166: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "4/4 - 1s - loss: 0.3953 - mse: 0.3730 - val_loss: 0.3634 - val_mse: 0.3634 - lr: 0.0010 - 707ms/epoch - 177ms/step\n",
            "Epoch 167/1000\n",
            "4/4 - 1s - loss: 0.3961 - mse: 0.3739 - val_loss: 0.3635 - val_mse: 0.3635 - lr: 1.0000e-04 - 701ms/epoch - 175ms/step\n",
            "Epoch 168/1000\n",
            "4/4 - 1s - loss: 0.3955 - mse: 0.3733 - val_loss: 0.3636 - val_mse: 0.3636 - lr: 1.0000e-04 - 704ms/epoch - 176ms/step\n",
            "Epoch 169/1000\n",
            "4/4 - 1s - loss: 0.3967 - mse: 0.3744 - val_loss: 0.3637 - val_mse: 0.3637 - lr: 1.0000e-04 - 697ms/epoch - 174ms/step\n",
            "Epoch 170/1000\n",
            "4/4 - 1s - loss: 0.3955 - mse: 0.3732 - val_loss: 0.3637 - val_mse: 0.3637 - lr: 1.0000e-04 - 709ms/epoch - 177ms/step\n",
            "Epoch 171/1000\n",
            "4/4 - 1s - loss: 0.3956 - mse: 0.3734 - val_loss: 0.3638 - val_mse: 0.3638 - lr: 1.0000e-04 - 710ms/epoch - 178ms/step\n",
            "Epoch 172/1000\n",
            "4/4 - 1s - loss: 0.3954 - mse: 0.3732 - val_loss: 0.3639 - val_mse: 0.3639 - lr: 1.0000e-04 - 700ms/epoch - 175ms/step\n",
            "Epoch 172: early stopping\n",
            "==================================================\n",
            "Step 3\n",
            "==================================================\n",
            "Epoch 1/1000\n",
            "4/4 - 4s - loss: 3.0717 - mse: 2.8947 - val_loss: 0.9007 - val_mse: 0.9007 - lr: 0.0010 - 4s/epoch - 933ms/step\n",
            "Epoch 2/1000\n",
            "4/4 - 1s - loss: 2.0659 - mse: 1.9470 - val_loss: 0.8871 - val_mse: 0.8871 - lr: 0.0010 - 705ms/epoch - 176ms/step\n",
            "Epoch 3/1000\n",
            "4/4 - 1s - loss: 1.6549 - mse: 1.5597 - val_loss: 0.8964 - val_mse: 0.8964 - lr: 0.0010 - 702ms/epoch - 175ms/step\n",
            "Epoch 4/1000\n",
            "4/4 - 1s - loss: 1.4771 - mse: 1.3949 - val_loss: 0.8985 - val_mse: 0.8985 - lr: 0.0010 - 710ms/epoch - 177ms/step\n",
            "Epoch 5/1000\n",
            "4/4 - 1s - loss: 1.3607 - mse: 1.2863 - val_loss: 0.8892 - val_mse: 0.8892 - lr: 0.0010 - 717ms/epoch - 179ms/step\n",
            "Epoch 6/1000\n",
            "4/4 - 1s - loss: 1.2590 - mse: 1.1905 - val_loss: 0.8807 - val_mse: 0.8807 - lr: 0.0010 - 714ms/epoch - 178ms/step\n",
            "Epoch 7/1000\n",
            "4/4 - 1s - loss: 1.1819 - mse: 1.1180 - val_loss: 0.8804 - val_mse: 0.8804 - lr: 0.0010 - 694ms/epoch - 173ms/step\n",
            "Epoch 8/1000\n",
            "4/4 - 1s - loss: 1.1344 - mse: 1.0734 - val_loss: 0.8855 - val_mse: 0.8855 - lr: 0.0010 - 705ms/epoch - 176ms/step\n",
            "Epoch 9/1000\n",
            "4/4 - 1s - loss: 1.0916 - mse: 1.0337 - val_loss: 0.8881 - val_mse: 0.8881 - lr: 0.0010 - 714ms/epoch - 179ms/step\n",
            "Epoch 10/1000\n",
            "4/4 - 1s - loss: 1.0543 - mse: 0.9983 - val_loss: 0.8848 - val_mse: 0.8848 - lr: 0.0010 - 710ms/epoch - 178ms/step\n",
            "Epoch 11/1000\n",
            "4/4 - 1s - loss: 1.0275 - mse: 0.9733 - val_loss: 0.8797 - val_mse: 0.8797 - lr: 0.0010 - 699ms/epoch - 175ms/step\n",
            "Epoch 12/1000\n",
            "4/4 - 1s - loss: 1.0055 - mse: 0.9520 - val_loss: 0.8781 - val_mse: 0.8781 - lr: 0.0010 - 705ms/epoch - 176ms/step\n",
            "Epoch 13/1000\n",
            "4/4 - 1s - loss: 0.9839 - mse: 0.9319 - val_loss: 0.8786 - val_mse: 0.8786 - lr: 0.0010 - 714ms/epoch - 178ms/step\n",
            "Epoch 14/1000\n",
            "4/4 - 1s - loss: 0.9634 - mse: 0.9133 - val_loss: 0.8760 - val_mse: 0.8760 - lr: 0.0010 - 723ms/epoch - 181ms/step\n",
            "Epoch 15/1000\n",
            "4/4 - 1s - loss: 0.9536 - mse: 0.9034 - val_loss: 0.8733 - val_mse: 0.8733 - lr: 0.0010 - 693ms/epoch - 173ms/step\n",
            "Epoch 16/1000\n",
            "4/4 - 1s - loss: 0.9337 - mse: 0.8844 - val_loss: 0.8698 - val_mse: 0.8698 - lr: 0.0010 - 700ms/epoch - 175ms/step\n",
            "Epoch 17/1000\n",
            "4/4 - 1s - loss: 0.9180 - mse: 0.8700 - val_loss: 0.8643 - val_mse: 0.8643 - lr: 0.0010 - 703ms/epoch - 176ms/step\n",
            "Epoch 18/1000\n",
            "4/4 - 1s - loss: 0.8988 - mse: 0.8518 - val_loss: 0.8604 - val_mse: 0.8604 - lr: 0.0010 - 699ms/epoch - 175ms/step\n",
            "Epoch 19/1000\n",
            "4/4 - 1s - loss: 0.8864 - mse: 0.8403 - val_loss: 0.8572 - val_mse: 0.8572 - lr: 0.0010 - 692ms/epoch - 173ms/step\n",
            "Epoch 20/1000\n",
            "4/4 - 1s - loss: 0.8702 - mse: 0.8246 - val_loss: 0.8531 - val_mse: 0.8531 - lr: 0.0010 - 696ms/epoch - 174ms/step\n",
            "Epoch 21/1000\n",
            "4/4 - 1s - loss: 0.8661 - mse: 0.8208 - val_loss: 0.8482 - val_mse: 0.8482 - lr: 0.0010 - 691ms/epoch - 173ms/step\n",
            "Epoch 22/1000\n",
            "4/4 - 1s - loss: 0.8488 - mse: 0.8042 - val_loss: 0.8414 - val_mse: 0.8414 - lr: 0.0010 - 703ms/epoch - 176ms/step\n",
            "Epoch 23/1000\n",
            "4/4 - 1s - loss: 0.8409 - mse: 0.7965 - val_loss: 0.8355 - val_mse: 0.8355 - lr: 0.0010 - 698ms/epoch - 175ms/step\n",
            "Epoch 24/1000\n",
            "4/4 - 1s - loss: 0.8225 - mse: 0.7794 - val_loss: 0.8310 - val_mse: 0.8310 - lr: 0.0010 - 696ms/epoch - 174ms/step\n",
            "Epoch 25/1000\n",
            "4/4 - 1s - loss: 0.8151 - mse: 0.7722 - val_loss: 0.8248 - val_mse: 0.8248 - lr: 0.0010 - 683ms/epoch - 171ms/step\n",
            "Epoch 26/1000\n",
            "4/4 - 1s - loss: 0.7999 - mse: 0.7576 - val_loss: 0.8172 - val_mse: 0.8172 - lr: 0.0010 - 699ms/epoch - 175ms/step\n",
            "Epoch 27/1000\n",
            "4/4 - 1s - loss: 0.7944 - mse: 0.7526 - val_loss: 0.8105 - val_mse: 0.8105 - lr: 0.0010 - 677ms/epoch - 169ms/step\n",
            "Epoch 28/1000\n",
            "4/4 - 1s - loss: 0.7800 - mse: 0.7390 - val_loss: 0.8042 - val_mse: 0.8042 - lr: 0.0010 - 690ms/epoch - 172ms/step\n",
            "Epoch 29/1000\n",
            "4/4 - 1s - loss: 0.7758 - mse: 0.7349 - val_loss: 0.7976 - val_mse: 0.7976 - lr: 0.0010 - 693ms/epoch - 173ms/step\n",
            "Epoch 30/1000\n",
            "4/4 - 1s - loss: 0.7603 - mse: 0.7205 - val_loss: 0.7905 - val_mse: 0.7905 - lr: 0.0010 - 697ms/epoch - 174ms/step\n",
            "Epoch 31/1000\n",
            "4/4 - 1s - loss: 0.7548 - mse: 0.7153 - val_loss: 0.7832 - val_mse: 0.7832 - lr: 0.0010 - 699ms/epoch - 175ms/step\n",
            "Epoch 32/1000\n",
            "4/4 - 1s - loss: 0.7432 - mse: 0.7045 - val_loss: 0.7737 - val_mse: 0.7737 - lr: 0.0010 - 691ms/epoch - 173ms/step\n",
            "Epoch 33/1000\n",
            "4/4 - 1s - loss: 0.7357 - mse: 0.6972 - val_loss: 0.7644 - val_mse: 0.7644 - lr: 0.0010 - 681ms/epoch - 170ms/step\n",
            "Epoch 34/1000\n",
            "4/4 - 1s - loss: 0.7316 - mse: 0.6931 - val_loss: 0.7565 - val_mse: 0.7565 - lr: 0.0010 - 695ms/epoch - 174ms/step\n",
            "Epoch 35/1000\n",
            "4/4 - 1s - loss: 0.7239 - mse: 0.6856 - val_loss: 0.7502 - val_mse: 0.7502 - lr: 0.0010 - 702ms/epoch - 176ms/step\n",
            "Epoch 36/1000\n",
            "4/4 - 1s - loss: 0.7122 - mse: 0.6747 - val_loss: 0.7447 - val_mse: 0.7447 - lr: 0.0010 - 687ms/epoch - 172ms/step\n",
            "Epoch 37/1000\n",
            "4/4 - 1s - loss: 0.7070 - mse: 0.6701 - val_loss: 0.7378 - val_mse: 0.7378 - lr: 0.0010 - 688ms/epoch - 172ms/step\n",
            "Epoch 38/1000\n",
            "4/4 - 1s - loss: 0.7010 - mse: 0.6644 - val_loss: 0.7288 - val_mse: 0.7288 - lr: 0.0010 - 699ms/epoch - 175ms/step\n",
            "Epoch 39/1000\n",
            "4/4 - 1s - loss: 0.6927 - mse: 0.6562 - val_loss: 0.7202 - val_mse: 0.7202 - lr: 0.0010 - 709ms/epoch - 177ms/step\n",
            "Epoch 40/1000\n",
            "4/4 - 1s - loss: 0.6857 - mse: 0.6498 - val_loss: 0.7116 - val_mse: 0.7116 - lr: 0.0010 - 704ms/epoch - 176ms/step\n",
            "Epoch 41/1000\n",
            "4/4 - 1s - loss: 0.6759 - mse: 0.6403 - val_loss: 0.7045 - val_mse: 0.7045 - lr: 0.0010 - 703ms/epoch - 176ms/step\n",
            "Epoch 42/1000\n",
            "4/4 - 1s - loss: 0.6730 - mse: 0.6374 - val_loss: 0.6979 - val_mse: 0.6979 - lr: 0.0010 - 688ms/epoch - 172ms/step\n",
            "Epoch 43/1000\n",
            "4/4 - 1s - loss: 0.6648 - mse: 0.6298 - val_loss: 0.6883 - val_mse: 0.6883 - lr: 0.0010 - 702ms/epoch - 176ms/step\n",
            "Epoch 44/1000\n",
            "4/4 - 1s - loss: 0.6598 - mse: 0.6250 - val_loss: 0.6791 - val_mse: 0.6791 - lr: 0.0010 - 685ms/epoch - 171ms/step\n",
            "Epoch 45/1000\n",
            "4/4 - 1s - loss: 0.6544 - mse: 0.6199 - val_loss: 0.6718 - val_mse: 0.6718 - lr: 0.0010 - 695ms/epoch - 174ms/step\n",
            "Epoch 46/1000\n",
            "4/4 - 1s - loss: 0.6507 - mse: 0.6161 - val_loss: 0.6657 - val_mse: 0.6657 - lr: 0.0010 - 692ms/epoch - 173ms/step\n",
            "Epoch 47/1000\n",
            "4/4 - 1s - loss: 0.6414 - mse: 0.6073 - val_loss: 0.6594 - val_mse: 0.6594 - lr: 0.0010 - 702ms/epoch - 175ms/step\n",
            "Epoch 48/1000\n",
            "4/4 - 1s - loss: 0.6350 - mse: 0.6012 - val_loss: 0.6518 - val_mse: 0.6518 - lr: 0.0010 - 693ms/epoch - 173ms/step\n",
            "Epoch 49/1000\n",
            "4/4 - 1s - loss: 0.6323 - mse: 0.5986 - val_loss: 0.6425 - val_mse: 0.6425 - lr: 0.0010 - 692ms/epoch - 173ms/step\n",
            "Epoch 50/1000\n",
            "4/4 - 1s - loss: 0.6273 - mse: 0.5941 - val_loss: 0.6353 - val_mse: 0.6353 - lr: 0.0010 - 684ms/epoch - 171ms/step\n",
            "Epoch 51/1000\n",
            "4/4 - 1s - loss: 0.6209 - mse: 0.5878 - val_loss: 0.6295 - val_mse: 0.6295 - lr: 0.0010 - 688ms/epoch - 172ms/step\n",
            "Epoch 52/1000\n",
            "4/4 - 1s - loss: 0.6185 - mse: 0.5857 - val_loss: 0.6229 - val_mse: 0.6229 - lr: 0.0010 - 686ms/epoch - 171ms/step\n",
            "Epoch 53/1000\n",
            "4/4 - 1s - loss: 0.6111 - mse: 0.5785 - val_loss: 0.6158 - val_mse: 0.6158 - lr: 0.0010 - 683ms/epoch - 171ms/step\n",
            "Epoch 54/1000\n",
            "4/4 - 1s - loss: 0.6053 - mse: 0.5733 - val_loss: 0.6080 - val_mse: 0.6080 - lr: 0.0010 - 685ms/epoch - 171ms/step\n",
            "Epoch 55/1000\n",
            "4/4 - 1s - loss: 0.6008 - mse: 0.5690 - val_loss: 0.6003 - val_mse: 0.6003 - lr: 0.0010 - 687ms/epoch - 172ms/step\n",
            "Epoch 56/1000\n",
            "4/4 - 1s - loss: 0.5977 - mse: 0.5657 - val_loss: 0.5927 - val_mse: 0.5927 - lr: 0.0010 - 692ms/epoch - 173ms/step\n",
            "Epoch 57/1000\n",
            "4/4 - 1s - loss: 0.5924 - mse: 0.5609 - val_loss: 0.5864 - val_mse: 0.5864 - lr: 0.0010 - 697ms/epoch - 174ms/step\n",
            "Epoch 58/1000\n",
            "4/4 - 1s - loss: 0.5875 - mse: 0.5562 - val_loss: 0.5804 - val_mse: 0.5804 - lr: 0.0010 - 704ms/epoch - 176ms/step\n",
            "Epoch 59/1000\n",
            "4/4 - 1s - loss: 0.5834 - mse: 0.5523 - val_loss: 0.5742 - val_mse: 0.5742 - lr: 0.0010 - 679ms/epoch - 170ms/step\n",
            "Epoch 60/1000\n",
            "4/4 - 1s - loss: 0.5812 - mse: 0.5500 - val_loss: 0.5689 - val_mse: 0.5689 - lr: 0.0010 - 692ms/epoch - 173ms/step\n",
            "Epoch 61/1000\n",
            "4/4 - 1s - loss: 0.5739 - mse: 0.5433 - val_loss: 0.5630 - val_mse: 0.5630 - lr: 0.0010 - 691ms/epoch - 173ms/step\n",
            "Epoch 62/1000\n",
            "4/4 - 1s - loss: 0.5744 - mse: 0.5437 - val_loss: 0.5565 - val_mse: 0.5565 - lr: 0.0010 - 696ms/epoch - 174ms/step\n",
            "Epoch 63/1000\n",
            "4/4 - 1s - loss: 0.5699 - mse: 0.5393 - val_loss: 0.5492 - val_mse: 0.5492 - lr: 0.0010 - 697ms/epoch - 174ms/step\n",
            "Epoch 64/1000\n",
            "4/4 - 1s - loss: 0.5675 - mse: 0.5371 - val_loss: 0.5424 - val_mse: 0.5424 - lr: 0.0010 - 698ms/epoch - 175ms/step\n",
            "Epoch 65/1000\n",
            "4/4 - 1s - loss: 0.5593 - mse: 0.5292 - val_loss: 0.5369 - val_mse: 0.5369 - lr: 0.0010 - 702ms/epoch - 175ms/step\n",
            "Epoch 66/1000\n",
            "4/4 - 1s - loss: 0.5578 - mse: 0.5280 - val_loss: 0.5326 - val_mse: 0.5326 - lr: 0.0010 - 708ms/epoch - 177ms/step\n",
            "Epoch 67/1000\n",
            "4/4 - 1s - loss: 0.5538 - mse: 0.5237 - val_loss: 0.5284 - val_mse: 0.5284 - lr: 0.0010 - 694ms/epoch - 173ms/step\n",
            "Epoch 68/1000\n",
            "4/4 - 1s - loss: 0.5497 - mse: 0.5200 - val_loss: 0.5239 - val_mse: 0.5239 - lr: 0.0010 - 691ms/epoch - 173ms/step\n",
            "Epoch 69/1000\n",
            "4/4 - 1s - loss: 0.5465 - mse: 0.5172 - val_loss: 0.5185 - val_mse: 0.5185 - lr: 0.0010 - 698ms/epoch - 175ms/step\n",
            "Epoch 70/1000\n",
            "4/4 - 1s - loss: 0.5445 - mse: 0.5152 - val_loss: 0.5124 - val_mse: 0.5124 - lr: 0.0010 - 688ms/epoch - 172ms/step\n",
            "Epoch 71/1000\n",
            "4/4 - 1s - loss: 0.5402 - mse: 0.5112 - val_loss: 0.5072 - val_mse: 0.5072 - lr: 0.0010 - 681ms/epoch - 170ms/step\n",
            "Epoch 72/1000\n",
            "4/4 - 1s - loss: 0.5374 - mse: 0.5084 - val_loss: 0.5024 - val_mse: 0.5024 - lr: 0.0010 - 697ms/epoch - 174ms/step\n",
            "Epoch 73/1000\n",
            "4/4 - 1s - loss: 0.5349 - mse: 0.5060 - val_loss: 0.4981 - val_mse: 0.4981 - lr: 0.0010 - 698ms/epoch - 175ms/step\n",
            "Epoch 74/1000\n",
            "4/4 - 1s - loss: 0.5306 - mse: 0.5020 - val_loss: 0.4943 - val_mse: 0.4943 - lr: 0.0010 - 680ms/epoch - 170ms/step\n",
            "Epoch 75/1000\n",
            "4/4 - 1s - loss: 0.5263 - mse: 0.4979 - val_loss: 0.4901 - val_mse: 0.4901 - lr: 0.0010 - 695ms/epoch - 174ms/step\n",
            "Epoch 76/1000\n",
            "4/4 - 1s - loss: 0.5220 - mse: 0.4937 - val_loss: 0.4861 - val_mse: 0.4861 - lr: 0.0010 - 699ms/epoch - 175ms/step\n",
            "Epoch 77/1000\n",
            "4/4 - 1s - loss: 0.5215 - mse: 0.4933 - val_loss: 0.4812 - val_mse: 0.4812 - lr: 0.0010 - 690ms/epoch - 173ms/step\n",
            "Epoch 78/1000\n",
            "4/4 - 1s - loss: 0.5168 - mse: 0.4889 - val_loss: 0.4764 - val_mse: 0.4764 - lr: 0.0010 - 708ms/epoch - 177ms/step\n",
            "Epoch 79/1000\n",
            "4/4 - 1s - loss: 0.5164 - mse: 0.4885 - val_loss: 0.4726 - val_mse: 0.4726 - lr: 0.0010 - 724ms/epoch - 181ms/step\n",
            "Epoch 80/1000\n",
            "4/4 - 1s - loss: 0.5143 - mse: 0.4864 - val_loss: 0.4690 - val_mse: 0.4690 - lr: 0.0010 - 704ms/epoch - 176ms/step\n",
            "Epoch 81/1000\n",
            "4/4 - 1s - loss: 0.5120 - mse: 0.4842 - val_loss: 0.4651 - val_mse: 0.4651 - lr: 0.0010 - 703ms/epoch - 176ms/step\n",
            "Epoch 82/1000\n",
            "4/4 - 1s - loss: 0.5081 - mse: 0.4805 - val_loss: 0.4611 - val_mse: 0.4611 - lr: 0.0010 - 697ms/epoch - 174ms/step\n",
            "Epoch 83/1000\n",
            "4/4 - 1s - loss: 0.5060 - mse: 0.4786 - val_loss: 0.4572 - val_mse: 0.4572 - lr: 0.0010 - 709ms/epoch - 177ms/step\n",
            "Epoch 84/1000\n",
            "4/4 - 1s - loss: 0.5031 - mse: 0.4757 - val_loss: 0.4537 - val_mse: 0.4537 - lr: 0.0010 - 708ms/epoch - 177ms/step\n",
            "Epoch 85/1000\n",
            "4/4 - 1s - loss: 0.5025 - mse: 0.4750 - val_loss: 0.4500 - val_mse: 0.4500 - lr: 0.0010 - 700ms/epoch - 175ms/step\n",
            "Epoch 86/1000\n",
            "4/4 - 1s - loss: 0.4985 - mse: 0.4714 - val_loss: 0.4465 - val_mse: 0.4465 - lr: 0.0010 - 707ms/epoch - 177ms/step\n",
            "Epoch 87/1000\n",
            "4/4 - 1s - loss: 0.4965 - mse: 0.4694 - val_loss: 0.4433 - val_mse: 0.4433 - lr: 0.0010 - 699ms/epoch - 175ms/step\n",
            "Epoch 88/1000\n",
            "4/4 - 1s - loss: 0.4941 - mse: 0.4673 - val_loss: 0.4403 - val_mse: 0.4403 - lr: 0.0010 - 695ms/epoch - 174ms/step\n",
            "Epoch 89/1000\n",
            "4/4 - 1s - loss: 0.4924 - mse: 0.4656 - val_loss: 0.4377 - val_mse: 0.4377 - lr: 0.0010 - 702ms/epoch - 176ms/step\n",
            "Epoch 90/1000\n",
            "4/4 - 1s - loss: 0.4904 - mse: 0.4636 - val_loss: 0.4352 - val_mse: 0.4352 - lr: 0.0010 - 711ms/epoch - 178ms/step\n",
            "Epoch 91/1000\n",
            "4/4 - 1s - loss: 0.4905 - mse: 0.4637 - val_loss: 0.4328 - val_mse: 0.4328 - lr: 0.0010 - 715ms/epoch - 179ms/step\n",
            "Epoch 92/1000\n",
            "4/4 - 1s - loss: 0.4874 - mse: 0.4609 - val_loss: 0.4291 - val_mse: 0.4291 - lr: 0.0010 - 688ms/epoch - 172ms/step\n",
            "Epoch 93/1000\n",
            "4/4 - 1s - loss: 0.4843 - mse: 0.4577 - val_loss: 0.4254 - val_mse: 0.4254 - lr: 0.0010 - 720ms/epoch - 180ms/step\n",
            "Epoch 94/1000\n",
            "4/4 - 1s - loss: 0.4825 - mse: 0.4563 - val_loss: 0.4229 - val_mse: 0.4229 - lr: 0.0010 - 710ms/epoch - 178ms/step\n",
            "Epoch 95/1000\n",
            "4/4 - 1s - loss: 0.4811 - mse: 0.4548 - val_loss: 0.4215 - val_mse: 0.4215 - lr: 0.0010 - 713ms/epoch - 178ms/step\n",
            "Epoch 96/1000\n",
            "4/4 - 1s - loss: 0.4795 - mse: 0.4532 - val_loss: 0.4194 - val_mse: 0.4194 - lr: 0.0010 - 731ms/epoch - 183ms/step\n",
            "Epoch 97/1000\n",
            "4/4 - 1s - loss: 0.4784 - mse: 0.4521 - val_loss: 0.4173 - val_mse: 0.4173 - lr: 0.0010 - 719ms/epoch - 180ms/step\n",
            "Epoch 98/1000\n",
            "4/4 - 1s - loss: 0.4756 - mse: 0.4497 - val_loss: 0.4152 - val_mse: 0.4152 - lr: 0.0010 - 721ms/epoch - 180ms/step\n",
            "Epoch 99/1000\n",
            "4/4 - 1s - loss: 0.4754 - mse: 0.4494 - val_loss: 0.4128 - val_mse: 0.4128 - lr: 0.0010 - 718ms/epoch - 179ms/step\n",
            "Epoch 100/1000\n",
            "4/4 - 1s - loss: 0.4734 - mse: 0.4474 - val_loss: 0.4103 - val_mse: 0.4103 - lr: 0.0010 - 713ms/epoch - 178ms/step\n",
            "Epoch 101/1000\n",
            "4/4 - 1s - loss: 0.4710 - mse: 0.4453 - val_loss: 0.4078 - val_mse: 0.4078 - lr: 0.0010 - 724ms/epoch - 181ms/step\n",
            "Epoch 102/1000\n",
            "4/4 - 1s - loss: 0.4700 - mse: 0.4442 - val_loss: 0.4056 - val_mse: 0.4056 - lr: 0.0010 - 694ms/epoch - 173ms/step\n",
            "Epoch 103/1000\n",
            "4/4 - 1s - loss: 0.4683 - mse: 0.4427 - val_loss: 0.4041 - val_mse: 0.4041 - lr: 0.0010 - 696ms/epoch - 174ms/step\n",
            "Epoch 104/1000\n",
            "4/4 - 1s - loss: 0.4669 - mse: 0.4411 - val_loss: 0.4021 - val_mse: 0.4021 - lr: 0.0010 - 714ms/epoch - 178ms/step\n",
            "Epoch 105/1000\n",
            "4/4 - 1s - loss: 0.4655 - mse: 0.4398 - val_loss: 0.4006 - val_mse: 0.4006 - lr: 0.0010 - 724ms/epoch - 181ms/step\n",
            "Epoch 106/1000\n",
            "4/4 - 1s - loss: 0.4641 - mse: 0.4386 - val_loss: 0.3996 - val_mse: 0.3996 - lr: 0.0010 - 710ms/epoch - 177ms/step\n",
            "Epoch 107/1000\n",
            "4/4 - 1s - loss: 0.4624 - mse: 0.4371 - val_loss: 0.3980 - val_mse: 0.3980 - lr: 0.0010 - 700ms/epoch - 175ms/step\n",
            "Epoch 108/1000\n",
            "4/4 - 1s - loss: 0.4614 - mse: 0.4359 - val_loss: 0.3960 - val_mse: 0.3960 - lr: 0.0010 - 687ms/epoch - 172ms/step\n",
            "Epoch 109/1000\n",
            "4/4 - 1s - loss: 0.4599 - mse: 0.4345 - val_loss: 0.3944 - val_mse: 0.3944 - lr: 0.0010 - 706ms/epoch - 177ms/step\n",
            "Epoch 110/1000\n",
            "4/4 - 1s - loss: 0.4577 - mse: 0.4326 - val_loss: 0.3930 - val_mse: 0.3930 - lr: 0.0010 - 704ms/epoch - 176ms/step\n",
            "Epoch 111/1000\n",
            "4/4 - 1s - loss: 0.4559 - mse: 0.4307 - val_loss: 0.3912 - val_mse: 0.3912 - lr: 0.0010 - 699ms/epoch - 175ms/step\n",
            "Epoch 112/1000\n",
            "4/4 - 1s - loss: 0.4556 - mse: 0.4304 - val_loss: 0.3899 - val_mse: 0.3899 - lr: 0.0010 - 701ms/epoch - 175ms/step\n",
            "Epoch 113/1000\n",
            "4/4 - 1s - loss: 0.4535 - mse: 0.4286 - val_loss: 0.3890 - val_mse: 0.3890 - lr: 0.0010 - 692ms/epoch - 173ms/step\n",
            "Epoch 114/1000\n",
            "4/4 - 1s - loss: 0.4527 - mse: 0.4278 - val_loss: 0.3884 - val_mse: 0.3884 - lr: 0.0010 - 691ms/epoch - 173ms/step\n",
            "Epoch 115/1000\n",
            "4/4 - 1s - loss: 0.4530 - mse: 0.4280 - val_loss: 0.3876 - val_mse: 0.3876 - lr: 0.0010 - 699ms/epoch - 175ms/step\n",
            "Epoch 116/1000\n",
            "4/4 - 1s - loss: 0.4510 - mse: 0.4260 - val_loss: 0.3860 - val_mse: 0.3860 - lr: 0.0010 - 703ms/epoch - 176ms/step\n",
            "Epoch 117/1000\n",
            "4/4 - 1s - loss: 0.4500 - mse: 0.4252 - val_loss: 0.3847 - val_mse: 0.3847 - lr: 0.0010 - 696ms/epoch - 174ms/step\n",
            "Epoch 118/1000\n",
            "4/4 - 1s - loss: 0.4480 - mse: 0.4232 - val_loss: 0.3835 - val_mse: 0.3835 - lr: 0.0010 - 703ms/epoch - 176ms/step\n",
            "Epoch 119/1000\n",
            "4/4 - 1s - loss: 0.4473 - mse: 0.4225 - val_loss: 0.3826 - val_mse: 0.3826 - lr: 0.0010 - 693ms/epoch - 173ms/step\n",
            "Epoch 120/1000\n",
            "4/4 - 1s - loss: 0.4459 - mse: 0.4214 - val_loss: 0.3818 - val_mse: 0.3818 - lr: 0.0010 - 693ms/epoch - 173ms/step\n",
            "Epoch 121/1000\n",
            "4/4 - 1s - loss: 0.4445 - mse: 0.4200 - val_loss: 0.3812 - val_mse: 0.3812 - lr: 0.0010 - 703ms/epoch - 176ms/step\n",
            "Epoch 122/1000\n",
            "4/4 - 1s - loss: 0.4443 - mse: 0.4198 - val_loss: 0.3805 - val_mse: 0.3805 - lr: 0.0010 - 694ms/epoch - 174ms/step\n",
            "Epoch 123/1000\n",
            "4/4 - 1s - loss: 0.4431 - mse: 0.4188 - val_loss: 0.3798 - val_mse: 0.3798 - lr: 0.0010 - 679ms/epoch - 170ms/step\n",
            "Epoch 124/1000\n",
            "4/4 - 1s - loss: 0.4428 - mse: 0.4184 - val_loss: 0.3789 - val_mse: 0.3789 - lr: 0.0010 - 701ms/epoch - 175ms/step\n",
            "Epoch 125/1000\n",
            "4/4 - 1s - loss: 0.4417 - mse: 0.4173 - val_loss: 0.3777 - val_mse: 0.3777 - lr: 0.0010 - 698ms/epoch - 174ms/step\n",
            "Epoch 126/1000\n",
            "4/4 - 1s - loss: 0.4399 - mse: 0.4155 - val_loss: 0.3768 - val_mse: 0.3768 - lr: 0.0010 - 707ms/epoch - 177ms/step\n",
            "Epoch 127/1000\n",
            "4/4 - 1s - loss: 0.4392 - mse: 0.4148 - val_loss: 0.3762 - val_mse: 0.3762 - lr: 0.0010 - 694ms/epoch - 173ms/step\n",
            "Epoch 128/1000\n",
            "4/4 - 1s - loss: 0.4399 - mse: 0.4154 - val_loss: 0.3759 - val_mse: 0.3759 - lr: 0.0010 - 696ms/epoch - 174ms/step\n",
            "Epoch 129/1000\n",
            "4/4 - 1s - loss: 0.4381 - mse: 0.4139 - val_loss: 0.3754 - val_mse: 0.3754 - lr: 0.0010 - 703ms/epoch - 176ms/step\n",
            "Epoch 130/1000\n",
            "4/4 - 1s - loss: 0.4365 - mse: 0.4124 - val_loss: 0.3748 - val_mse: 0.3748 - lr: 0.0010 - 700ms/epoch - 175ms/step\n",
            "Epoch 131/1000\n",
            "4/4 - 1s - loss: 0.4371 - mse: 0.4128 - val_loss: 0.3743 - val_mse: 0.3743 - lr: 0.0010 - 687ms/epoch - 172ms/step\n",
            "Epoch 132/1000\n",
            "4/4 - 1s - loss: 0.4354 - mse: 0.4112 - val_loss: 0.3739 - val_mse: 0.3739 - lr: 0.0010 - 691ms/epoch - 173ms/step\n",
            "Epoch 133/1000\n",
            "4/4 - 1s - loss: 0.4344 - mse: 0.4104 - val_loss: 0.3735 - val_mse: 0.3735 - lr: 0.0010 - 703ms/epoch - 176ms/step\n",
            "Epoch 134/1000\n",
            "4/4 - 1s - loss: 0.4340 - mse: 0.4099 - val_loss: 0.3731 - val_mse: 0.3731 - lr: 0.0010 - 696ms/epoch - 174ms/step\n",
            "Epoch 135/1000\n",
            "4/4 - 1s - loss: 0.4321 - mse: 0.4082 - val_loss: 0.3728 - val_mse: 0.3728 - lr: 0.0010 - 687ms/epoch - 172ms/step\n",
            "Epoch 136/1000\n",
            "4/4 - 1s - loss: 0.4315 - mse: 0.4076 - val_loss: 0.3726 - val_mse: 0.3726 - lr: 0.0010 - 686ms/epoch - 172ms/step\n",
            "Epoch 137/1000\n",
            "4/4 - 1s - loss: 0.4304 - mse: 0.4066 - val_loss: 0.3723 - val_mse: 0.3723 - lr: 0.0010 - 701ms/epoch - 175ms/step\n",
            "Epoch 138/1000\n",
            "4/4 - 1s - loss: 0.4319 - mse: 0.4081 - val_loss: 0.3718 - val_mse: 0.3718 - lr: 0.0010 - 705ms/epoch - 176ms/step\n",
            "Epoch 139/1000\n",
            "4/4 - 1s - loss: 0.4294 - mse: 0.4055 - val_loss: 0.3715 - val_mse: 0.3715 - lr: 0.0010 - 694ms/epoch - 173ms/step\n",
            "Epoch 140/1000\n",
            "4/4 - 1s - loss: 0.4283 - mse: 0.4044 - val_loss: 0.3713 - val_mse: 0.3713 - lr: 0.0010 - 698ms/epoch - 174ms/step\n",
            "Epoch 141/1000\n",
            "4/4 - 1s - loss: 0.4296 - mse: 0.4057 - val_loss: 0.3711 - val_mse: 0.3711 - lr: 0.0010 - 701ms/epoch - 175ms/step\n",
            "Epoch 142/1000\n",
            "4/4 - 1s - loss: 0.4279 - mse: 0.4043 - val_loss: 0.3709 - val_mse: 0.3709 - lr: 0.0010 - 724ms/epoch - 181ms/step\n",
            "Epoch 143/1000\n",
            "4/4 - 1s - loss: 0.4269 - mse: 0.4032 - val_loss: 0.3706 - val_mse: 0.3706 - lr: 0.0010 - 720ms/epoch - 180ms/step\n",
            "Epoch 144/1000\n",
            "4/4 - 1s - loss: 0.4266 - mse: 0.4029 - val_loss: 0.3705 - val_mse: 0.3705 - lr: 0.0010 - 700ms/epoch - 175ms/step\n",
            "Epoch 145/1000\n",
            "4/4 - 1s - loss: 0.4253 - mse: 0.4016 - val_loss: 0.3704 - val_mse: 0.3704 - lr: 0.0010 - 695ms/epoch - 174ms/step\n",
            "Epoch 146/1000\n",
            "4/4 - 1s - loss: 0.4247 - mse: 0.4012 - val_loss: 0.3705 - val_mse: 0.3705 - lr: 0.0010 - 697ms/epoch - 174ms/step\n",
            "Epoch 147/1000\n",
            "4/4 - 1s - loss: 0.4249 - mse: 0.4013 - val_loss: 0.3703 - val_mse: 0.3703 - lr: 0.0010 - 710ms/epoch - 178ms/step\n",
            "Epoch 148/1000\n",
            "4/4 - 1s - loss: 0.4240 - mse: 0.4004 - val_loss: 0.3701 - val_mse: 0.3701 - lr: 0.0010 - 677ms/epoch - 169ms/step\n",
            "Epoch 149/1000\n",
            "4/4 - 1s - loss: 0.4231 - mse: 0.3996 - val_loss: 0.3698 - val_mse: 0.3698 - lr: 0.0010 - 690ms/epoch - 172ms/step\n",
            "Epoch 150/1000\n",
            "4/4 - 1s - loss: 0.4228 - mse: 0.3993 - val_loss: 0.3696 - val_mse: 0.3696 - lr: 0.0010 - 703ms/epoch - 176ms/step\n",
            "Epoch 151/1000\n",
            "4/4 - 1s - loss: 0.4230 - mse: 0.3995 - val_loss: 0.3695 - val_mse: 0.3695 - lr: 0.0010 - 678ms/epoch - 169ms/step\n",
            "Epoch 152/1000\n",
            "4/4 - 1s - loss: 0.4225 - mse: 0.3990 - val_loss: 0.3695 - val_mse: 0.3695 - lr: 0.0010 - 700ms/epoch - 175ms/step\n",
            "Epoch 153/1000\n",
            "4/4 - 1s - loss: 0.4212 - mse: 0.3979 - val_loss: 0.3695 - val_mse: 0.3695 - lr: 0.0010 - 695ms/epoch - 174ms/step\n",
            "Epoch 154/1000\n",
            "4/4 - 1s - loss: 0.4202 - mse: 0.3969 - val_loss: 0.3692 - val_mse: 0.3692 - lr: 0.0010 - 691ms/epoch - 173ms/step\n",
            "Epoch 155/1000\n",
            "4/4 - 1s - loss: 0.4199 - mse: 0.3966 - val_loss: 0.3690 - val_mse: 0.3690 - lr: 0.0010 - 676ms/epoch - 169ms/step\n",
            "Epoch 156/1000\n",
            "4/4 - 1s - loss: 0.4201 - mse: 0.3968 - val_loss: 0.3689 - val_mse: 0.3689 - lr: 0.0010 - 689ms/epoch - 172ms/step\n",
            "Epoch 157/1000\n",
            "4/4 - 1s - loss: 0.4190 - mse: 0.3957 - val_loss: 0.3689 - val_mse: 0.3689 - lr: 0.0010 - 686ms/epoch - 172ms/step\n",
            "Epoch 158/1000\n",
            "4/4 - 1s - loss: 0.4192 - mse: 0.3959 - val_loss: 0.3688 - val_mse: 0.3688 - lr: 0.0010 - 695ms/epoch - 174ms/step\n",
            "Epoch 159/1000\n",
            "4/4 - 1s - loss: 0.4182 - mse: 0.3950 - val_loss: 0.3689 - val_mse: 0.3689 - lr: 0.0010 - 695ms/epoch - 174ms/step\n",
            "Epoch 160/1000\n",
            "4/4 - 1s - loss: 0.4180 - mse: 0.3947 - val_loss: 0.3688 - val_mse: 0.3688 - lr: 0.0010 - 694ms/epoch - 173ms/step\n",
            "Epoch 161/1000\n",
            "4/4 - 1s - loss: 0.4169 - mse: 0.3938 - val_loss: 0.3688 - val_mse: 0.3688 - lr: 0.0010 - 697ms/epoch - 174ms/step\n",
            "Epoch 162/1000\n",
            "4/4 - 1s - loss: 0.4172 - mse: 0.3940 - val_loss: 0.3689 - val_mse: 0.3689 - lr: 0.0010 - 693ms/epoch - 173ms/step\n",
            "Epoch 163/1000\n",
            "4/4 - 1s - loss: 0.4169 - mse: 0.3938 - val_loss: 0.3688 - val_mse: 0.3688 - lr: 0.0010 - 708ms/epoch - 177ms/step\n",
            "Epoch 164/1000\n",
            "4/4 - 1s - loss: 0.4156 - mse: 0.3926 - val_loss: 0.3687 - val_mse: 0.3687 - lr: 0.0010 - 699ms/epoch - 175ms/step\n",
            "Epoch 165/1000\n",
            "4/4 - 1s - loss: 0.4150 - mse: 0.3921 - val_loss: 0.3687 - val_mse: 0.3687 - lr: 0.0010 - 702ms/epoch - 176ms/step\n",
            "Epoch 166/1000\n",
            "4/4 - 1s - loss: 0.4155 - mse: 0.3923 - val_loss: 0.3687 - val_mse: 0.3687 - lr: 0.0010 - 699ms/epoch - 175ms/step\n",
            "Epoch 167/1000\n",
            "4/4 - 1s - loss: 0.4138 - mse: 0.3908 - val_loss: 0.3687 - val_mse: 0.3687 - lr: 0.0010 - 688ms/epoch - 172ms/step\n",
            "Epoch 168/1000\n",
            "4/4 - 1s - loss: 0.4150 - mse: 0.3918 - val_loss: 0.3685 - val_mse: 0.3685 - lr: 0.0010 - 701ms/epoch - 175ms/step\n",
            "Epoch 169/1000\n",
            "4/4 - 1s - loss: 0.4141 - mse: 0.3912 - val_loss: 0.3684 - val_mse: 0.3684 - lr: 0.0010 - 695ms/epoch - 174ms/step\n",
            "Epoch 170/1000\n",
            "4/4 - 1s - loss: 0.4139 - mse: 0.3910 - val_loss: 0.3683 - val_mse: 0.3683 - lr: 0.0010 - 690ms/epoch - 173ms/step\n",
            "Epoch 171/1000\n",
            "4/4 - 1s - loss: 0.4133 - mse: 0.3903 - val_loss: 0.3683 - val_mse: 0.3683 - lr: 0.0010 - 702ms/epoch - 175ms/step\n",
            "Epoch 172/1000\n",
            "4/4 - 1s - loss: 0.4122 - mse: 0.3895 - val_loss: 0.3683 - val_mse: 0.3683 - lr: 0.0010 - 691ms/epoch - 173ms/step\n",
            "Epoch 173/1000\n",
            "4/4 - 1s - loss: 0.4126 - mse: 0.3896 - val_loss: 0.3682 - val_mse: 0.3682 - lr: 0.0010 - 682ms/epoch - 171ms/step\n",
            "Epoch 174/1000\n",
            "4/4 - 1s - loss: 0.4124 - mse: 0.3896 - val_loss: 0.3682 - val_mse: 0.3682 - lr: 0.0010 - 677ms/epoch - 169ms/step\n",
            "Epoch 175/1000\n",
            "4/4 - 1s - loss: 0.4114 - mse: 0.3884 - val_loss: 0.3681 - val_mse: 0.3681 - lr: 0.0010 - 706ms/epoch - 177ms/step\n",
            "Epoch 176/1000\n",
            "4/4 - 1s - loss: 0.4122 - mse: 0.3894 - val_loss: 0.3682 - val_mse: 0.3682 - lr: 0.0010 - 690ms/epoch - 173ms/step\n",
            "Epoch 177/1000\n",
            "4/4 - 1s - loss: 0.4115 - mse: 0.3887 - val_loss: 0.3681 - val_mse: 0.3681 - lr: 0.0010 - 694ms/epoch - 174ms/step\n",
            "Epoch 178/1000\n",
            "4/4 - 1s - loss: 0.4103 - mse: 0.3875 - val_loss: 0.3683 - val_mse: 0.3683 - lr: 0.0010 - 681ms/epoch - 170ms/step\n",
            "Epoch 179/1000\n",
            "4/4 - 1s - loss: 0.4110 - mse: 0.3882 - val_loss: 0.3682 - val_mse: 0.3682 - lr: 0.0010 - 704ms/epoch - 176ms/step\n",
            "Epoch 180/1000\n",
            "4/4 - 1s - loss: 0.4094 - mse: 0.3866 - val_loss: 0.3683 - val_mse: 0.3683 - lr: 0.0010 - 690ms/epoch - 172ms/step\n",
            "Epoch 181/1000\n",
            "4/4 - 1s - loss: 0.4090 - mse: 0.3863 - val_loss: 0.3684 - val_mse: 0.3684 - lr: 0.0010 - 698ms/epoch - 174ms/step\n",
            "Epoch 182/1000\n",
            "\n",
            "Epoch 182: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "4/4 - 1s - loss: 0.4096 - mse: 0.3869 - val_loss: 0.3686 - val_mse: 0.3686 - lr: 0.0010 - 681ms/epoch - 170ms/step\n",
            "Epoch 183/1000\n",
            "4/4 - 1s - loss: 0.4091 - mse: 0.3865 - val_loss: 0.3686 - val_mse: 0.3686 - lr: 1.0000e-04 - 687ms/epoch - 172ms/step\n",
            "Epoch 184/1000\n",
            "4/4 - 1s - loss: 0.4094 - mse: 0.3867 - val_loss: 0.3686 - val_mse: 0.3686 - lr: 1.0000e-04 - 696ms/epoch - 174ms/step\n",
            "Epoch 185/1000\n",
            "4/4 - 1s - loss: 0.4098 - mse: 0.3870 - val_loss: 0.3685 - val_mse: 0.3685 - lr: 1.0000e-04 - 699ms/epoch - 175ms/step\n",
            "Epoch 185: early stopping\n",
            "==================================================\n",
            "Step 4\n",
            "==================================================\n",
            "Epoch 1/1000\n",
            "4/4 - 4s - loss: 2.5739 - mse: 2.4010 - val_loss: 1.0321 - val_mse: 1.0321 - lr: 0.0010 - 4s/epoch - 1s/step\n",
            "Epoch 2/1000\n",
            "4/4 - 1s - loss: 1.8331 - mse: 1.7122 - val_loss: 1.0396 - val_mse: 1.0396 - lr: 0.0010 - 697ms/epoch - 174ms/step\n",
            "Epoch 3/1000\n",
            "4/4 - 1s - loss: 1.4965 - mse: 1.3940 - val_loss: 1.0428 - val_mse: 1.0428 - lr: 0.0010 - 675ms/epoch - 169ms/step\n",
            "Epoch 4/1000\n",
            "4/4 - 1s - loss: 1.3278 - mse: 1.2356 - val_loss: 1.0230 - val_mse: 1.0230 - lr: 0.0010 - 686ms/epoch - 172ms/step\n",
            "Epoch 5/1000\n",
            "4/4 - 1s - loss: 1.2032 - mse: 1.1208 - val_loss: 0.9929 - val_mse: 0.9929 - lr: 0.0010 - 694ms/epoch - 174ms/step\n",
            "Epoch 6/1000\n",
            "4/4 - 1s - loss: 1.1231 - mse: 1.0468 - val_loss: 0.9676 - val_mse: 0.9676 - lr: 0.0010 - 688ms/epoch - 172ms/step\n",
            "Epoch 7/1000\n",
            "4/4 - 1s - loss: 1.0635 - mse: 0.9911 - val_loss: 0.9486 - val_mse: 0.9486 - lr: 0.0010 - 697ms/epoch - 174ms/step\n",
            "Epoch 8/1000\n",
            "4/4 - 1s - loss: 1.0202 - mse: 0.9512 - val_loss: 0.9332 - val_mse: 0.9332 - lr: 0.0010 - 686ms/epoch - 172ms/step\n",
            "Epoch 9/1000\n",
            "4/4 - 1s - loss: 0.9898 - mse: 0.9232 - val_loss: 0.9204 - val_mse: 0.9204 - lr: 0.0010 - 680ms/epoch - 170ms/step\n",
            "Epoch 10/1000\n",
            "4/4 - 1s - loss: 0.9598 - mse: 0.8952 - val_loss: 0.9115 - val_mse: 0.9115 - lr: 0.0010 - 678ms/epoch - 169ms/step\n",
            "Epoch 11/1000\n",
            "4/4 - 1s - loss: 0.9365 - mse: 0.8729 - val_loss: 0.9052 - val_mse: 0.9052 - lr: 0.0010 - 682ms/epoch - 171ms/step\n",
            "Epoch 12/1000\n",
            "4/4 - 1s - loss: 0.9166 - mse: 0.8555 - val_loss: 0.8973 - val_mse: 0.8973 - lr: 0.0010 - 689ms/epoch - 172ms/step\n",
            "Epoch 13/1000\n",
            "4/4 - 1s - loss: 0.8951 - mse: 0.8350 - val_loss: 0.8873 - val_mse: 0.8873 - lr: 0.0010 - 685ms/epoch - 171ms/step\n",
            "Epoch 14/1000\n",
            "4/4 - 1s - loss: 0.8748 - mse: 0.8166 - val_loss: 0.8761 - val_mse: 0.8761 - lr: 0.0010 - 688ms/epoch - 172ms/step\n",
            "Epoch 15/1000\n",
            "4/4 - 1s - loss: 0.8657 - mse: 0.8080 - val_loss: 0.8655 - val_mse: 0.8655 - lr: 0.0010 - 685ms/epoch - 171ms/step\n",
            "Epoch 16/1000\n",
            "4/4 - 1s - loss: 0.8512 - mse: 0.7948 - val_loss: 0.8584 - val_mse: 0.8584 - lr: 0.0010 - 677ms/epoch - 169ms/step\n",
            "Epoch 17/1000\n",
            "4/4 - 1s - loss: 0.8374 - mse: 0.7824 - val_loss: 0.8538 - val_mse: 0.8538 - lr: 0.0010 - 689ms/epoch - 172ms/step\n",
            "Epoch 18/1000\n",
            "4/4 - 1s - loss: 0.8212 - mse: 0.7669 - val_loss: 0.8486 - val_mse: 0.8486 - lr: 0.0010 - 681ms/epoch - 170ms/step\n",
            "Epoch 19/1000\n",
            "4/4 - 1s - loss: 0.8091 - mse: 0.7557 - val_loss: 0.8415 - val_mse: 0.8415 - lr: 0.0010 - 686ms/epoch - 172ms/step\n",
            "Epoch 20/1000\n",
            "4/4 - 1s - loss: 0.7988 - mse: 0.7468 - val_loss: 0.8338 - val_mse: 0.8338 - lr: 0.0010 - 686ms/epoch - 171ms/step\n",
            "Epoch 21/1000\n",
            "4/4 - 1s - loss: 0.7869 - mse: 0.7360 - val_loss: 0.8271 - val_mse: 0.8271 - lr: 0.0010 - 687ms/epoch - 172ms/step\n",
            "Epoch 22/1000\n",
            "4/4 - 1s - loss: 0.7755 - mse: 0.7253 - val_loss: 0.8210 - val_mse: 0.8210 - lr: 0.0010 - 687ms/epoch - 172ms/step\n",
            "Epoch 23/1000\n",
            "4/4 - 1s - loss: 0.7659 - mse: 0.7165 - val_loss: 0.8149 - val_mse: 0.8149 - lr: 0.0010 - 690ms/epoch - 172ms/step\n",
            "Epoch 24/1000\n",
            "4/4 - 1s - loss: 0.7547 - mse: 0.7061 - val_loss: 0.8089 - val_mse: 0.8089 - lr: 0.0010 - 691ms/epoch - 173ms/step\n",
            "Epoch 25/1000\n",
            "4/4 - 1s - loss: 0.7457 - mse: 0.6981 - val_loss: 0.8025 - val_mse: 0.8025 - lr: 0.0010 - 679ms/epoch - 170ms/step\n",
            "Epoch 26/1000\n",
            "4/4 - 1s - loss: 0.7315 - mse: 0.6852 - val_loss: 0.7962 - val_mse: 0.7962 - lr: 0.0010 - 695ms/epoch - 174ms/step\n",
            "Epoch 27/1000\n",
            "4/4 - 1s - loss: 0.7256 - mse: 0.6798 - val_loss: 0.7912 - val_mse: 0.7912 - lr: 0.0010 - 688ms/epoch - 172ms/step\n",
            "Epoch 28/1000\n",
            "4/4 - 1s - loss: 0.7148 - mse: 0.6702 - val_loss: 0.7858 - val_mse: 0.7858 - lr: 0.0010 - 684ms/epoch - 171ms/step\n",
            "Epoch 29/1000\n",
            "4/4 - 1s - loss: 0.7073 - mse: 0.6634 - val_loss: 0.7791 - val_mse: 0.7791 - lr: 0.0010 - 691ms/epoch - 173ms/step\n",
            "Epoch 30/1000\n",
            "4/4 - 1s - loss: 0.7030 - mse: 0.6593 - val_loss: 0.7725 - val_mse: 0.7725 - lr: 0.0010 - 698ms/epoch - 175ms/step\n",
            "Epoch 31/1000\n",
            "4/4 - 1s - loss: 0.6929 - mse: 0.6501 - val_loss: 0.7660 - val_mse: 0.7660 - lr: 0.0010 - 693ms/epoch - 173ms/step\n",
            "Epoch 32/1000\n",
            "4/4 - 1s - loss: 0.6830 - mse: 0.6410 - val_loss: 0.7598 - val_mse: 0.7598 - lr: 0.0010 - 689ms/epoch - 172ms/step\n",
            "Epoch 33/1000\n",
            "4/4 - 1s - loss: 0.6770 - mse: 0.6353 - val_loss: 0.7540 - val_mse: 0.7540 - lr: 0.0010 - 686ms/epoch - 172ms/step\n",
            "Epoch 34/1000\n",
            "4/4 - 1s - loss: 0.6718 - mse: 0.6309 - val_loss: 0.7485 - val_mse: 0.7485 - lr: 0.0010 - 698ms/epoch - 175ms/step\n",
            "Epoch 35/1000\n",
            "4/4 - 1s - loss: 0.6659 - mse: 0.6256 - val_loss: 0.7445 - val_mse: 0.7445 - lr: 0.0010 - 703ms/epoch - 176ms/step\n",
            "Epoch 36/1000\n",
            "4/4 - 1s - loss: 0.6575 - mse: 0.6177 - val_loss: 0.7414 - val_mse: 0.7414 - lr: 0.0010 - 689ms/epoch - 172ms/step\n",
            "Epoch 37/1000\n",
            "4/4 - 1s - loss: 0.6539 - mse: 0.6145 - val_loss: 0.7366 - val_mse: 0.7366 - lr: 0.0010 - 688ms/epoch - 172ms/step\n",
            "Epoch 38/1000\n",
            "4/4 - 1s - loss: 0.6449 - mse: 0.6065 - val_loss: 0.7301 - val_mse: 0.7301 - lr: 0.0010 - 691ms/epoch - 173ms/step\n",
            "Epoch 39/1000\n",
            "4/4 - 1s - loss: 0.6416 - mse: 0.6030 - val_loss: 0.7244 - val_mse: 0.7244 - lr: 0.0010 - 685ms/epoch - 171ms/step\n",
            "Epoch 40/1000\n",
            "4/4 - 1s - loss: 0.6357 - mse: 0.5977 - val_loss: 0.7195 - val_mse: 0.7195 - lr: 0.0010 - 676ms/epoch - 169ms/step\n",
            "Epoch 41/1000\n",
            "4/4 - 1s - loss: 0.6283 - mse: 0.5909 - val_loss: 0.7146 - val_mse: 0.7146 - lr: 0.0010 - 687ms/epoch - 172ms/step\n",
            "Epoch 42/1000\n",
            "4/4 - 1s - loss: 0.6232 - mse: 0.5860 - val_loss: 0.7099 - val_mse: 0.7099 - lr: 0.0010 - 687ms/epoch - 172ms/step\n",
            "Epoch 43/1000\n",
            "4/4 - 1s - loss: 0.6177 - mse: 0.5812 - val_loss: 0.7048 - val_mse: 0.7048 - lr: 0.0010 - 683ms/epoch - 171ms/step\n",
            "Epoch 44/1000\n",
            "4/4 - 1s - loss: 0.6136 - mse: 0.5774 - val_loss: 0.6989 - val_mse: 0.6989 - lr: 0.0010 - 689ms/epoch - 172ms/step\n",
            "Epoch 45/1000\n",
            "4/4 - 1s - loss: 0.6068 - mse: 0.5709 - val_loss: 0.6946 - val_mse: 0.6946 - lr: 0.0010 - 695ms/epoch - 174ms/step\n",
            "Epoch 46/1000\n",
            "4/4 - 1s - loss: 0.6028 - mse: 0.5678 - val_loss: 0.6905 - val_mse: 0.6905 - lr: 0.0010 - 672ms/epoch - 168ms/step\n",
            "Epoch 47/1000\n",
            "4/4 - 1s - loss: 0.5978 - mse: 0.5629 - val_loss: 0.6853 - val_mse: 0.6853 - lr: 0.0010 - 700ms/epoch - 175ms/step\n",
            "Epoch 48/1000\n",
            "4/4 - 1s - loss: 0.5941 - mse: 0.5597 - val_loss: 0.6797 - val_mse: 0.6797 - lr: 0.0010 - 685ms/epoch - 171ms/step\n",
            "Epoch 49/1000\n",
            "4/4 - 1s - loss: 0.5899 - mse: 0.5557 - val_loss: 0.6743 - val_mse: 0.6743 - lr: 0.0010 - 685ms/epoch - 171ms/step\n",
            "Epoch 50/1000\n",
            "4/4 - 1s - loss: 0.5849 - mse: 0.5509 - val_loss: 0.6690 - val_mse: 0.6690 - lr: 0.0010 - 669ms/epoch - 167ms/step\n",
            "Epoch 51/1000\n",
            "4/4 - 1s - loss: 0.5783 - mse: 0.5449 - val_loss: 0.6652 - val_mse: 0.6652 - lr: 0.0010 - 691ms/epoch - 173ms/step\n",
            "Epoch 52/1000\n",
            "4/4 - 1s - loss: 0.5743 - mse: 0.5415 - val_loss: 0.6612 - val_mse: 0.6612 - lr: 0.0010 - 684ms/epoch - 171ms/step\n",
            "Epoch 53/1000\n",
            "4/4 - 1s - loss: 0.5709 - mse: 0.5383 - val_loss: 0.6558 - val_mse: 0.6558 - lr: 0.0010 - 686ms/epoch - 171ms/step\n",
            "Epoch 54/1000\n",
            "4/4 - 1s - loss: 0.5663 - mse: 0.5340 - val_loss: 0.6503 - val_mse: 0.6503 - lr: 0.0010 - 675ms/epoch - 169ms/step\n",
            "Epoch 55/1000\n",
            "4/4 - 1s - loss: 0.5602 - mse: 0.5281 - val_loss: 0.6448 - val_mse: 0.6448 - lr: 0.0010 - 673ms/epoch - 168ms/step\n",
            "Epoch 56/1000\n",
            "4/4 - 1s - loss: 0.5610 - mse: 0.5290 - val_loss: 0.6391 - val_mse: 0.6391 - lr: 0.0010 - 673ms/epoch - 168ms/step\n",
            "Epoch 57/1000\n",
            "4/4 - 1s - loss: 0.5578 - mse: 0.5260 - val_loss: 0.6330 - val_mse: 0.6330 - lr: 0.0010 - 685ms/epoch - 171ms/step\n",
            "Epoch 58/1000\n",
            "4/4 - 1s - loss: 0.5521 - mse: 0.5208 - val_loss: 0.6269 - val_mse: 0.6269 - lr: 0.0010 - 667ms/epoch - 167ms/step\n",
            "Epoch 59/1000\n",
            "4/4 - 1s - loss: 0.5481 - mse: 0.5169 - val_loss: 0.6228 - val_mse: 0.6228 - lr: 0.0010 - 693ms/epoch - 173ms/step\n",
            "Epoch 60/1000\n",
            "4/4 - 1s - loss: 0.5458 - mse: 0.5149 - val_loss: 0.6191 - val_mse: 0.6191 - lr: 0.0010 - 699ms/epoch - 175ms/step\n",
            "Epoch 61/1000\n",
            "4/4 - 1s - loss: 0.5426 - mse: 0.5119 - val_loss: 0.6148 - val_mse: 0.6148 - lr: 0.0010 - 696ms/epoch - 174ms/step\n",
            "Epoch 62/1000\n",
            "4/4 - 1s - loss: 0.5384 - mse: 0.5078 - val_loss: 0.6098 - val_mse: 0.6098 - lr: 0.0010 - 701ms/epoch - 175ms/step\n",
            "Epoch 63/1000\n",
            "4/4 - 1s - loss: 0.5352 - mse: 0.5052 - val_loss: 0.6049 - val_mse: 0.6049 - lr: 0.0010 - 685ms/epoch - 171ms/step\n",
            "Epoch 64/1000\n",
            "4/4 - 1s - loss: 0.5343 - mse: 0.5042 - val_loss: 0.6002 - val_mse: 0.6002 - lr: 0.0010 - 684ms/epoch - 171ms/step\n",
            "Epoch 65/1000\n",
            "4/4 - 1s - loss: 0.5296 - mse: 0.5000 - val_loss: 0.5956 - val_mse: 0.5956 - lr: 0.0010 - 680ms/epoch - 170ms/step\n",
            "Epoch 66/1000\n",
            "4/4 - 1s - loss: 0.5241 - mse: 0.4949 - val_loss: 0.5907 - val_mse: 0.5907 - lr: 0.0010 - 700ms/epoch - 175ms/step\n",
            "Epoch 67/1000\n",
            "4/4 - 1s - loss: 0.5232 - mse: 0.4939 - val_loss: 0.5863 - val_mse: 0.5863 - lr: 0.0010 - 696ms/epoch - 174ms/step\n",
            "Epoch 68/1000\n",
            "4/4 - 1s - loss: 0.5209 - mse: 0.4918 - val_loss: 0.5815 - val_mse: 0.5815 - lr: 0.0010 - 681ms/epoch - 170ms/step\n",
            "Epoch 69/1000\n",
            "4/4 - 1s - loss: 0.5173 - mse: 0.4885 - val_loss: 0.5765 - val_mse: 0.5765 - lr: 0.0010 - 685ms/epoch - 171ms/step\n",
            "Epoch 70/1000\n",
            "4/4 - 1s - loss: 0.5169 - mse: 0.4881 - val_loss: 0.5715 - val_mse: 0.5715 - lr: 0.0010 - 686ms/epoch - 171ms/step\n",
            "Epoch 71/1000\n",
            "4/4 - 1s - loss: 0.5113 - mse: 0.4829 - val_loss: 0.5673 - val_mse: 0.5673 - lr: 0.0010 - 684ms/epoch - 171ms/step\n",
            "Epoch 72/1000\n",
            "4/4 - 1s - loss: 0.5086 - mse: 0.4804 - val_loss: 0.5634 - val_mse: 0.5634 - lr: 0.0010 - 710ms/epoch - 177ms/step\n",
            "Epoch 73/1000\n",
            "4/4 - 1s - loss: 0.5082 - mse: 0.4800 - val_loss: 0.5597 - val_mse: 0.5597 - lr: 0.0010 - 691ms/epoch - 173ms/step\n",
            "Epoch 74/1000\n",
            "4/4 - 1s - loss: 0.5056 - mse: 0.4778 - val_loss: 0.5545 - val_mse: 0.5545 - lr: 0.0010 - 679ms/epoch - 170ms/step\n",
            "Epoch 75/1000\n",
            "4/4 - 1s - loss: 0.5036 - mse: 0.4757 - val_loss: 0.5484 - val_mse: 0.5484 - lr: 0.0010 - 694ms/epoch - 174ms/step\n",
            "Epoch 76/1000\n",
            "4/4 - 1s - loss: 0.5002 - mse: 0.4726 - val_loss: 0.5431 - val_mse: 0.5431 - lr: 0.0010 - 686ms/epoch - 171ms/step\n",
            "Epoch 77/1000\n",
            "4/4 - 1s - loss: 0.4987 - mse: 0.4711 - val_loss: 0.5385 - val_mse: 0.5385 - lr: 0.0010 - 690ms/epoch - 172ms/step\n",
            "Epoch 78/1000\n",
            "4/4 - 1s - loss: 0.4956 - mse: 0.4682 - val_loss: 0.5349 - val_mse: 0.5349 - lr: 0.0010 - 693ms/epoch - 173ms/step\n",
            "Epoch 79/1000\n",
            "4/4 - 1s - loss: 0.4943 - mse: 0.4672 - val_loss: 0.5313 - val_mse: 0.5313 - lr: 0.0010 - 701ms/epoch - 175ms/step\n",
            "Epoch 80/1000\n",
            "4/4 - 1s - loss: 0.4914 - mse: 0.4643 - val_loss: 0.5271 - val_mse: 0.5271 - lr: 0.0010 - 693ms/epoch - 173ms/step\n",
            "Epoch 81/1000\n",
            "4/4 - 1s - loss: 0.4876 - mse: 0.4609 - val_loss: 0.5240 - val_mse: 0.5240 - lr: 0.0010 - 712ms/epoch - 178ms/step\n",
            "Epoch 82/1000\n",
            "4/4 - 1s - loss: 0.4869 - mse: 0.4602 - val_loss: 0.5207 - val_mse: 0.5207 - lr: 0.0010 - 709ms/epoch - 177ms/step\n",
            "Epoch 83/1000\n",
            "4/4 - 1s - loss: 0.4834 - mse: 0.4570 - val_loss: 0.5161 - val_mse: 0.5161 - lr: 0.0010 - 702ms/epoch - 176ms/step\n",
            "Epoch 84/1000\n",
            "4/4 - 1s - loss: 0.4827 - mse: 0.4562 - val_loss: 0.5109 - val_mse: 0.5109 - lr: 0.0010 - 716ms/epoch - 179ms/step\n",
            "Epoch 85/1000\n",
            "4/4 - 1s - loss: 0.4827 - mse: 0.4561 - val_loss: 0.5059 - val_mse: 0.5059 - lr: 0.0010 - 692ms/epoch - 173ms/step\n",
            "Epoch 86/1000\n",
            "4/4 - 1s - loss: 0.4792 - mse: 0.4528 - val_loss: 0.5021 - val_mse: 0.5021 - lr: 0.0010 - 699ms/epoch - 175ms/step\n",
            "Epoch 87/1000\n",
            "4/4 - 1s - loss: 0.4772 - mse: 0.4512 - val_loss: 0.4989 - val_mse: 0.4989 - lr: 0.0010 - 707ms/epoch - 177ms/step\n",
            "Epoch 88/1000\n",
            "4/4 - 1s - loss: 0.4766 - mse: 0.4504 - val_loss: 0.4955 - val_mse: 0.4955 - lr: 0.0010 - 700ms/epoch - 175ms/step\n",
            "Epoch 89/1000\n",
            "4/4 - 1s - loss: 0.4730 - mse: 0.4471 - val_loss: 0.4913 - val_mse: 0.4913 - lr: 0.0010 - 692ms/epoch - 173ms/step\n",
            "Epoch 90/1000\n",
            "4/4 - 1s - loss: 0.4722 - mse: 0.4464 - val_loss: 0.4872 - val_mse: 0.4872 - lr: 0.0010 - 701ms/epoch - 175ms/step\n",
            "Epoch 91/1000\n",
            "4/4 - 1s - loss: 0.4718 - mse: 0.4462 - val_loss: 0.4842 - val_mse: 0.4842 - lr: 0.0010 - 709ms/epoch - 177ms/step\n",
            "Epoch 92/1000\n",
            "4/4 - 1s - loss: 0.4686 - mse: 0.4430 - val_loss: 0.4811 - val_mse: 0.4811 - lr: 0.0010 - 709ms/epoch - 177ms/step\n",
            "Epoch 93/1000\n",
            "4/4 - 1s - loss: 0.4700 - mse: 0.4444 - val_loss: 0.4771 - val_mse: 0.4771 - lr: 0.0010 - 691ms/epoch - 173ms/step\n",
            "Epoch 94/1000\n",
            "4/4 - 1s - loss: 0.4672 - mse: 0.4417 - val_loss: 0.4729 - val_mse: 0.4729 - lr: 0.0010 - 706ms/epoch - 176ms/step\n",
            "Epoch 95/1000\n",
            "4/4 - 1s - loss: 0.4657 - mse: 0.4404 - val_loss: 0.4691 - val_mse: 0.4691 - lr: 0.0010 - 692ms/epoch - 173ms/step\n",
            "Epoch 96/1000\n",
            "4/4 - 1s - loss: 0.4642 - mse: 0.4390 - val_loss: 0.4653 - val_mse: 0.4653 - lr: 0.0010 - 698ms/epoch - 175ms/step\n",
            "Epoch 97/1000\n",
            "4/4 - 1s - loss: 0.4620 - mse: 0.4368 - val_loss: 0.4618 - val_mse: 0.4618 - lr: 0.0010 - 701ms/epoch - 175ms/step\n",
            "Epoch 98/1000\n",
            "4/4 - 1s - loss: 0.4597 - mse: 0.4346 - val_loss: 0.4597 - val_mse: 0.4597 - lr: 0.0010 - 702ms/epoch - 175ms/step\n",
            "Epoch 99/1000\n",
            "4/4 - 1s - loss: 0.4587 - mse: 0.4337 - val_loss: 0.4581 - val_mse: 0.4581 - lr: 0.0010 - 726ms/epoch - 181ms/step\n",
            "Epoch 100/1000\n",
            "4/4 - 1s - loss: 0.4581 - mse: 0.4333 - val_loss: 0.4553 - val_mse: 0.4553 - lr: 0.0010 - 702ms/epoch - 175ms/step\n",
            "Epoch 101/1000\n",
            "4/4 - 1s - loss: 0.4574 - mse: 0.4325 - val_loss: 0.4518 - val_mse: 0.4518 - lr: 0.0010 - 690ms/epoch - 173ms/step\n",
            "Epoch 102/1000\n",
            "4/4 - 1s - loss: 0.4566 - mse: 0.4317 - val_loss: 0.4493 - val_mse: 0.4493 - lr: 0.0010 - 691ms/epoch - 173ms/step\n",
            "Epoch 103/1000\n",
            "4/4 - 1s - loss: 0.4555 - mse: 0.4306 - val_loss: 0.4475 - val_mse: 0.4475 - lr: 0.0010 - 698ms/epoch - 175ms/step\n",
            "Epoch 104/1000\n",
            "4/4 - 1s - loss: 0.4535 - mse: 0.4287 - val_loss: 0.4450 - val_mse: 0.4450 - lr: 0.0010 - 708ms/epoch - 177ms/step\n",
            "Epoch 105/1000\n",
            "4/4 - 1s - loss: 0.4526 - mse: 0.4280 - val_loss: 0.4418 - val_mse: 0.4418 - lr: 0.0010 - 696ms/epoch - 174ms/step\n",
            "Epoch 106/1000\n",
            "4/4 - 1s - loss: 0.4514 - mse: 0.4268 - val_loss: 0.4393 - val_mse: 0.4393 - lr: 0.0010 - 678ms/epoch - 170ms/step\n",
            "Epoch 107/1000\n",
            "4/4 - 1s - loss: 0.4500 - mse: 0.4255 - val_loss: 0.4372 - val_mse: 0.4372 - lr: 0.0010 - 690ms/epoch - 173ms/step\n",
            "Epoch 108/1000\n",
            "4/4 - 1s - loss: 0.4488 - mse: 0.4244 - val_loss: 0.4355 - val_mse: 0.4355 - lr: 0.0010 - 692ms/epoch - 173ms/step\n",
            "Epoch 109/1000\n",
            "4/4 - 1s - loss: 0.4483 - mse: 0.4240 - val_loss: 0.4340 - val_mse: 0.4340 - lr: 0.0010 - 695ms/epoch - 174ms/step\n",
            "Epoch 110/1000\n",
            "4/4 - 1s - loss: 0.4457 - mse: 0.4215 - val_loss: 0.4315 - val_mse: 0.4315 - lr: 0.0010 - 686ms/epoch - 172ms/step\n",
            "Epoch 111/1000\n",
            "4/4 - 1s - loss: 0.4458 - mse: 0.4217 - val_loss: 0.4283 - val_mse: 0.4283 - lr: 0.0010 - 684ms/epoch - 171ms/step\n",
            "Epoch 112/1000\n",
            "4/4 - 1s - loss: 0.4450 - mse: 0.4208 - val_loss: 0.4257 - val_mse: 0.4257 - lr: 0.0010 - 680ms/epoch - 170ms/step\n",
            "Epoch 113/1000\n",
            "4/4 - 1s - loss: 0.4433 - mse: 0.4192 - val_loss: 0.4241 - val_mse: 0.4241 - lr: 0.0010 - 694ms/epoch - 174ms/step\n",
            "Epoch 114/1000\n",
            "4/4 - 1s - loss: 0.4435 - mse: 0.4193 - val_loss: 0.4234 - val_mse: 0.4234 - lr: 0.0010 - 690ms/epoch - 172ms/step\n",
            "Epoch 115/1000\n",
            "4/4 - 1s - loss: 0.4418 - mse: 0.4179 - val_loss: 0.4230 - val_mse: 0.4230 - lr: 0.0010 - 732ms/epoch - 183ms/step\n",
            "Epoch 116/1000\n",
            "4/4 - 1s - loss: 0.4411 - mse: 0.4173 - val_loss: 0.4211 - val_mse: 0.4211 - lr: 0.0010 - 737ms/epoch - 184ms/step\n",
            "Epoch 117/1000\n",
            "4/4 - 1s - loss: 0.4394 - mse: 0.4157 - val_loss: 0.4184 - val_mse: 0.4184 - lr: 0.0010 - 744ms/epoch - 186ms/step\n",
            "Epoch 118/1000\n",
            "4/4 - 1s - loss: 0.4392 - mse: 0.4154 - val_loss: 0.4158 - val_mse: 0.4158 - lr: 0.0010 - 760ms/epoch - 190ms/step\n",
            "Epoch 119/1000\n",
            "4/4 - 1s - loss: 0.4380 - mse: 0.4143 - val_loss: 0.4147 - val_mse: 0.4147 - lr: 0.0010 - 755ms/epoch - 189ms/step\n",
            "Epoch 120/1000\n",
            "4/4 - 1s - loss: 0.4370 - mse: 0.4134 - val_loss: 0.4144 - val_mse: 0.4144 - lr: 0.0010 - 761ms/epoch - 190ms/step\n",
            "Epoch 121/1000\n",
            "4/4 - 1s - loss: 0.4366 - mse: 0.4130 - val_loss: 0.4138 - val_mse: 0.4138 - lr: 0.0010 - 768ms/epoch - 192ms/step\n",
            "Epoch 122/1000\n",
            "4/4 - 1s - loss: 0.4351 - mse: 0.4115 - val_loss: 0.4111 - val_mse: 0.4111 - lr: 0.0010 - 788ms/epoch - 197ms/step\n",
            "Epoch 123/1000\n",
            "4/4 - 1s - loss: 0.4349 - mse: 0.4113 - val_loss: 0.4088 - val_mse: 0.4088 - lr: 0.0010 - 762ms/epoch - 191ms/step\n",
            "Epoch 124/1000\n",
            "4/4 - 1s - loss: 0.4342 - mse: 0.4107 - val_loss: 0.4075 - val_mse: 0.4075 - lr: 0.0010 - 1s/epoch - 326ms/step\n",
            "Epoch 125/1000\n",
            "4/4 - 2s - loss: 0.4328 - mse: 0.4095 - val_loss: 0.4069 - val_mse: 0.4069 - lr: 0.0010 - 2s/epoch - 385ms/step\n",
            "Epoch 126/1000\n",
            "4/4 - 1s - loss: 0.4329 - mse: 0.4095 - val_loss: 0.4063 - val_mse: 0.4063 - lr: 0.0010 - 1s/epoch - 349ms/step\n",
            "Epoch 127/1000\n",
            "4/4 - 2s - loss: 0.4313 - mse: 0.4080 - val_loss: 0.4052 - val_mse: 0.4052 - lr: 0.0010 - 2s/epoch - 377ms/step\n",
            "Epoch 128/1000\n",
            "4/4 - 2s - loss: 0.4318 - mse: 0.4084 - val_loss: 0.4045 - val_mse: 0.4045 - lr: 0.0010 - 2s/epoch - 378ms/step\n",
            "Epoch 129/1000\n",
            "4/4 - 1s - loss: 0.4305 - mse: 0.4072 - val_loss: 0.4034 - val_mse: 0.4034 - lr: 0.0010 - 1s/epoch - 343ms/step\n",
            "Epoch 130/1000\n",
            "4/4 - 1s - loss: 0.4302 - mse: 0.4070 - val_loss: 0.4020 - val_mse: 0.4020 - lr: 0.0010 - 1s/epoch - 356ms/step\n",
            "Epoch 131/1000\n",
            "4/4 - 1s - loss: 0.4302 - mse: 0.4070 - val_loss: 0.4003 - val_mse: 0.4003 - lr: 0.0010 - 1s/epoch - 260ms/step\n",
            "Epoch 132/1000\n",
            "4/4 - 1s - loss: 0.4296 - mse: 0.4063 - val_loss: 0.3994 - val_mse: 0.3994 - lr: 0.0010 - 852ms/epoch - 213ms/step\n",
            "Epoch 133/1000\n",
            "4/4 - 1s - loss: 0.4280 - mse: 0.4048 - val_loss: 0.3993 - val_mse: 0.3993 - lr: 0.0010 - 885ms/epoch - 221ms/step\n",
            "Epoch 134/1000\n",
            "4/4 - 1s - loss: 0.4278 - mse: 0.4046 - val_loss: 0.3990 - val_mse: 0.3990 - lr: 0.0010 - 757ms/epoch - 189ms/step\n",
            "Epoch 135/1000\n",
            "4/4 - 1s - loss: 0.4262 - mse: 0.4031 - val_loss: 0.3980 - val_mse: 0.3980 - lr: 0.0010 - 703ms/epoch - 176ms/step\n",
            "Epoch 136/1000\n",
            "4/4 - 1s - loss: 0.4263 - mse: 0.4033 - val_loss: 0.3970 - val_mse: 0.3970 - lr: 0.0010 - 709ms/epoch - 177ms/step\n",
            "Epoch 137/1000\n",
            "4/4 - 1s - loss: 0.4261 - mse: 0.4030 - val_loss: 0.3960 - val_mse: 0.3960 - lr: 0.0010 - 692ms/epoch - 173ms/step\n",
            "Epoch 138/1000\n",
            "4/4 - 1s - loss: 0.4254 - mse: 0.4024 - val_loss: 0.3952 - val_mse: 0.3952 - lr: 0.0010 - 716ms/epoch - 179ms/step\n",
            "Epoch 139/1000\n",
            "4/4 - 1s - loss: 0.4253 - mse: 0.4022 - val_loss: 0.3940 - val_mse: 0.3940 - lr: 0.0010 - 704ms/epoch - 176ms/step\n",
            "Epoch 140/1000\n",
            "4/4 - 1s - loss: 0.4236 - mse: 0.4007 - val_loss: 0.3933 - val_mse: 0.3933 - lr: 0.0010 - 688ms/epoch - 172ms/step\n",
            "Epoch 141/1000\n",
            "4/4 - 1s - loss: 0.4234 - mse: 0.4005 - val_loss: 0.3929 - val_mse: 0.3929 - lr: 0.0010 - 691ms/epoch - 173ms/step\n",
            "Epoch 142/1000\n",
            "4/4 - 1s - loss: 0.4227 - mse: 0.3999 - val_loss: 0.3931 - val_mse: 0.3931 - lr: 0.0010 - 685ms/epoch - 171ms/step\n",
            "Epoch 143/1000\n",
            "4/4 - 1s - loss: 0.4226 - mse: 0.3998 - val_loss: 0.3926 - val_mse: 0.3926 - lr: 0.0010 - 702ms/epoch - 176ms/step\n",
            "Epoch 144/1000\n",
            "4/4 - 1s - loss: 0.4224 - mse: 0.3996 - val_loss: 0.3918 - val_mse: 0.3918 - lr: 0.0010 - 681ms/epoch - 170ms/step\n",
            "Epoch 145/1000\n",
            "4/4 - 1s - loss: 0.4218 - mse: 0.3991 - val_loss: 0.3913 - val_mse: 0.3913 - lr: 0.0010 - 693ms/epoch - 173ms/step\n",
            "Epoch 146/1000\n",
            "4/4 - 1s - loss: 0.4204 - mse: 0.3977 - val_loss: 0.3910 - val_mse: 0.3910 - lr: 0.0010 - 698ms/epoch - 174ms/step\n",
            "Epoch 147/1000\n",
            "4/4 - 1s - loss: 0.4206 - mse: 0.3980 - val_loss: 0.3913 - val_mse: 0.3913 - lr: 0.0010 - 687ms/epoch - 172ms/step\n",
            "Epoch 148/1000\n",
            "4/4 - 1s - loss: 0.4202 - mse: 0.3975 - val_loss: 0.3908 - val_mse: 0.3908 - lr: 0.0010 - 687ms/epoch - 172ms/step\n",
            "Epoch 149/1000\n",
            "4/4 - 1s - loss: 0.4196 - mse: 0.3970 - val_loss: 0.3895 - val_mse: 0.3895 - lr: 0.0010 - 697ms/epoch - 174ms/step\n",
            "Epoch 150/1000\n",
            "4/4 - 1s - loss: 0.4190 - mse: 0.3964 - val_loss: 0.3889 - val_mse: 0.3889 - lr: 0.0010 - 702ms/epoch - 175ms/step\n",
            "Epoch 151/1000\n",
            "4/4 - 1s - loss: 0.4186 - mse: 0.3960 - val_loss: 0.3882 - val_mse: 0.3882 - lr: 0.0010 - 683ms/epoch - 171ms/step\n",
            "Epoch 152/1000\n",
            "4/4 - 1s - loss: 0.4193 - mse: 0.3966 - val_loss: 0.3881 - val_mse: 0.3881 - lr: 0.0010 - 689ms/epoch - 172ms/step\n",
            "Epoch 153/1000\n",
            "4/4 - 1s - loss: 0.4183 - mse: 0.3957 - val_loss: 0.3888 - val_mse: 0.3888 - lr: 0.0010 - 688ms/epoch - 172ms/step\n",
            "Epoch 154/1000\n",
            "4/4 - 1s - loss: 0.4174 - mse: 0.3950 - val_loss: 0.3889 - val_mse: 0.3889 - lr: 0.0010 - 689ms/epoch - 172ms/step\n",
            "Epoch 155/1000\n",
            "4/4 - 1s - loss: 0.4171 - mse: 0.3946 - val_loss: 0.3887 - val_mse: 0.3887 - lr: 0.0010 - 680ms/epoch - 170ms/step\n",
            "Epoch 156/1000\n",
            "4/4 - 1s - loss: 0.4165 - mse: 0.3940 - val_loss: 0.3881 - val_mse: 0.3881 - lr: 0.0010 - 690ms/epoch - 173ms/step\n",
            "Epoch 157/1000\n",
            "4/4 - 1s - loss: 0.4161 - mse: 0.3937 - val_loss: 0.3871 - val_mse: 0.3871 - lr: 0.0010 - 692ms/epoch - 173ms/step\n",
            "Epoch 158/1000\n",
            "4/4 - 1s - loss: 0.4160 - mse: 0.3936 - val_loss: 0.3864 - val_mse: 0.3864 - lr: 0.0010 - 702ms/epoch - 175ms/step\n",
            "Epoch 159/1000\n",
            "4/4 - 1s - loss: 0.4153 - mse: 0.3929 - val_loss: 0.3862 - val_mse: 0.3862 - lr: 0.0010 - 681ms/epoch - 170ms/step\n",
            "Epoch 160/1000\n",
            "4/4 - 1s - loss: 0.4161 - mse: 0.3937 - val_loss: 0.3862 - val_mse: 0.3862 - lr: 0.0010 - 696ms/epoch - 174ms/step\n",
            "Epoch 161/1000\n",
            "4/4 - 1s - loss: 0.4155 - mse: 0.3932 - val_loss: 0.3864 - val_mse: 0.3864 - lr: 0.0010 - 689ms/epoch - 172ms/step\n",
            "Epoch 162/1000\n",
            "4/4 - 1s - loss: 0.4148 - mse: 0.3925 - val_loss: 0.3858 - val_mse: 0.3858 - lr: 0.0010 - 690ms/epoch - 172ms/step\n",
            "Epoch 163/1000\n",
            "4/4 - 1s - loss: 0.4145 - mse: 0.3922 - val_loss: 0.3852 - val_mse: 0.3852 - lr: 0.0010 - 694ms/epoch - 173ms/step\n",
            "Epoch 164/1000\n",
            "4/4 - 1s - loss: 0.4142 - mse: 0.3919 - val_loss: 0.3851 - val_mse: 0.3851 - lr: 0.0010 - 696ms/epoch - 174ms/step\n",
            "Epoch 165/1000\n",
            "4/4 - 1s - loss: 0.4135 - mse: 0.3912 - val_loss: 0.3855 - val_mse: 0.3855 - lr: 0.0010 - 694ms/epoch - 174ms/step\n",
            "Epoch 166/1000\n",
            "4/4 - 1s - loss: 0.4137 - mse: 0.3914 - val_loss: 0.3852 - val_mse: 0.3852 - lr: 0.0010 - 723ms/epoch - 181ms/step\n",
            "Epoch 167/1000\n",
            "4/4 - 1s - loss: 0.4137 - mse: 0.3914 - val_loss: 0.3855 - val_mse: 0.3855 - lr: 0.0010 - 711ms/epoch - 178ms/step\n",
            "Epoch 168/1000\n",
            "4/4 - 1s - loss: 0.4136 - mse: 0.3913 - val_loss: 0.3844 - val_mse: 0.3844 - lr: 0.0010 - 695ms/epoch - 174ms/step\n",
            "Epoch 169/1000\n",
            "4/4 - 1s - loss: 0.4134 - mse: 0.3912 - val_loss: 0.3841 - val_mse: 0.3841 - lr: 0.0010 - 684ms/epoch - 171ms/step\n",
            "Epoch 170/1000\n",
            "4/4 - 1s - loss: 0.4120 - mse: 0.3899 - val_loss: 0.3847 - val_mse: 0.3847 - lr: 0.0010 - 689ms/epoch - 172ms/step\n",
            "Epoch 171/1000\n",
            "4/4 - 1s - loss: 0.4121 - mse: 0.3900 - val_loss: 0.3851 - val_mse: 0.3851 - lr: 0.0010 - 702ms/epoch - 176ms/step\n",
            "Epoch 172/1000\n",
            "4/4 - 1s - loss: 0.4122 - mse: 0.3900 - val_loss: 0.3847 - val_mse: 0.3847 - lr: 0.0010 - 680ms/epoch - 170ms/step\n",
            "Epoch 173/1000\n",
            "4/4 - 1s - loss: 0.4108 - mse: 0.3888 - val_loss: 0.3840 - val_mse: 0.3840 - lr: 0.0010 - 690ms/epoch - 172ms/step\n",
            "Epoch 174/1000\n",
            "4/4 - 1s - loss: 0.4110 - mse: 0.3888 - val_loss: 0.3839 - val_mse: 0.3839 - lr: 0.0010 - 685ms/epoch - 171ms/step\n",
            "Epoch 175/1000\n",
            "4/4 - 1s - loss: 0.4110 - mse: 0.3889 - val_loss: 0.3837 - val_mse: 0.3837 - lr: 0.0010 - 693ms/epoch - 173ms/step\n",
            "Epoch 176/1000\n",
            "4/4 - 1s - loss: 0.4102 - mse: 0.3882 - val_loss: 0.3828 - val_mse: 0.3828 - lr: 0.0010 - 697ms/epoch - 174ms/step\n",
            "Epoch 177/1000\n",
            "4/4 - 1s - loss: 0.4106 - mse: 0.3885 - val_loss: 0.3827 - val_mse: 0.3827 - lr: 0.0010 - 692ms/epoch - 173ms/step\n",
            "Epoch 178/1000\n",
            "4/4 - 1s - loss: 0.4096 - mse: 0.3875 - val_loss: 0.3835 - val_mse: 0.3835 - lr: 0.0010 - 690ms/epoch - 172ms/step\n",
            "Epoch 179/1000\n",
            "4/4 - 1s - loss: 0.4099 - mse: 0.3879 - val_loss: 0.3838 - val_mse: 0.3838 - lr: 0.0010 - 689ms/epoch - 172ms/step\n",
            "Epoch 180/1000\n",
            "4/4 - 1s - loss: 0.4101 - mse: 0.3879 - val_loss: 0.3830 - val_mse: 0.3830 - lr: 0.0010 - 692ms/epoch - 173ms/step\n",
            "Epoch 181/1000\n",
            "4/4 - 1s - loss: 0.4095 - mse: 0.3875 - val_loss: 0.3824 - val_mse: 0.3824 - lr: 0.0010 - 703ms/epoch - 176ms/step\n",
            "Epoch 182/1000\n",
            "4/4 - 1s - loss: 0.4092 - mse: 0.3871 - val_loss: 0.3820 - val_mse: 0.3820 - lr: 0.0010 - 699ms/epoch - 175ms/step\n",
            "Epoch 183/1000\n",
            "4/4 - 1s - loss: 0.4088 - mse: 0.3869 - val_loss: 0.3818 - val_mse: 0.3818 - lr: 0.0010 - 688ms/epoch - 172ms/step\n",
            "Epoch 184/1000\n",
            "4/4 - 1s - loss: 0.4086 - mse: 0.3867 - val_loss: 0.3817 - val_mse: 0.3817 - lr: 0.0010 - 685ms/epoch - 171ms/step\n",
            "Epoch 185/1000\n",
            "4/4 - 1s - loss: 0.4090 - mse: 0.3869 - val_loss: 0.3819 - val_mse: 0.3819 - lr: 0.0010 - 689ms/epoch - 172ms/step\n",
            "Epoch 186/1000\n",
            "4/4 - 1s - loss: 0.4081 - mse: 0.3862 - val_loss: 0.3813 - val_mse: 0.3813 - lr: 0.0010 - 701ms/epoch - 175ms/step\n",
            "Epoch 187/1000\n",
            "4/4 - 1s - loss: 0.4073 - mse: 0.3854 - val_loss: 0.3810 - val_mse: 0.3810 - lr: 0.0010 - 691ms/epoch - 173ms/step\n",
            "Epoch 188/1000\n",
            "4/4 - 1s - loss: 0.4085 - mse: 0.3865 - val_loss: 0.3809 - val_mse: 0.3809 - lr: 0.0010 - 702ms/epoch - 176ms/step\n",
            "Epoch 189/1000\n",
            "4/4 - 1s - loss: 0.4071 - mse: 0.3853 - val_loss: 0.3808 - val_mse: 0.3808 - lr: 0.0010 - 692ms/epoch - 173ms/step\n",
            "Epoch 190/1000\n",
            "4/4 - 1s - loss: 0.4072 - mse: 0.3852 - val_loss: 0.3804 - val_mse: 0.3804 - lr: 0.0010 - 693ms/epoch - 173ms/step\n",
            "Epoch 191/1000\n",
            "4/4 - 1s - loss: 0.4069 - mse: 0.3850 - val_loss: 0.3807 - val_mse: 0.3807 - lr: 0.0010 - 687ms/epoch - 172ms/step\n",
            "Epoch 192/1000\n",
            "4/4 - 1s - loss: 0.4075 - mse: 0.3857 - val_loss: 0.3806 - val_mse: 0.3806 - lr: 0.0010 - 703ms/epoch - 176ms/step\n",
            "Epoch 193/1000\n",
            "4/4 - 1s - loss: 0.4068 - mse: 0.3849 - val_loss: 0.3801 - val_mse: 0.3801 - lr: 0.0010 - 687ms/epoch - 172ms/step\n",
            "Epoch 194/1000\n",
            "4/4 - 1s - loss: 0.4072 - mse: 0.3852 - val_loss: 0.3801 - val_mse: 0.3801 - lr: 0.0010 - 685ms/epoch - 171ms/step\n",
            "Epoch 195/1000\n",
            "4/4 - 1s - loss: 0.4059 - mse: 0.3841 - val_loss: 0.3801 - val_mse: 0.3801 - lr: 0.0010 - 691ms/epoch - 173ms/step\n",
            "Epoch 196/1000\n",
            "4/4 - 1s - loss: 0.4059 - mse: 0.3841 - val_loss: 0.3804 - val_mse: 0.3804 - lr: 0.0010 - 703ms/epoch - 176ms/step\n",
            "Epoch 197/1000\n",
            "4/4 - 1s - loss: 0.4056 - mse: 0.3838 - val_loss: 0.3800 - val_mse: 0.3800 - lr: 0.0010 - 694ms/epoch - 174ms/step\n",
            "Epoch 198/1000\n",
            "4/4 - 1s - loss: 0.4061 - mse: 0.3843 - val_loss: 0.3797 - val_mse: 0.3797 - lr: 0.0010 - 686ms/epoch - 172ms/step\n",
            "Epoch 199/1000\n",
            "4/4 - 1s - loss: 0.4054 - mse: 0.3837 - val_loss: 0.3793 - val_mse: 0.3793 - lr: 0.0010 - 692ms/epoch - 173ms/step\n",
            "Epoch 200/1000\n",
            "4/4 - 1s - loss: 0.4053 - mse: 0.3835 - val_loss: 0.3796 - val_mse: 0.3796 - lr: 0.0010 - 684ms/epoch - 171ms/step\n",
            "Epoch 201/1000\n",
            "4/4 - 1s - loss: 0.4048 - mse: 0.3832 - val_loss: 0.3800 - val_mse: 0.3800 - lr: 0.0010 - 686ms/epoch - 172ms/step\n",
            "Epoch 202/1000\n",
            "4/4 - 1s - loss: 0.4052 - mse: 0.3834 - val_loss: 0.3798 - val_mse: 0.3798 - lr: 0.0010 - 686ms/epoch - 171ms/step\n",
            "Epoch 203/1000\n",
            "4/4 - 1s - loss: 0.4047 - mse: 0.3829 - val_loss: 0.3793 - val_mse: 0.3793 - lr: 0.0010 - 686ms/epoch - 172ms/step\n",
            "Epoch 204/1000\n",
            "4/4 - 1s - loss: 0.4044 - mse: 0.3828 - val_loss: 0.3795 - val_mse: 0.3795 - lr: 0.0010 - 689ms/epoch - 172ms/step\n",
            "Epoch 205/1000\n",
            "4/4 - 1s - loss: 0.4038 - mse: 0.3822 - val_loss: 0.3789 - val_mse: 0.3789 - lr: 0.0010 - 700ms/epoch - 175ms/step\n",
            "Epoch 206/1000\n",
            "4/4 - 1s - loss: 0.4043 - mse: 0.3825 - val_loss: 0.3784 - val_mse: 0.3784 - lr: 0.0010 - 688ms/epoch - 172ms/step\n",
            "Epoch 207/1000\n",
            "4/4 - 1s - loss: 0.4044 - mse: 0.3827 - val_loss: 0.3787 - val_mse: 0.3787 - lr: 0.0010 - 698ms/epoch - 175ms/step\n",
            "Epoch 208/1000\n",
            "4/4 - 1s - loss: 0.4035 - mse: 0.3818 - val_loss: 0.3788 - val_mse: 0.3788 - lr: 0.0010 - 697ms/epoch - 174ms/step\n",
            "Epoch 209/1000\n",
            "4/4 - 1s - loss: 0.4043 - mse: 0.3826 - val_loss: 0.3787 - val_mse: 0.3787 - lr: 0.0010 - 685ms/epoch - 171ms/step\n",
            "Epoch 210/1000\n",
            "4/4 - 1s - loss: 0.4042 - mse: 0.3825 - val_loss: 0.3779 - val_mse: 0.3779 - lr: 0.0010 - 699ms/epoch - 175ms/step\n",
            "Epoch 211/1000\n",
            "4/4 - 1s - loss: 0.4041 - mse: 0.3823 - val_loss: 0.3779 - val_mse: 0.3779 - lr: 0.0010 - 700ms/epoch - 175ms/step\n",
            "Epoch 212/1000\n",
            "4/4 - 1s - loss: 0.4039 - mse: 0.3823 - val_loss: 0.3778 - val_mse: 0.3778 - lr: 0.0010 - 692ms/epoch - 173ms/step\n",
            "Epoch 213/1000\n",
            "4/4 - 1s - loss: 0.4032 - mse: 0.3816 - val_loss: 0.3781 - val_mse: 0.3781 - lr: 0.0010 - 682ms/epoch - 171ms/step\n",
            "Epoch 214/1000\n",
            "4/4 - 1s - loss: 0.4032 - mse: 0.3815 - val_loss: 0.3772 - val_mse: 0.3772 - lr: 0.0010 - 698ms/epoch - 175ms/step\n",
            "Epoch 215/1000\n",
            "4/4 - 1s - loss: 0.4038 - mse: 0.3821 - val_loss: 0.3772 - val_mse: 0.3772 - lr: 0.0010 - 700ms/epoch - 175ms/step\n",
            "Epoch 216/1000\n",
            "4/4 - 1s - loss: 0.4031 - mse: 0.3814 - val_loss: 0.3778 - val_mse: 0.3778 - lr: 0.0010 - 687ms/epoch - 172ms/step\n",
            "Epoch 217/1000\n",
            "4/4 - 1s - loss: 0.4027 - mse: 0.3811 - val_loss: 0.3784 - val_mse: 0.3784 - lr: 0.0010 - 688ms/epoch - 172ms/step\n",
            "Epoch 218/1000\n",
            "4/4 - 1s - loss: 0.4027 - mse: 0.3811 - val_loss: 0.3776 - val_mse: 0.3776 - lr: 0.0010 - 688ms/epoch - 172ms/step\n",
            "Epoch 219/1000\n",
            "4/4 - 1s - loss: 0.4028 - mse: 0.3811 - val_loss: 0.3770 - val_mse: 0.3770 - lr: 0.0010 - 684ms/epoch - 171ms/step\n",
            "Epoch 220/1000\n",
            "4/4 - 1s - loss: 0.4016 - mse: 0.3801 - val_loss: 0.3771 - val_mse: 0.3771 - lr: 0.0010 - 688ms/epoch - 172ms/step\n",
            "Epoch 221/1000\n",
            "4/4 - 1s - loss: 0.4022 - mse: 0.3806 - val_loss: 0.3780 - val_mse: 0.3780 - lr: 0.0010 - 687ms/epoch - 172ms/step\n",
            "Epoch 222/1000\n",
            "4/4 - 1s - loss: 0.4033 - mse: 0.3816 - val_loss: 0.3776 - val_mse: 0.3776 - lr: 0.0010 - 692ms/epoch - 173ms/step\n",
            "Epoch 223/1000\n",
            "4/4 - 1s - loss: 0.4016 - mse: 0.3800 - val_loss: 0.3769 - val_mse: 0.3769 - lr: 0.0010 - 696ms/epoch - 174ms/step\n",
            "Epoch 224/1000\n",
            "4/4 - 1s - loss: 0.4022 - mse: 0.3806 - val_loss: 0.3767 - val_mse: 0.3767 - lr: 0.0010 - 707ms/epoch - 177ms/step\n",
            "Epoch 225/1000\n",
            "4/4 - 1s - loss: 0.4021 - mse: 0.3805 - val_loss: 0.3776 - val_mse: 0.3776 - lr: 0.0010 - 707ms/epoch - 177ms/step\n",
            "Epoch 226/1000\n",
            "4/4 - 1s - loss: 0.4010 - mse: 0.3795 - val_loss: 0.3770 - val_mse: 0.3770 - lr: 0.0010 - 714ms/epoch - 178ms/step\n",
            "Epoch 227/1000\n",
            "4/4 - 1s - loss: 0.4017 - mse: 0.3802 - val_loss: 0.3764 - val_mse: 0.3764 - lr: 0.0010 - 682ms/epoch - 171ms/step\n",
            "Epoch 228/1000\n",
            "4/4 - 1s - loss: 0.4020 - mse: 0.3803 - val_loss: 0.3766 - val_mse: 0.3766 - lr: 0.0010 - 700ms/epoch - 175ms/step\n",
            "Epoch 229/1000\n",
            "4/4 - 1s - loss: 0.4012 - mse: 0.3797 - val_loss: 0.3766 - val_mse: 0.3766 - lr: 0.0010 - 694ms/epoch - 174ms/step\n",
            "Epoch 230/1000\n",
            "4/4 - 1s - loss: 0.4020 - mse: 0.3804 - val_loss: 0.3763 - val_mse: 0.3763 - lr: 0.0010 - 690ms/epoch - 173ms/step\n",
            "Epoch 231/1000\n",
            "4/4 - 1s - loss: 0.4018 - mse: 0.3803 - val_loss: 0.3766 - val_mse: 0.3766 - lr: 0.0010 - 694ms/epoch - 174ms/step\n",
            "Epoch 232/1000\n",
            "4/4 - 1s - loss: 0.4014 - mse: 0.3799 - val_loss: 0.3767 - val_mse: 0.3767 - lr: 0.0010 - 685ms/epoch - 171ms/step\n",
            "Epoch 233/1000\n",
            "4/4 - 1s - loss: 0.4010 - mse: 0.3795 - val_loss: 0.3760 - val_mse: 0.3760 - lr: 0.0010 - 689ms/epoch - 172ms/step\n",
            "Epoch 234/1000\n",
            "4/4 - 1s - loss: 0.4011 - mse: 0.3796 - val_loss: 0.3752 - val_mse: 0.3752 - lr: 0.0010 - 690ms/epoch - 173ms/step\n",
            "Epoch 235/1000\n",
            "4/4 - 1s - loss: 0.4015 - mse: 0.3799 - val_loss: 0.3760 - val_mse: 0.3760 - lr: 0.0010 - 673ms/epoch - 168ms/step\n",
            "Epoch 236/1000\n",
            "4/4 - 1s - loss: 0.4007 - mse: 0.3792 - val_loss: 0.3767 - val_mse: 0.3767 - lr: 0.0010 - 675ms/epoch - 169ms/step\n",
            "Epoch 237/1000\n",
            "4/4 - 1s - loss: 0.4009 - mse: 0.3794 - val_loss: 0.3759 - val_mse: 0.3759 - lr: 0.0010 - 696ms/epoch - 174ms/step\n",
            "Epoch 238/1000\n",
            "4/4 - 1s - loss: 0.4012 - mse: 0.3797 - val_loss: 0.3755 - val_mse: 0.3755 - lr: 0.0010 - 692ms/epoch - 173ms/step\n",
            "Epoch 239/1000\n",
            "4/4 - 1s - loss: 0.4001 - mse: 0.3785 - val_loss: 0.3755 - val_mse: 0.3755 - lr: 0.0010 - 693ms/epoch - 173ms/step\n",
            "Epoch 240/1000\n",
            "4/4 - 1s - loss: 0.4007 - mse: 0.3792 - val_loss: 0.3755 - val_mse: 0.3755 - lr: 0.0010 - 698ms/epoch - 174ms/step\n",
            "Epoch 241/1000\n",
            "\n",
            "Epoch 241: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "4/4 - 1s - loss: 0.4006 - mse: 0.3791 - val_loss: 0.3756 - val_mse: 0.3756 - lr: 0.0010 - 697ms/epoch - 174ms/step\n",
            "Epoch 242/1000\n",
            "4/4 - 1s - loss: 0.4004 - mse: 0.3790 - val_loss: 0.3755 - val_mse: 0.3755 - lr: 1.0000e-04 - 695ms/epoch - 174ms/step\n",
            "Epoch 243/1000\n",
            "4/4 - 1s - loss: 0.4009 - mse: 0.3794 - val_loss: 0.3754 - val_mse: 0.3754 - lr: 1.0000e-04 - 689ms/epoch - 172ms/step\n",
            "Epoch 244/1000\n",
            "4/4 - 1s - loss: 0.3997 - mse: 0.3782 - val_loss: 0.3753 - val_mse: 0.3753 - lr: 1.0000e-04 - 698ms/epoch - 174ms/step\n",
            "Epoch 244: early stopping\n",
            "==================================================\n",
            "Step 5\n",
            "==================================================\n",
            "Epoch 1/1000\n",
            "4/4 - 4s - loss: 2.2612 - mse: 2.1283 - val_loss: 1.0096 - val_mse: 1.0096 - lr: 0.0010 - 4s/epoch - 956ms/step\n",
            "Epoch 2/1000\n",
            "4/4 - 1s - loss: 1.6640 - mse: 1.5595 - val_loss: 0.9862 - val_mse: 0.9862 - lr: 0.0010 - 712ms/epoch - 178ms/step\n",
            "Epoch 3/1000\n",
            "4/4 - 1s - loss: 1.3765 - mse: 1.2889 - val_loss: 0.9858 - val_mse: 0.9858 - lr: 0.0010 - 716ms/epoch - 179ms/step\n",
            "Epoch 4/1000\n",
            "4/4 - 1s - loss: 1.2442 - mse: 1.1661 - val_loss: 0.9847 - val_mse: 0.9847 - lr: 0.0010 - 699ms/epoch - 175ms/step\n",
            "Epoch 5/1000\n",
            "4/4 - 1s - loss: 1.1420 - mse: 1.0711 - val_loss: 0.9760 - val_mse: 0.9760 - lr: 0.0010 - 717ms/epoch - 179ms/step\n",
            "Epoch 6/1000\n",
            "4/4 - 1s - loss: 1.0763 - mse: 1.0101 - val_loss: 0.9639 - val_mse: 0.9639 - lr: 0.0010 - 705ms/epoch - 176ms/step\n",
            "Epoch 7/1000\n",
            "4/4 - 1s - loss: 1.0286 - mse: 0.9652 - val_loss: 0.9534 - val_mse: 0.9534 - lr: 0.0010 - 687ms/epoch - 172ms/step\n",
            "Epoch 8/1000\n",
            "4/4 - 1s - loss: 0.9882 - mse: 0.9275 - val_loss: 0.9462 - val_mse: 0.9462 - lr: 0.0010 - 701ms/epoch - 175ms/step\n",
            "Epoch 9/1000\n",
            "4/4 - 1s - loss: 0.9593 - mse: 0.9002 - val_loss: 0.9399 - val_mse: 0.9399 - lr: 0.0010 - 671ms/epoch - 168ms/step\n",
            "Epoch 10/1000\n",
            "4/4 - 1s - loss: 0.9374 - mse: 0.8808 - val_loss: 0.9314 - val_mse: 0.9314 - lr: 0.0010 - 696ms/epoch - 174ms/step\n",
            "Epoch 11/1000\n",
            "4/4 - 1s - loss: 0.9159 - mse: 0.8606 - val_loss: 0.9216 - val_mse: 0.9216 - lr: 0.0010 - 703ms/epoch - 176ms/step\n",
            "Epoch 12/1000\n",
            "4/4 - 1s - loss: 0.8942 - mse: 0.8408 - val_loss: 0.9135 - val_mse: 0.9135 - lr: 0.0010 - 698ms/epoch - 175ms/step\n",
            "Epoch 13/1000\n",
            "4/4 - 1s - loss: 0.8764 - mse: 0.8245 - val_loss: 0.9089 - val_mse: 0.9089 - lr: 0.0010 - 695ms/epoch - 174ms/step\n",
            "Epoch 14/1000\n",
            "4/4 - 1s - loss: 0.8614 - mse: 0.8104 - val_loss: 0.9050 - val_mse: 0.9050 - lr: 0.0010 - 692ms/epoch - 173ms/step\n",
            "Epoch 15/1000\n",
            "4/4 - 1s - loss: 0.8458 - mse: 0.7963 - val_loss: 0.9006 - val_mse: 0.9006 - lr: 0.0010 - 706ms/epoch - 176ms/step\n",
            "Epoch 16/1000\n",
            "4/4 - 1s - loss: 0.8367 - mse: 0.7879 - val_loss: 0.8956 - val_mse: 0.8956 - lr: 0.0010 - 712ms/epoch - 178ms/step\n",
            "Epoch 17/1000\n",
            "4/4 - 1s - loss: 0.8214 - mse: 0.7739 - val_loss: 0.8915 - val_mse: 0.8915 - lr: 0.0010 - 688ms/epoch - 172ms/step\n",
            "Epoch 18/1000\n",
            "4/4 - 1s - loss: 0.8048 - mse: 0.7583 - val_loss: 0.8895 - val_mse: 0.8895 - lr: 0.0010 - 680ms/epoch - 170ms/step\n",
            "Epoch 19/1000\n",
            "4/4 - 1s - loss: 0.7989 - mse: 0.7529 - val_loss: 0.8874 - val_mse: 0.8874 - lr: 0.0010 - 702ms/epoch - 176ms/step\n",
            "Epoch 20/1000\n",
            "4/4 - 1s - loss: 0.7892 - mse: 0.7437 - val_loss: 0.8838 - val_mse: 0.8838 - lr: 0.0010 - 692ms/epoch - 173ms/step\n",
            "Epoch 21/1000\n",
            "4/4 - 1s - loss: 0.7796 - mse: 0.7348 - val_loss: 0.8790 - val_mse: 0.8790 - lr: 0.0010 - 696ms/epoch - 174ms/step\n",
            "Epoch 22/1000\n",
            "4/4 - 1s - loss: 0.7678 - mse: 0.7237 - val_loss: 0.8757 - val_mse: 0.8757 - lr: 0.0010 - 704ms/epoch - 176ms/step\n",
            "Epoch 23/1000\n",
            "4/4 - 1s - loss: 0.7621 - mse: 0.7189 - val_loss: 0.8751 - val_mse: 0.8751 - lr: 0.0010 - 701ms/epoch - 175ms/step\n",
            "Epoch 24/1000\n",
            "4/4 - 1s - loss: 0.7525 - mse: 0.7099 - val_loss: 0.8725 - val_mse: 0.8725 - lr: 0.0010 - 691ms/epoch - 173ms/step\n",
            "Epoch 25/1000\n",
            "4/4 - 1s - loss: 0.7424 - mse: 0.7002 - val_loss: 0.8689 - val_mse: 0.8689 - lr: 0.0010 - 687ms/epoch - 172ms/step\n",
            "Epoch 26/1000\n",
            "4/4 - 1s - loss: 0.7320 - mse: 0.6909 - val_loss: 0.8656 - val_mse: 0.8656 - lr: 0.0010 - 703ms/epoch - 176ms/step\n",
            "Epoch 27/1000\n",
            "4/4 - 1s - loss: 0.7263 - mse: 0.6853 - val_loss: 0.8626 - val_mse: 0.8626 - lr: 0.0010 - 695ms/epoch - 174ms/step\n",
            "Epoch 28/1000\n",
            "4/4 - 1s - loss: 0.7206 - mse: 0.6804 - val_loss: 0.8598 - val_mse: 0.8598 - lr: 0.0010 - 700ms/epoch - 175ms/step\n",
            "Epoch 29/1000\n",
            "4/4 - 1s - loss: 0.7092 - mse: 0.6699 - val_loss: 0.8550 - val_mse: 0.8550 - lr: 0.0010 - 701ms/epoch - 175ms/step\n",
            "Epoch 30/1000\n",
            "4/4 - 1s - loss: 0.7032 - mse: 0.6641 - val_loss: 0.8510 - val_mse: 0.8510 - lr: 0.0010 - 689ms/epoch - 172ms/step\n",
            "Epoch 31/1000\n",
            "4/4 - 1s - loss: 0.6946 - mse: 0.6562 - val_loss: 0.8478 - val_mse: 0.8478 - lr: 0.0010 - 683ms/epoch - 171ms/step\n",
            "Epoch 32/1000\n",
            "4/4 - 1s - loss: 0.6892 - mse: 0.6512 - val_loss: 0.8419 - val_mse: 0.8419 - lr: 0.0010 - 686ms/epoch - 172ms/step\n",
            "Epoch 33/1000\n",
            "4/4 - 1s - loss: 0.6812 - mse: 0.6439 - val_loss: 0.8367 - val_mse: 0.8367 - lr: 0.0010 - 695ms/epoch - 174ms/step\n",
            "Epoch 34/1000\n",
            "4/4 - 1s - loss: 0.6726 - mse: 0.6360 - val_loss: 0.8325 - val_mse: 0.8325 - lr: 0.0010 - 696ms/epoch - 174ms/step\n",
            "Epoch 35/1000\n",
            "4/4 - 1s - loss: 0.6722 - mse: 0.6352 - val_loss: 0.8286 - val_mse: 0.8286 - lr: 0.0010 - 701ms/epoch - 175ms/step\n",
            "Epoch 36/1000\n",
            "4/4 - 1s - loss: 0.6624 - mse: 0.6262 - val_loss: 0.8249 - val_mse: 0.8249 - lr: 0.0010 - 706ms/epoch - 177ms/step\n",
            "Epoch 37/1000\n",
            "4/4 - 1s - loss: 0.6625 - mse: 0.6264 - val_loss: 0.8206 - val_mse: 0.8206 - lr: 0.0010 - 688ms/epoch - 172ms/step\n",
            "Epoch 38/1000\n",
            "4/4 - 1s - loss: 0.6529 - mse: 0.6175 - val_loss: 0.8149 - val_mse: 0.8149 - lr: 0.0010 - 693ms/epoch - 173ms/step\n",
            "Epoch 39/1000\n",
            "4/4 - 1s - loss: 0.6481 - mse: 0.6130 - val_loss: 0.8097 - val_mse: 0.8097 - lr: 0.0010 - 701ms/epoch - 175ms/step\n",
            "Epoch 40/1000\n",
            "4/4 - 1s - loss: 0.6393 - mse: 0.6048 - val_loss: 0.8042 - val_mse: 0.8042 - lr: 0.0010 - 716ms/epoch - 179ms/step\n",
            "Epoch 41/1000\n",
            "4/4 - 1s - loss: 0.6356 - mse: 0.6012 - val_loss: 0.7992 - val_mse: 0.7992 - lr: 0.0010 - 683ms/epoch - 171ms/step\n",
            "Epoch 42/1000\n",
            "4/4 - 1s - loss: 0.6321 - mse: 0.5980 - val_loss: 0.7932 - val_mse: 0.7932 - lr: 0.0010 - 694ms/epoch - 173ms/step\n",
            "Epoch 43/1000\n",
            "4/4 - 1s - loss: 0.6250 - mse: 0.5913 - val_loss: 0.7866 - val_mse: 0.7866 - lr: 0.0010 - 691ms/epoch - 173ms/step\n",
            "Epoch 44/1000\n",
            "4/4 - 1s - loss: 0.6220 - mse: 0.5881 - val_loss: 0.7802 - val_mse: 0.7802 - lr: 0.0010 - 691ms/epoch - 173ms/step\n",
            "Epoch 45/1000\n",
            "4/4 - 1s - loss: 0.6170 - mse: 0.5834 - val_loss: 0.7742 - val_mse: 0.7742 - lr: 0.0010 - 707ms/epoch - 177ms/step\n",
            "Epoch 46/1000\n",
            "4/4 - 1s - loss: 0.6117 - mse: 0.5787 - val_loss: 0.7685 - val_mse: 0.7685 - lr: 0.0010 - 707ms/epoch - 177ms/step\n",
            "Epoch 47/1000\n",
            "4/4 - 1s - loss: 0.6065 - mse: 0.5741 - val_loss: 0.7622 - val_mse: 0.7622 - lr: 0.0010 - 704ms/epoch - 176ms/step\n",
            "Epoch 48/1000\n",
            "4/4 - 1s - loss: 0.6050 - mse: 0.5727 - val_loss: 0.7553 - val_mse: 0.7553 - lr: 0.0010 - 710ms/epoch - 178ms/step\n",
            "Epoch 49/1000\n",
            "4/4 - 1s - loss: 0.5971 - mse: 0.5651 - val_loss: 0.7467 - val_mse: 0.7467 - lr: 0.0010 - 715ms/epoch - 179ms/step\n",
            "Epoch 50/1000\n",
            "4/4 - 1s - loss: 0.5955 - mse: 0.5637 - val_loss: 0.7399 - val_mse: 0.7399 - lr: 0.0010 - 691ms/epoch - 173ms/step\n",
            "Epoch 51/1000\n",
            "4/4 - 1s - loss: 0.5889 - mse: 0.5575 - val_loss: 0.7346 - val_mse: 0.7346 - lr: 0.0010 - 708ms/epoch - 177ms/step\n",
            "Epoch 52/1000\n",
            "4/4 - 1s - loss: 0.5873 - mse: 0.5559 - val_loss: 0.7279 - val_mse: 0.7279 - lr: 0.0010 - 698ms/epoch - 174ms/step\n",
            "Epoch 53/1000\n",
            "4/4 - 1s - loss: 0.5826 - mse: 0.5514 - val_loss: 0.7201 - val_mse: 0.7201 - lr: 0.0010 - 689ms/epoch - 172ms/step\n",
            "Epoch 54/1000\n",
            "4/4 - 1s - loss: 0.5775 - mse: 0.5469 - val_loss: 0.7119 - val_mse: 0.7119 - lr: 0.0010 - 686ms/epoch - 171ms/step\n",
            "Epoch 55/1000\n",
            "4/4 - 1s - loss: 0.5746 - mse: 0.5441 - val_loss: 0.7055 - val_mse: 0.7055 - lr: 0.0010 - 677ms/epoch - 169ms/step\n",
            "Epoch 56/1000\n",
            "4/4 - 1s - loss: 0.5699 - mse: 0.5395 - val_loss: 0.6994 - val_mse: 0.6994 - lr: 0.0010 - 691ms/epoch - 173ms/step\n",
            "Epoch 57/1000\n",
            "4/4 - 1s - loss: 0.5680 - mse: 0.5378 - val_loss: 0.6942 - val_mse: 0.6942 - lr: 0.0010 - 704ms/epoch - 176ms/step\n",
            "Epoch 58/1000\n",
            "4/4 - 1s - loss: 0.5649 - mse: 0.5350 - val_loss: 0.6879 - val_mse: 0.6879 - lr: 0.0010 - 683ms/epoch - 171ms/step\n",
            "Epoch 59/1000\n",
            "4/4 - 1s - loss: 0.5602 - mse: 0.5305 - val_loss: 0.6800 - val_mse: 0.6800 - lr: 0.0010 - 689ms/epoch - 172ms/step\n",
            "Epoch 60/1000\n",
            "4/4 - 1s - loss: 0.5556 - mse: 0.5261 - val_loss: 0.6724 - val_mse: 0.6724 - lr: 0.0010 - 679ms/epoch - 170ms/step\n",
            "Epoch 61/1000\n",
            "4/4 - 1s - loss: 0.5557 - mse: 0.5262 - val_loss: 0.6649 - val_mse: 0.6649 - lr: 0.0010 - 704ms/epoch - 176ms/step\n",
            "Epoch 62/1000\n",
            "4/4 - 1s - loss: 0.5509 - mse: 0.5217 - val_loss: 0.6578 - val_mse: 0.6578 - lr: 0.0010 - 686ms/epoch - 171ms/step\n",
            "Epoch 63/1000\n",
            "4/4 - 1s - loss: 0.5474 - mse: 0.5185 - val_loss: 0.6509 - val_mse: 0.6509 - lr: 0.0010 - 682ms/epoch - 171ms/step\n",
            "Epoch 64/1000\n",
            "4/4 - 1s - loss: 0.5459 - mse: 0.5171 - val_loss: 0.6452 - val_mse: 0.6452 - lr: 0.0010 - 675ms/epoch - 169ms/step\n",
            "Epoch 65/1000\n",
            "4/4 - 1s - loss: 0.5434 - mse: 0.5146 - val_loss: 0.6394 - val_mse: 0.6394 - lr: 0.0010 - 690ms/epoch - 172ms/step\n",
            "Epoch 66/1000\n",
            "4/4 - 1s - loss: 0.5393 - mse: 0.5108 - val_loss: 0.6328 - val_mse: 0.6328 - lr: 0.0010 - 688ms/epoch - 172ms/step\n",
            "Epoch 67/1000\n",
            "4/4 - 1s - loss: 0.5335 - mse: 0.5053 - val_loss: 0.6246 - val_mse: 0.6246 - lr: 0.0010 - 699ms/epoch - 175ms/step\n",
            "Epoch 68/1000\n",
            "4/4 - 1s - loss: 0.5364 - mse: 0.5081 - val_loss: 0.6164 - val_mse: 0.6164 - lr: 0.0010 - 682ms/epoch - 170ms/step\n",
            "Epoch 69/1000\n",
            "4/4 - 1s - loss: 0.5327 - mse: 0.5047 - val_loss: 0.6097 - val_mse: 0.6097 - lr: 0.0010 - 686ms/epoch - 172ms/step\n",
            "Epoch 70/1000\n",
            "4/4 - 1s - loss: 0.5289 - mse: 0.5010 - val_loss: 0.6049 - val_mse: 0.6049 - lr: 0.0010 - 697ms/epoch - 174ms/step\n",
            "Epoch 71/1000\n",
            "4/4 - 1s - loss: 0.5259 - mse: 0.4981 - val_loss: 0.5996 - val_mse: 0.5996 - lr: 0.0010 - 688ms/epoch - 172ms/step\n",
            "Epoch 72/1000\n",
            "4/4 - 1s - loss: 0.5248 - mse: 0.4971 - val_loss: 0.5928 - val_mse: 0.5928 - lr: 0.0010 - 697ms/epoch - 174ms/step\n",
            "Epoch 73/1000\n",
            "4/4 - 1s - loss: 0.5214 - mse: 0.4940 - val_loss: 0.5861 - val_mse: 0.5861 - lr: 0.0010 - 688ms/epoch - 172ms/step\n",
            "Epoch 74/1000\n",
            "4/4 - 1s - loss: 0.5200 - mse: 0.4926 - val_loss: 0.5804 - val_mse: 0.5804 - lr: 0.0010 - 688ms/epoch - 172ms/step\n",
            "Epoch 75/1000\n",
            "4/4 - 1s - loss: 0.5179 - mse: 0.4905 - val_loss: 0.5748 - val_mse: 0.5748 - lr: 0.0010 - 684ms/epoch - 171ms/step\n",
            "Epoch 76/1000\n",
            "4/4 - 1s - loss: 0.5163 - mse: 0.4891 - val_loss: 0.5690 - val_mse: 0.5690 - lr: 0.0010 - 696ms/epoch - 174ms/step\n",
            "Epoch 77/1000\n",
            "4/4 - 1s - loss: 0.5124 - mse: 0.4854 - val_loss: 0.5622 - val_mse: 0.5622 - lr: 0.0010 - 682ms/epoch - 170ms/step\n",
            "Epoch 78/1000\n",
            "4/4 - 1s - loss: 0.5120 - mse: 0.4850 - val_loss: 0.5569 - val_mse: 0.5569 - lr: 0.0010 - 680ms/epoch - 170ms/step\n",
            "Epoch 79/1000\n",
            "4/4 - 1s - loss: 0.5103 - mse: 0.4835 - val_loss: 0.5516 - val_mse: 0.5516 - lr: 0.0010 - 684ms/epoch - 171ms/step\n",
            "Epoch 80/1000\n",
            "4/4 - 1s - loss: 0.5068 - mse: 0.4802 - val_loss: 0.5453 - val_mse: 0.5453 - lr: 0.0010 - 696ms/epoch - 174ms/step\n",
            "Epoch 81/1000\n",
            "4/4 - 1s - loss: 0.5041 - mse: 0.4776 - val_loss: 0.5396 - val_mse: 0.5396 - lr: 0.0010 - 686ms/epoch - 171ms/step\n",
            "Epoch 82/1000\n",
            "4/4 - 1s - loss: 0.5018 - mse: 0.4753 - val_loss: 0.5349 - val_mse: 0.5349 - lr: 0.0010 - 690ms/epoch - 173ms/step\n",
            "Epoch 83/1000\n",
            "4/4 - 1s - loss: 0.5013 - mse: 0.4749 - val_loss: 0.5305 - val_mse: 0.5305 - lr: 0.0010 - 690ms/epoch - 172ms/step\n",
            "Epoch 84/1000\n",
            "4/4 - 1s - loss: 0.4990 - mse: 0.4727 - val_loss: 0.5254 - val_mse: 0.5254 - lr: 0.0010 - 697ms/epoch - 174ms/step\n",
            "Epoch 85/1000\n",
            "4/4 - 1s - loss: 0.4989 - mse: 0.4726 - val_loss: 0.5200 - val_mse: 0.5200 - lr: 0.0010 - 692ms/epoch - 173ms/step\n",
            "Epoch 86/1000\n",
            "4/4 - 1s - loss: 0.4938 - mse: 0.4678 - val_loss: 0.5150 - val_mse: 0.5150 - lr: 0.0010 - 696ms/epoch - 174ms/step\n",
            "Epoch 87/1000\n",
            "4/4 - 1s - loss: 0.4934 - mse: 0.4673 - val_loss: 0.5105 - val_mse: 0.5105 - lr: 0.0010 - 700ms/epoch - 175ms/step\n",
            "Epoch 88/1000\n",
            "4/4 - 1s - loss: 0.4931 - mse: 0.4672 - val_loss: 0.5053 - val_mse: 0.5053 - lr: 0.0010 - 694ms/epoch - 173ms/step\n",
            "Epoch 89/1000\n",
            "4/4 - 1s - loss: 0.4901 - mse: 0.4642 - val_loss: 0.5003 - val_mse: 0.5003 - lr: 0.0010 - 686ms/epoch - 171ms/step\n",
            "Epoch 90/1000\n",
            "4/4 - 1s - loss: 0.4897 - mse: 0.4639 - val_loss: 0.4978 - val_mse: 0.4978 - lr: 0.0010 - 682ms/epoch - 171ms/step\n",
            "Epoch 91/1000\n",
            "4/4 - 1s - loss: 0.4867 - mse: 0.4611 - val_loss: 0.4933 - val_mse: 0.4933 - lr: 0.0010 - 690ms/epoch - 173ms/step\n",
            "Epoch 92/1000\n",
            "4/4 - 1s - loss: 0.4858 - mse: 0.4602 - val_loss: 0.4897 - val_mse: 0.4897 - lr: 0.0010 - 712ms/epoch - 178ms/step\n",
            "Epoch 93/1000\n",
            "4/4 - 1s - loss: 0.4820 - mse: 0.4568 - val_loss: 0.4859 - val_mse: 0.4859 - lr: 0.0010 - 717ms/epoch - 179ms/step\n",
            "Epoch 94/1000\n",
            "4/4 - 1s - loss: 0.4822 - mse: 0.4567 - val_loss: 0.4814 - val_mse: 0.4814 - lr: 0.0010 - 706ms/epoch - 177ms/step\n",
            "Epoch 95/1000\n",
            "4/4 - 1s - loss: 0.4806 - mse: 0.4553 - val_loss: 0.4790 - val_mse: 0.4790 - lr: 0.0010 - 706ms/epoch - 177ms/step\n",
            "Epoch 96/1000\n",
            "4/4 - 1s - loss: 0.4802 - mse: 0.4549 - val_loss: 0.4757 - val_mse: 0.4757 - lr: 0.0010 - 694ms/epoch - 174ms/step\n",
            "Epoch 97/1000\n",
            "4/4 - 1s - loss: 0.4780 - mse: 0.4528 - val_loss: 0.4719 - val_mse: 0.4719 - lr: 0.0010 - 688ms/epoch - 172ms/step\n",
            "Epoch 98/1000\n",
            "4/4 - 1s - loss: 0.4774 - mse: 0.4523 - val_loss: 0.4680 - val_mse: 0.4680 - lr: 0.0010 - 708ms/epoch - 177ms/step\n",
            "Epoch 99/1000\n",
            "4/4 - 1s - loss: 0.4759 - mse: 0.4508 - val_loss: 0.4659 - val_mse: 0.4659 - lr: 0.0010 - 681ms/epoch - 170ms/step\n",
            "Epoch 100/1000\n",
            "4/4 - 1s - loss: 0.4735 - mse: 0.4486 - val_loss: 0.4633 - val_mse: 0.4633 - lr: 0.0010 - 679ms/epoch - 170ms/step\n",
            "Epoch 101/1000\n",
            "4/4 - 1s - loss: 0.4731 - mse: 0.4482 - val_loss: 0.4598 - val_mse: 0.4598 - lr: 0.0010 - 682ms/epoch - 171ms/step\n",
            "Epoch 102/1000\n",
            "4/4 - 1s - loss: 0.4724 - mse: 0.4474 - val_loss: 0.4551 - val_mse: 0.4551 - lr: 0.0010 - 690ms/epoch - 173ms/step\n",
            "Epoch 103/1000\n",
            "4/4 - 1s - loss: 0.4701 - mse: 0.4453 - val_loss: 0.4510 - val_mse: 0.4510 - lr: 0.0010 - 690ms/epoch - 173ms/step\n",
            "Epoch 104/1000\n",
            "4/4 - 1s - loss: 0.4706 - mse: 0.4458 - val_loss: 0.4503 - val_mse: 0.4503 - lr: 0.0010 - 692ms/epoch - 173ms/step\n",
            "Epoch 105/1000\n",
            "4/4 - 1s - loss: 0.4685 - mse: 0.4436 - val_loss: 0.4481 - val_mse: 0.4481 - lr: 0.0010 - 686ms/epoch - 171ms/step\n",
            "Epoch 106/1000\n",
            "4/4 - 1s - loss: 0.4674 - mse: 0.4427 - val_loss: 0.4453 - val_mse: 0.4453 - lr: 0.0010 - 690ms/epoch - 172ms/step\n",
            "Epoch 107/1000\n",
            "4/4 - 1s - loss: 0.4674 - mse: 0.4428 - val_loss: 0.4423 - val_mse: 0.4423 - lr: 0.0010 - 712ms/epoch - 178ms/step\n",
            "Epoch 108/1000\n",
            "4/4 - 1s - loss: 0.4653 - mse: 0.4407 - val_loss: 0.4392 - val_mse: 0.4392 - lr: 0.0010 - 696ms/epoch - 174ms/step\n",
            "Epoch 109/1000\n",
            "4/4 - 1s - loss: 0.4635 - mse: 0.4392 - val_loss: 0.4382 - val_mse: 0.4382 - lr: 0.0010 - 692ms/epoch - 173ms/step\n",
            "Epoch 110/1000\n",
            "4/4 - 1s - loss: 0.4633 - mse: 0.4388 - val_loss: 0.4361 - val_mse: 0.4361 - lr: 0.0010 - 692ms/epoch - 173ms/step\n",
            "Epoch 111/1000\n",
            "4/4 - 1s - loss: 0.4621 - mse: 0.4377 - val_loss: 0.4329 - val_mse: 0.4329 - lr: 0.0010 - 702ms/epoch - 176ms/step\n",
            "Epoch 112/1000\n",
            "4/4 - 1s - loss: 0.4609 - mse: 0.4366 - val_loss: 0.4320 - val_mse: 0.4320 - lr: 0.0010 - 707ms/epoch - 177ms/step\n",
            "Epoch 113/1000\n",
            "4/4 - 1s - loss: 0.4605 - mse: 0.4362 - val_loss: 0.4299 - val_mse: 0.4299 - lr: 0.0010 - 699ms/epoch - 175ms/step\n",
            "Epoch 114/1000\n",
            "4/4 - 1s - loss: 0.4593 - mse: 0.4351 - val_loss: 0.4263 - val_mse: 0.4263 - lr: 0.0010 - 700ms/epoch - 175ms/step\n",
            "Epoch 115/1000\n",
            "4/4 - 1s - loss: 0.4578 - mse: 0.4336 - val_loss: 0.4259 - val_mse: 0.4259 - lr: 0.0010 - 697ms/epoch - 174ms/step\n",
            "Epoch 116/1000\n",
            "4/4 - 1s - loss: 0.4575 - mse: 0.4332 - val_loss: 0.4263 - val_mse: 0.4263 - lr: 0.0010 - 696ms/epoch - 174ms/step\n",
            "Epoch 117/1000\n",
            "4/4 - 1s - loss: 0.4569 - mse: 0.4327 - val_loss: 0.4220 - val_mse: 0.4220 - lr: 0.0010 - 692ms/epoch - 173ms/step\n",
            "Epoch 118/1000\n",
            "4/4 - 1s - loss: 0.4562 - mse: 0.4322 - val_loss: 0.4182 - val_mse: 0.4182 - lr: 0.0010 - 706ms/epoch - 176ms/step\n",
            "Epoch 119/1000\n",
            "4/4 - 1s - loss: 0.4543 - mse: 0.4303 - val_loss: 0.4201 - val_mse: 0.4201 - lr: 0.0010 - 699ms/epoch - 175ms/step\n",
            "Epoch 120/1000\n",
            "4/4 - 1s - loss: 0.4542 - mse: 0.4302 - val_loss: 0.4175 - val_mse: 0.4175 - lr: 0.0010 - 695ms/epoch - 174ms/step\n",
            "Epoch 121/1000\n",
            "4/4 - 1s - loss: 0.4521 - mse: 0.4283 - val_loss: 0.4167 - val_mse: 0.4167 - lr: 0.0010 - 708ms/epoch - 177ms/step\n",
            "Epoch 122/1000\n",
            "4/4 - 1s - loss: 0.4534 - mse: 0.4295 - val_loss: 0.4154 - val_mse: 0.4154 - lr: 0.0010 - 686ms/epoch - 171ms/step\n",
            "Epoch 123/1000\n",
            "4/4 - 1s - loss: 0.4516 - mse: 0.4279 - val_loss: 0.4133 - val_mse: 0.4133 - lr: 0.0010 - 699ms/epoch - 175ms/step\n",
            "Epoch 124/1000\n",
            "4/4 - 1s - loss: 0.4502 - mse: 0.4265 - val_loss: 0.4093 - val_mse: 0.4093 - lr: 0.0010 - 694ms/epoch - 174ms/step\n",
            "Epoch 125/1000\n",
            "4/4 - 1s - loss: 0.4505 - mse: 0.4267 - val_loss: 0.4104 - val_mse: 0.4104 - lr: 0.0010 - 699ms/epoch - 175ms/step\n",
            "Epoch 126/1000\n",
            "4/4 - 1s - loss: 0.4487 - mse: 0.4249 - val_loss: 0.4107 - val_mse: 0.4107 - lr: 0.0010 - 701ms/epoch - 175ms/step\n",
            "Epoch 127/1000\n",
            "4/4 - 1s - loss: 0.4489 - mse: 0.4251 - val_loss: 0.4071 - val_mse: 0.4071 - lr: 0.0010 - 688ms/epoch - 172ms/step\n",
            "Epoch 128/1000\n",
            "4/4 - 1s - loss: 0.4480 - mse: 0.4244 - val_loss: 0.4078 - val_mse: 0.4078 - lr: 0.0010 - 697ms/epoch - 174ms/step\n",
            "Epoch 129/1000\n",
            "4/4 - 1s - loss: 0.4467 - mse: 0.4231 - val_loss: 0.4059 - val_mse: 0.4059 - lr: 0.0010 - 689ms/epoch - 172ms/step\n",
            "Epoch 130/1000\n",
            "4/4 - 1s - loss: 0.4463 - mse: 0.4227 - val_loss: 0.4048 - val_mse: 0.4048 - lr: 0.0010 - 700ms/epoch - 175ms/step\n",
            "Epoch 131/1000\n",
            "4/4 - 1s - loss: 0.4461 - mse: 0.4225 - val_loss: 0.4034 - val_mse: 0.4034 - lr: 0.0010 - 694ms/epoch - 174ms/step\n",
            "Epoch 132/1000\n",
            "4/4 - 1s - loss: 0.4445 - mse: 0.4210 - val_loss: 0.4011 - val_mse: 0.4011 - lr: 0.0010 - 684ms/epoch - 171ms/step\n",
            "Epoch 133/1000\n",
            "4/4 - 1s - loss: 0.4430 - mse: 0.4196 - val_loss: 0.4019 - val_mse: 0.4019 - lr: 0.0010 - 698ms/epoch - 174ms/step\n",
            "Epoch 134/1000\n",
            "4/4 - 1s - loss: 0.4438 - mse: 0.4204 - val_loss: 0.4014 - val_mse: 0.4014 - lr: 0.0010 - 686ms/epoch - 172ms/step\n",
            "Epoch 135/1000\n",
            "4/4 - 1s - loss: 0.4447 - mse: 0.4213 - val_loss: 0.3999 - val_mse: 0.3999 - lr: 0.0010 - 692ms/epoch - 173ms/step\n",
            "Epoch 136/1000\n",
            "4/4 - 1s - loss: 0.4422 - mse: 0.4189 - val_loss: 0.3992 - val_mse: 0.3992 - lr: 0.0010 - 701ms/epoch - 175ms/step\n",
            "Epoch 137/1000\n",
            "4/4 - 1s - loss: 0.4419 - mse: 0.4187 - val_loss: 0.4000 - val_mse: 0.4000 - lr: 0.0010 - 689ms/epoch - 172ms/step\n",
            "Epoch 138/1000\n",
            "4/4 - 1s - loss: 0.4425 - mse: 0.4190 - val_loss: 0.3974 - val_mse: 0.3974 - lr: 0.0010 - 689ms/epoch - 172ms/step\n",
            "Epoch 139/1000\n",
            "4/4 - 1s - loss: 0.4417 - mse: 0.4184 - val_loss: 0.3963 - val_mse: 0.3963 - lr: 0.0010 - 699ms/epoch - 175ms/step\n",
            "Epoch 140/1000\n",
            "4/4 - 1s - loss: 0.4410 - mse: 0.4177 - val_loss: 0.3974 - val_mse: 0.3974 - lr: 0.0010 - 703ms/epoch - 176ms/step\n",
            "Epoch 141/1000\n",
            "4/4 - 1s - loss: 0.4390 - mse: 0.4158 - val_loss: 0.3952 - val_mse: 0.3952 - lr: 0.0010 - 712ms/epoch - 178ms/step\n",
            "Epoch 142/1000\n",
            "4/4 - 1s - loss: 0.4402 - mse: 0.4170 - val_loss: 0.3953 - val_mse: 0.3953 - lr: 0.0010 - 698ms/epoch - 175ms/step\n",
            "Epoch 143/1000\n",
            "4/4 - 1s - loss: 0.4396 - mse: 0.4163 - val_loss: 0.3939 - val_mse: 0.3939 - lr: 0.0010 - 706ms/epoch - 176ms/step\n",
            "Epoch 144/1000\n",
            "4/4 - 1s - loss: 0.4385 - mse: 0.4153 - val_loss: 0.3935 - val_mse: 0.3935 - lr: 0.0010 - 692ms/epoch - 173ms/step\n",
            "Epoch 145/1000\n",
            "4/4 - 1s - loss: 0.4384 - mse: 0.4152 - val_loss: 0.3937 - val_mse: 0.3937 - lr: 0.0010 - 704ms/epoch - 176ms/step\n",
            "Epoch 146/1000\n",
            "4/4 - 1s - loss: 0.4389 - mse: 0.4157 - val_loss: 0.3919 - val_mse: 0.3919 - lr: 0.0010 - 696ms/epoch - 174ms/step\n",
            "Epoch 147/1000\n",
            "4/4 - 1s - loss: 0.4377 - mse: 0.4146 - val_loss: 0.3914 - val_mse: 0.3914 - lr: 0.0010 - 691ms/epoch - 173ms/step\n",
            "Epoch 148/1000\n",
            "4/4 - 1s - loss: 0.4369 - mse: 0.4138 - val_loss: 0.3914 - val_mse: 0.3914 - lr: 0.0010 - 706ms/epoch - 176ms/step\n",
            "Epoch 149/1000\n",
            "4/4 - 1s - loss: 0.4356 - mse: 0.4126 - val_loss: 0.3904 - val_mse: 0.3904 - lr: 0.0010 - 700ms/epoch - 175ms/step\n",
            "Epoch 150/1000\n",
            "4/4 - 1s - loss: 0.4357 - mse: 0.4125 - val_loss: 0.3901 - val_mse: 0.3901 - lr: 0.0010 - 708ms/epoch - 177ms/step\n",
            "Epoch 151/1000\n",
            "4/4 - 1s - loss: 0.4360 - mse: 0.4129 - val_loss: 0.3899 - val_mse: 0.3899 - lr: 0.0010 - 689ms/epoch - 172ms/step\n",
            "Epoch 152/1000\n",
            "4/4 - 1s - loss: 0.4353 - mse: 0.4123 - val_loss: 0.3894 - val_mse: 0.3894 - lr: 0.0010 - 685ms/epoch - 171ms/step\n",
            "Epoch 153/1000\n",
            "4/4 - 1s - loss: 0.4350 - mse: 0.4119 - val_loss: 0.3886 - val_mse: 0.3886 - lr: 0.0010 - 683ms/epoch - 171ms/step\n",
            "Epoch 154/1000\n",
            "4/4 - 1s - loss: 0.4342 - mse: 0.4112 - val_loss: 0.3890 - val_mse: 0.3890 - lr: 0.0010 - 687ms/epoch - 172ms/step\n",
            "Epoch 155/1000\n",
            "4/4 - 1s - loss: 0.4348 - mse: 0.4118 - val_loss: 0.3889 - val_mse: 0.3889 - lr: 0.0010 - 711ms/epoch - 178ms/step\n",
            "Epoch 156/1000\n",
            "4/4 - 1s - loss: 0.4344 - mse: 0.4116 - val_loss: 0.3869 - val_mse: 0.3869 - lr: 0.0010 - 701ms/epoch - 175ms/step\n",
            "Epoch 157/1000\n",
            "4/4 - 1s - loss: 0.4338 - mse: 0.4108 - val_loss: 0.3873 - val_mse: 0.3873 - lr: 0.0010 - 675ms/epoch - 169ms/step\n",
            "Epoch 158/1000\n",
            "4/4 - 1s - loss: 0.4332 - mse: 0.4103 - val_loss: 0.3872 - val_mse: 0.3872 - lr: 0.0010 - 693ms/epoch - 173ms/step\n",
            "Epoch 159/1000\n",
            "4/4 - 1s - loss: 0.4317 - mse: 0.4089 - val_loss: 0.3866 - val_mse: 0.3866 - lr: 0.0010 - 690ms/epoch - 173ms/step\n",
            "Epoch 160/1000\n",
            "4/4 - 1s - loss: 0.4325 - mse: 0.4098 - val_loss: 0.3871 - val_mse: 0.3871 - lr: 0.0010 - 692ms/epoch - 173ms/step\n",
            "Epoch 161/1000\n",
            "4/4 - 1s - loss: 0.4324 - mse: 0.4095 - val_loss: 0.3864 - val_mse: 0.3864 - lr: 0.0010 - 707ms/epoch - 177ms/step\n",
            "Epoch 162/1000\n",
            "4/4 - 1s - loss: 0.4313 - mse: 0.4085 - val_loss: 0.3861 - val_mse: 0.3861 - lr: 0.0010 - 688ms/epoch - 172ms/step\n",
            "Epoch 163/1000\n",
            "4/4 - 1s - loss: 0.4311 - mse: 0.4083 - val_loss: 0.3867 - val_mse: 0.3867 - lr: 0.0010 - 690ms/epoch - 172ms/step\n",
            "Epoch 164/1000\n",
            "4/4 - 1s - loss: 0.4314 - mse: 0.4085 - val_loss: 0.3859 - val_mse: 0.3859 - lr: 0.0010 - 700ms/epoch - 175ms/step\n",
            "Epoch 165/1000\n",
            "4/4 - 1s - loss: 0.4308 - mse: 0.4080 - val_loss: 0.3850 - val_mse: 0.3850 - lr: 0.0010 - 686ms/epoch - 171ms/step\n",
            "Epoch 166/1000\n",
            "4/4 - 1s - loss: 0.4296 - mse: 0.4069 - val_loss: 0.3850 - val_mse: 0.3850 - lr: 0.0010 - 681ms/epoch - 170ms/step\n",
            "Epoch 167/1000\n",
            "4/4 - 1s - loss: 0.4298 - mse: 0.4071 - val_loss: 0.3851 - val_mse: 0.3851 - lr: 0.0010 - 696ms/epoch - 174ms/step\n",
            "Epoch 168/1000\n",
            "4/4 - 1s - loss: 0.4302 - mse: 0.4074 - val_loss: 0.3843 - val_mse: 0.3843 - lr: 0.0010 - 699ms/epoch - 175ms/step\n",
            "Epoch 169/1000\n",
            "4/4 - 1s - loss: 0.4298 - mse: 0.4071 - val_loss: 0.3849 - val_mse: 0.3849 - lr: 0.0010 - 678ms/epoch - 170ms/step\n",
            "Epoch 170/1000\n",
            "4/4 - 1s - loss: 0.4298 - mse: 0.4070 - val_loss: 0.3842 - val_mse: 0.3842 - lr: 0.0010 - 710ms/epoch - 177ms/step\n",
            "Epoch 171/1000\n",
            "4/4 - 1s - loss: 0.4291 - mse: 0.4064 - val_loss: 0.3838 - val_mse: 0.3838 - lr: 0.0010 - 689ms/epoch - 172ms/step\n",
            "Epoch 172/1000\n",
            "4/4 - 1s - loss: 0.4285 - mse: 0.4058 - val_loss: 0.3846 - val_mse: 0.3846 - lr: 0.0010 - 710ms/epoch - 178ms/step\n",
            "Epoch 173/1000\n",
            "4/4 - 1s - loss: 0.4286 - mse: 0.4059 - val_loss: 0.3839 - val_mse: 0.3839 - lr: 0.0010 - 700ms/epoch - 175ms/step\n",
            "Epoch 174/1000\n",
            "4/4 - 1s - loss: 0.4286 - mse: 0.4060 - val_loss: 0.3833 - val_mse: 0.3833 - lr: 0.0010 - 692ms/epoch - 173ms/step\n",
            "Epoch 175/1000\n",
            "4/4 - 1s - loss: 0.4286 - mse: 0.4058 - val_loss: 0.3836 - val_mse: 0.3836 - lr: 0.0010 - 710ms/epoch - 178ms/step\n",
            "Epoch 176/1000\n",
            "4/4 - 1s - loss: 0.4278 - mse: 0.4052 - val_loss: 0.3838 - val_mse: 0.3838 - lr: 0.0010 - 700ms/epoch - 175ms/step\n",
            "Epoch 177/1000\n",
            "4/4 - 1s - loss: 0.4279 - mse: 0.4053 - val_loss: 0.3831 - val_mse: 0.3831 - lr: 0.0010 - 700ms/epoch - 175ms/step\n",
            "Epoch 178/1000\n",
            "4/4 - 1s - loss: 0.4275 - mse: 0.4049 - val_loss: 0.3831 - val_mse: 0.3831 - lr: 0.0010 - 684ms/epoch - 171ms/step\n",
            "Epoch 179/1000\n",
            "4/4 - 1s - loss: 0.4275 - mse: 0.4049 - val_loss: 0.3834 - val_mse: 0.3834 - lr: 0.0010 - 704ms/epoch - 176ms/step\n",
            "Epoch 180/1000\n",
            "4/4 - 1s - loss: 0.4273 - mse: 0.4047 - val_loss: 0.3829 - val_mse: 0.3829 - lr: 0.0010 - 694ms/epoch - 174ms/step\n",
            "Epoch 181/1000\n",
            "4/4 - 1s - loss: 0.4275 - mse: 0.4049 - val_loss: 0.3827 - val_mse: 0.3827 - lr: 0.0010 - 679ms/epoch - 170ms/step\n",
            "Epoch 182/1000\n",
            "4/4 - 1s - loss: 0.4264 - mse: 0.4038 - val_loss: 0.3832 - val_mse: 0.3832 - lr: 0.0010 - 681ms/epoch - 170ms/step\n",
            "Epoch 183/1000\n",
            "4/4 - 1s - loss: 0.4264 - mse: 0.4038 - val_loss: 0.3836 - val_mse: 0.3836 - lr: 0.0010 - 706ms/epoch - 176ms/step\n",
            "Epoch 184/1000\n",
            "4/4 - 1s - loss: 0.4272 - mse: 0.4046 - val_loss: 0.3827 - val_mse: 0.3827 - lr: 0.0010 - 705ms/epoch - 176ms/step\n",
            "Epoch 185/1000\n",
            "4/4 - 1s - loss: 0.4260 - mse: 0.4034 - val_loss: 0.3827 - val_mse: 0.3827 - lr: 0.0010 - 685ms/epoch - 171ms/step\n",
            "Epoch 186/1000\n",
            "4/4 - 1s - loss: 0.4254 - mse: 0.4029 - val_loss: 0.3831 - val_mse: 0.3831 - lr: 0.0010 - 703ms/epoch - 176ms/step\n",
            "Epoch 187/1000\n",
            "4/4 - 1s - loss: 0.4262 - mse: 0.4036 - val_loss: 0.3824 - val_mse: 0.3824 - lr: 0.0010 - 700ms/epoch - 175ms/step\n",
            "Epoch 188/1000\n",
            "4/4 - 1s - loss: 0.4246 - mse: 0.4022 - val_loss: 0.3825 - val_mse: 0.3825 - lr: 0.0010 - 702ms/epoch - 176ms/step\n",
            "Epoch 189/1000\n",
            "4/4 - 1s - loss: 0.4245 - mse: 0.4021 - val_loss: 0.3827 - val_mse: 0.3827 - lr: 0.0010 - 699ms/epoch - 175ms/step\n",
            "Epoch 190/1000\n",
            "4/4 - 1s - loss: 0.4247 - mse: 0.4022 - val_loss: 0.3824 - val_mse: 0.3824 - lr: 0.0010 - 707ms/epoch - 177ms/step\n",
            "Epoch 191/1000\n",
            "4/4 - 1s - loss: 0.4246 - mse: 0.4023 - val_loss: 0.3823 - val_mse: 0.3823 - lr: 0.0010 - 690ms/epoch - 173ms/step\n",
            "Epoch 192/1000\n",
            "4/4 - 1s - loss: 0.4245 - mse: 0.4020 - val_loss: 0.3822 - val_mse: 0.3822 - lr: 0.0010 - 690ms/epoch - 172ms/step\n",
            "Epoch 193/1000\n",
            "4/4 - 1s - loss: 0.4242 - mse: 0.4019 - val_loss: 0.3819 - val_mse: 0.3819 - lr: 0.0010 - 700ms/epoch - 175ms/step\n",
            "Epoch 194/1000\n",
            "4/4 - 1s - loss: 0.4246 - mse: 0.4021 - val_loss: 0.3820 - val_mse: 0.3820 - lr: 0.0010 - 700ms/epoch - 175ms/step\n",
            "Epoch 195/1000\n",
            "4/4 - 1s - loss: 0.4243 - mse: 0.4018 - val_loss: 0.3822 - val_mse: 0.3822 - lr: 0.0010 - 685ms/epoch - 171ms/step\n",
            "Epoch 196/1000\n",
            "4/4 - 1s - loss: 0.4241 - mse: 0.4018 - val_loss: 0.3823 - val_mse: 0.3823 - lr: 0.0010 - 697ms/epoch - 174ms/step\n",
            "Epoch 197/1000\n",
            "4/4 - 1s - loss: 0.4241 - mse: 0.4017 - val_loss: 0.3819 - val_mse: 0.3819 - lr: 0.0010 - 682ms/epoch - 171ms/step\n",
            "Epoch 198/1000\n",
            "4/4 - 1s - loss: 0.4243 - mse: 0.4018 - val_loss: 0.3817 - val_mse: 0.3817 - lr: 0.0010 - 689ms/epoch - 172ms/step\n",
            "Epoch 199/1000\n",
            "4/4 - 1s - loss: 0.4240 - mse: 0.4016 - val_loss: 0.3817 - val_mse: 0.3817 - lr: 0.0010 - 714ms/epoch - 178ms/step\n",
            "Epoch 200/1000\n",
            "4/4 - 1s - loss: 0.4238 - mse: 0.4013 - val_loss: 0.3817 - val_mse: 0.3817 - lr: 0.0010 - 712ms/epoch - 178ms/step\n",
            "Epoch 201/1000\n",
            "4/4 - 1s - loss: 0.4234 - mse: 0.4010 - val_loss: 0.3817 - val_mse: 0.3817 - lr: 0.0010 - 679ms/epoch - 170ms/step\n",
            "Epoch 202/1000\n",
            "4/4 - 1s - loss: 0.4233 - mse: 0.4010 - val_loss: 0.3816 - val_mse: 0.3816 - lr: 0.0010 - 697ms/epoch - 174ms/step\n",
            "Epoch 203/1000\n",
            "4/4 - 1s - loss: 0.4225 - mse: 0.4001 - val_loss: 0.3814 - val_mse: 0.3814 - lr: 0.0010 - 688ms/epoch - 172ms/step\n",
            "Epoch 204/1000\n",
            "4/4 - 1s - loss: 0.4233 - mse: 0.4009 - val_loss: 0.3814 - val_mse: 0.3814 - lr: 0.0010 - 700ms/epoch - 175ms/step\n",
            "Epoch 205/1000\n",
            "4/4 - 1s - loss: 0.4228 - mse: 0.4004 - val_loss: 0.3814 - val_mse: 0.3814 - lr: 0.0010 - 706ms/epoch - 177ms/step\n",
            "Epoch 206/1000\n",
            "4/4 - 1s - loss: 0.4227 - mse: 0.4004 - val_loss: 0.3813 - val_mse: 0.3813 - lr: 0.0010 - 694ms/epoch - 173ms/step\n",
            "Epoch 207/1000\n",
            "4/4 - 1s - loss: 0.4222 - mse: 0.3999 - val_loss: 0.3813 - val_mse: 0.3813 - lr: 0.0010 - 698ms/epoch - 175ms/step\n",
            "Epoch 208/1000\n",
            "4/4 - 1s - loss: 0.4227 - mse: 0.4004 - val_loss: 0.3814 - val_mse: 0.3814 - lr: 0.0010 - 702ms/epoch - 176ms/step\n",
            "Epoch 209/1000\n",
            "4/4 - 1s - loss: 0.4218 - mse: 0.3995 - val_loss: 0.3814 - val_mse: 0.3814 - lr: 0.0010 - 701ms/epoch - 175ms/step\n",
            "Epoch 210/1000\n",
            "4/4 - 1s - loss: 0.4225 - mse: 0.4001 - val_loss: 0.3813 - val_mse: 0.3813 - lr: 0.0010 - 692ms/epoch - 173ms/step\n",
            "Epoch 211/1000\n",
            "4/4 - 1s - loss: 0.4216 - mse: 0.3993 - val_loss: 0.3811 - val_mse: 0.3811 - lr: 0.0010 - 711ms/epoch - 178ms/step\n",
            "Epoch 212/1000\n",
            "4/4 - 1s - loss: 0.4217 - mse: 0.3994 - val_loss: 0.3811 - val_mse: 0.3811 - lr: 0.0010 - 697ms/epoch - 174ms/step\n",
            "Epoch 213/1000\n",
            "4/4 - 1s - loss: 0.4214 - mse: 0.3992 - val_loss: 0.3811 - val_mse: 0.3811 - lr: 0.0010 - 696ms/epoch - 174ms/step\n",
            "Epoch 214/1000\n",
            "4/4 - 1s - loss: 0.4215 - mse: 0.3992 - val_loss: 0.3812 - val_mse: 0.3812 - lr: 0.0010 - 685ms/epoch - 171ms/step\n",
            "Epoch 215/1000\n",
            "4/4 - 1s - loss: 0.4214 - mse: 0.3992 - val_loss: 0.3811 - val_mse: 0.3811 - lr: 0.0010 - 711ms/epoch - 178ms/step\n",
            "Epoch 216/1000\n",
            "4/4 - 1s - loss: 0.4214 - mse: 0.3991 - val_loss: 0.3810 - val_mse: 0.3810 - lr: 0.0010 - 701ms/epoch - 175ms/step\n",
            "Epoch 217/1000\n",
            "4/4 - 1s - loss: 0.4208 - mse: 0.3985 - val_loss: 0.3808 - val_mse: 0.3808 - lr: 0.0010 - 694ms/epoch - 174ms/step\n",
            "Epoch 218/1000\n",
            "4/4 - 1s - loss: 0.4212 - mse: 0.3989 - val_loss: 0.3807 - val_mse: 0.3807 - lr: 0.0010 - 707ms/epoch - 177ms/step\n",
            "Epoch 219/1000\n",
            "4/4 - 1s - loss: 0.4212 - mse: 0.3988 - val_loss: 0.3808 - val_mse: 0.3808 - lr: 0.0010 - 715ms/epoch - 179ms/step\n",
            "Epoch 220/1000\n",
            "4/4 - 1s - loss: 0.4204 - mse: 0.3982 - val_loss: 0.3808 - val_mse: 0.3808 - lr: 0.0010 - 701ms/epoch - 175ms/step\n",
            "Epoch 221/1000\n",
            "4/4 - 1s - loss: 0.4201 - mse: 0.3980 - val_loss: 0.3810 - val_mse: 0.3810 - lr: 0.0010 - 692ms/epoch - 173ms/step\n",
            "Epoch 222/1000\n",
            "4/4 - 1s - loss: 0.4206 - mse: 0.3984 - val_loss: 0.3809 - val_mse: 0.3809 - lr: 0.0010 - 703ms/epoch - 176ms/step\n",
            "Epoch 223/1000\n",
            "4/4 - 1s - loss: 0.4206 - mse: 0.3984 - val_loss: 0.3808 - val_mse: 0.3808 - lr: 0.0010 - 689ms/epoch - 172ms/step\n",
            "Epoch 224/1000\n",
            "4/4 - 1s - loss: 0.4203 - mse: 0.3980 - val_loss: 0.3807 - val_mse: 0.3807 - lr: 0.0010 - 690ms/epoch - 172ms/step\n",
            "Epoch 225/1000\n",
            "4/4 - 1s - loss: 0.4205 - mse: 0.3983 - val_loss: 0.3806 - val_mse: 0.3806 - lr: 0.0010 - 690ms/epoch - 172ms/step\n",
            "Epoch 226/1000\n",
            "4/4 - 1s - loss: 0.4203 - mse: 0.3981 - val_loss: 0.3806 - val_mse: 0.3806 - lr: 0.0010 - 682ms/epoch - 170ms/step\n",
            "Epoch 227/1000\n",
            "4/4 - 1s - loss: 0.4198 - mse: 0.3976 - val_loss: 0.3803 - val_mse: 0.3803 - lr: 0.0010 - 696ms/epoch - 174ms/step\n",
            "Epoch 228/1000\n",
            "4/4 - 1s - loss: 0.4204 - mse: 0.3982 - val_loss: 0.3802 - val_mse: 0.3802 - lr: 0.0010 - 700ms/epoch - 175ms/step\n",
            "Epoch 229/1000\n",
            "4/4 - 1s - loss: 0.4205 - mse: 0.3983 - val_loss: 0.3803 - val_mse: 0.3803 - lr: 0.0010 - 690ms/epoch - 172ms/step\n",
            "Epoch 230/1000\n",
            "4/4 - 1s - loss: 0.4192 - mse: 0.3971 - val_loss: 0.3802 - val_mse: 0.3802 - lr: 0.0010 - 713ms/epoch - 178ms/step\n",
            "Epoch 231/1000\n",
            "4/4 - 1s - loss: 0.4199 - mse: 0.3978 - val_loss: 0.3803 - val_mse: 0.3803 - lr: 0.0010 - 708ms/epoch - 177ms/step\n",
            "Epoch 232/1000\n",
            "4/4 - 1s - loss: 0.4202 - mse: 0.3980 - val_loss: 0.3803 - val_mse: 0.3803 - lr: 0.0010 - 719ms/epoch - 180ms/step\n",
            "Epoch 233/1000\n",
            "4/4 - 1s - loss: 0.4196 - mse: 0.3974 - val_loss: 0.3802 - val_mse: 0.3802 - lr: 0.0010 - 706ms/epoch - 177ms/step\n",
            "Epoch 234/1000\n",
            "4/4 - 1s - loss: 0.4189 - mse: 0.3969 - val_loss: 0.3803 - val_mse: 0.3803 - lr: 0.0010 - 715ms/epoch - 179ms/step\n",
            "Epoch 235/1000\n",
            "\n",
            "Epoch 235: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "4/4 - 1s - loss: 0.4189 - mse: 0.3968 - val_loss: 0.3803 - val_mse: 0.3803 - lr: 0.0010 - 715ms/epoch - 179ms/step\n",
            "Epoch 236/1000\n",
            "4/4 - 1s - loss: 0.4188 - mse: 0.3967 - val_loss: 0.3803 - val_mse: 0.3803 - lr: 1.0000e-04 - 712ms/epoch - 178ms/step\n",
            "Epoch 237/1000\n",
            "4/4 - 1s - loss: 0.4189 - mse: 0.3968 - val_loss: 0.3803 - val_mse: 0.3803 - lr: 1.0000e-04 - 715ms/epoch - 179ms/step\n",
            "Epoch 238/1000\n",
            "4/4 - 1s - loss: 0.4194 - mse: 0.3973 - val_loss: 0.3803 - val_mse: 0.3803 - lr: 1.0000e-04 - 706ms/epoch - 177ms/step\n",
            "Epoch 238: early stopping\n",
            "==================================================\n",
            "Step 6\n",
            "==================================================\n",
            "Epoch 1/1000\n",
            "4/4 - 4s - loss: 2.8829 - mse: 2.7019 - val_loss: 0.9152 - val_mse: 0.9152 - lr: 0.0010 - 4s/epoch - 904ms/step\n",
            "Epoch 2/1000\n",
            "4/4 - 1s - loss: 2.0360 - mse: 1.9165 - val_loss: 0.8693 - val_mse: 0.8693 - lr: 0.0010 - 685ms/epoch - 171ms/step\n",
            "Epoch 3/1000\n",
            "4/4 - 1s - loss: 1.6732 - mse: 1.5795 - val_loss: 0.8576 - val_mse: 0.8576 - lr: 0.0010 - 668ms/epoch - 167ms/step\n",
            "Epoch 4/1000\n",
            "4/4 - 1s - loss: 1.4541 - mse: 1.3725 - val_loss: 0.8495 - val_mse: 0.8495 - lr: 0.0010 - 684ms/epoch - 171ms/step\n",
            "Epoch 5/1000\n",
            "4/4 - 1s - loss: 1.3275 - mse: 1.2526 - val_loss: 0.8389 - val_mse: 0.8389 - lr: 0.0010 - 675ms/epoch - 169ms/step\n",
            "Epoch 6/1000\n",
            "4/4 - 1s - loss: 1.2439 - mse: 1.1742 - val_loss: 0.8293 - val_mse: 0.8293 - lr: 0.0010 - 660ms/epoch - 165ms/step\n",
            "Epoch 7/1000\n",
            "4/4 - 1s - loss: 1.1670 - mse: 1.1018 - val_loss: 0.8224 - val_mse: 0.8224 - lr: 0.0010 - 673ms/epoch - 168ms/step\n",
            "Epoch 8/1000\n",
            "4/4 - 1s - loss: 1.1193 - mse: 1.0570 - val_loss: 0.8177 - val_mse: 0.8177 - lr: 0.0010 - 677ms/epoch - 169ms/step\n",
            "Epoch 9/1000\n",
            "4/4 - 1s - loss: 1.0743 - mse: 1.0149 - val_loss: 0.8134 - val_mse: 0.8134 - lr: 0.0010 - 678ms/epoch - 169ms/step\n",
            "Epoch 10/1000\n",
            "4/4 - 1s - loss: 1.0434 - mse: 0.9859 - val_loss: 0.8080 - val_mse: 0.8080 - lr: 0.0010 - 671ms/epoch - 168ms/step\n",
            "Epoch 11/1000\n",
            "4/4 - 1s - loss: 1.0150 - mse: 0.9588 - val_loss: 0.8006 - val_mse: 0.8006 - lr: 0.0010 - 677ms/epoch - 169ms/step\n",
            "Epoch 12/1000\n",
            "4/4 - 1s - loss: 0.9943 - mse: 0.9397 - val_loss: 0.7925 - val_mse: 0.7925 - lr: 0.0010 - 669ms/epoch - 167ms/step\n",
            "Epoch 13/1000\n",
            "4/4 - 1s - loss: 0.9630 - mse: 0.9107 - val_loss: 0.7856 - val_mse: 0.7856 - lr: 0.0010 - 678ms/epoch - 170ms/step\n",
            "Epoch 14/1000\n",
            "4/4 - 1s - loss: 0.9509 - mse: 0.8992 - val_loss: 0.7801 - val_mse: 0.7801 - lr: 0.0010 - 670ms/epoch - 168ms/step\n",
            "Epoch 15/1000\n",
            "4/4 - 1s - loss: 0.9349 - mse: 0.8842 - val_loss: 0.7750 - val_mse: 0.7750 - lr: 0.0010 - 666ms/epoch - 166ms/step\n",
            "Epoch 16/1000\n",
            "4/4 - 1s - loss: 0.9165 - mse: 0.8669 - val_loss: 0.7707 - val_mse: 0.7707 - lr: 0.0010 - 673ms/epoch - 168ms/step\n",
            "Epoch 17/1000\n",
            "4/4 - 1s - loss: 0.9046 - mse: 0.8558 - val_loss: 0.7653 - val_mse: 0.7653 - lr: 0.0010 - 678ms/epoch - 169ms/step\n",
            "Epoch 18/1000\n",
            "4/4 - 1s - loss: 0.8848 - mse: 0.8374 - val_loss: 0.7595 - val_mse: 0.7595 - lr: 0.0010 - 675ms/epoch - 169ms/step\n",
            "Epoch 19/1000\n",
            "4/4 - 1s - loss: 0.8826 - mse: 0.8347 - val_loss: 0.7535 - val_mse: 0.7535 - lr: 0.0010 - 665ms/epoch - 166ms/step\n",
            "Epoch 20/1000\n",
            "4/4 - 1s - loss: 0.8659 - mse: 0.8197 - val_loss: 0.7482 - val_mse: 0.7482 - lr: 0.0010 - 675ms/epoch - 169ms/step\n",
            "Epoch 21/1000\n",
            "4/4 - 1s - loss: 0.8552 - mse: 0.8091 - val_loss: 0.7445 - val_mse: 0.7445 - lr: 0.0010 - 656ms/epoch - 164ms/step\n",
            "Epoch 22/1000\n",
            "4/4 - 1s - loss: 0.8407 - mse: 0.7956 - val_loss: 0.7409 - val_mse: 0.7409 - lr: 0.0010 - 666ms/epoch - 166ms/step\n",
            "Epoch 23/1000\n",
            "4/4 - 1s - loss: 0.8309 - mse: 0.7860 - val_loss: 0.7359 - val_mse: 0.7359 - lr: 0.0010 - 665ms/epoch - 166ms/step\n",
            "Epoch 24/1000\n",
            "4/4 - 1s - loss: 0.8230 - mse: 0.7792 - val_loss: 0.7299 - val_mse: 0.7299 - lr: 0.0010 - 674ms/epoch - 168ms/step\n",
            "Epoch 25/1000\n",
            "4/4 - 1s - loss: 0.8094 - mse: 0.7667 - val_loss: 0.7249 - val_mse: 0.7249 - lr: 0.0010 - 692ms/epoch - 173ms/step\n",
            "Epoch 26/1000\n",
            "4/4 - 1s - loss: 0.8029 - mse: 0.7600 - val_loss: 0.7208 - val_mse: 0.7208 - lr: 0.0010 - 671ms/epoch - 168ms/step\n",
            "Epoch 27/1000\n",
            "4/4 - 1s - loss: 0.7900 - mse: 0.7481 - val_loss: 0.7165 - val_mse: 0.7165 - lr: 0.0010 - 670ms/epoch - 168ms/step\n",
            "Epoch 28/1000\n",
            "4/4 - 1s - loss: 0.7801 - mse: 0.7388 - val_loss: 0.7102 - val_mse: 0.7102 - lr: 0.0010 - 683ms/epoch - 171ms/step\n",
            "Epoch 29/1000\n",
            "4/4 - 1s - loss: 0.7740 - mse: 0.7328 - val_loss: 0.7044 - val_mse: 0.7044 - lr: 0.0010 - 678ms/epoch - 170ms/step\n",
            "Epoch 30/1000\n",
            "4/4 - 1s - loss: 0.7679 - mse: 0.7273 - val_loss: 0.6997 - val_mse: 0.6997 - lr: 0.0010 - 674ms/epoch - 169ms/step\n",
            "Epoch 31/1000\n",
            "4/4 - 1s - loss: 0.7596 - mse: 0.7194 - val_loss: 0.6951 - val_mse: 0.6951 - lr: 0.0010 - 679ms/epoch - 170ms/step\n",
            "Epoch 32/1000\n",
            "4/4 - 1s - loss: 0.7489 - mse: 0.7093 - val_loss: 0.6901 - val_mse: 0.6901 - lr: 0.0010 - 681ms/epoch - 170ms/step\n",
            "Epoch 33/1000\n",
            "4/4 - 1s - loss: 0.7404 - mse: 0.7020 - val_loss: 0.6852 - val_mse: 0.6852 - lr: 0.0010 - 680ms/epoch - 170ms/step\n",
            "Epoch 34/1000\n",
            "4/4 - 1s - loss: 0.7357 - mse: 0.6970 - val_loss: 0.6795 - val_mse: 0.6795 - lr: 0.0010 - 671ms/epoch - 168ms/step\n",
            "Epoch 35/1000\n",
            "4/4 - 1s - loss: 0.7278 - mse: 0.6897 - val_loss: 0.6739 - val_mse: 0.6739 - lr: 0.0010 - 665ms/epoch - 166ms/step\n",
            "Epoch 36/1000\n",
            "4/4 - 1s - loss: 0.7210 - mse: 0.6835 - val_loss: 0.6702 - val_mse: 0.6702 - lr: 0.0010 - 664ms/epoch - 166ms/step\n",
            "Epoch 37/1000\n",
            "4/4 - 1s - loss: 0.7118 - mse: 0.6745 - val_loss: 0.6663 - val_mse: 0.6663 - lr: 0.0010 - 676ms/epoch - 169ms/step\n",
            "Epoch 38/1000\n",
            "4/4 - 1s - loss: 0.7061 - mse: 0.6689 - val_loss: 0.6626 - val_mse: 0.6626 - lr: 0.0010 - 686ms/epoch - 171ms/step\n",
            "Epoch 39/1000\n",
            "4/4 - 1s - loss: 0.7019 - mse: 0.6650 - val_loss: 0.6574 - val_mse: 0.6574 - lr: 0.0010 - 668ms/epoch - 167ms/step\n",
            "Epoch 40/1000\n",
            "4/4 - 1s - loss: 0.6935 - mse: 0.6572 - val_loss: 0.6509 - val_mse: 0.6509 - lr: 0.0010 - 679ms/epoch - 170ms/step\n",
            "Epoch 41/1000\n",
            "4/4 - 1s - loss: 0.6892 - mse: 0.6530 - val_loss: 0.6448 - val_mse: 0.6448 - lr: 0.0010 - 670ms/epoch - 168ms/step\n",
            "Epoch 42/1000\n",
            "4/4 - 1s - loss: 0.6793 - mse: 0.6438 - val_loss: 0.6405 - val_mse: 0.6405 - lr: 0.0010 - 677ms/epoch - 169ms/step\n",
            "Epoch 43/1000\n",
            "4/4 - 1s - loss: 0.6728 - mse: 0.6376 - val_loss: 0.6359 - val_mse: 0.6359 - lr: 0.0010 - 683ms/epoch - 171ms/step\n",
            "Epoch 44/1000\n",
            "4/4 - 1s - loss: 0.6690 - mse: 0.6342 - val_loss: 0.6311 - val_mse: 0.6311 - lr: 0.0010 - 675ms/epoch - 169ms/step\n",
            "Epoch 45/1000\n",
            "4/4 - 1s - loss: 0.6655 - mse: 0.6310 - val_loss: 0.6252 - val_mse: 0.6252 - lr: 0.0010 - 661ms/epoch - 165ms/step\n",
            "Epoch 46/1000\n",
            "4/4 - 1s - loss: 0.6595 - mse: 0.6254 - val_loss: 0.6174 - val_mse: 0.6174 - lr: 0.0010 - 677ms/epoch - 169ms/step\n",
            "Epoch 47/1000\n",
            "4/4 - 1s - loss: 0.6527 - mse: 0.6188 - val_loss: 0.6117 - val_mse: 0.6117 - lr: 0.0010 - 655ms/epoch - 164ms/step\n",
            "Epoch 48/1000\n",
            "4/4 - 1s - loss: 0.6482 - mse: 0.6145 - val_loss: 0.6082 - val_mse: 0.6082 - lr: 0.0010 - 655ms/epoch - 164ms/step\n",
            "Epoch 49/1000\n",
            "4/4 - 1s - loss: 0.6426 - mse: 0.6092 - val_loss: 0.6038 - val_mse: 0.6038 - lr: 0.0010 - 663ms/epoch - 166ms/step\n",
            "Epoch 50/1000\n",
            "4/4 - 1s - loss: 0.6367 - mse: 0.6037 - val_loss: 0.5972 - val_mse: 0.5972 - lr: 0.0010 - 658ms/epoch - 165ms/step\n",
            "Epoch 51/1000\n",
            "4/4 - 1s - loss: 0.6355 - mse: 0.6024 - val_loss: 0.5901 - val_mse: 0.5901 - lr: 0.0010 - 657ms/epoch - 164ms/step\n",
            "Epoch 52/1000\n",
            "4/4 - 1s - loss: 0.6298 - mse: 0.5970 - val_loss: 0.5850 - val_mse: 0.5850 - lr: 0.0010 - 654ms/epoch - 164ms/step\n",
            "Epoch 53/1000\n",
            "4/4 - 1s - loss: 0.6229 - mse: 0.5904 - val_loss: 0.5807 - val_mse: 0.5807 - lr: 0.0010 - 645ms/epoch - 161ms/step\n",
            "Epoch 54/1000\n",
            "4/4 - 1s - loss: 0.6196 - mse: 0.5876 - val_loss: 0.5763 - val_mse: 0.5763 - lr: 0.0010 - 670ms/epoch - 168ms/step\n",
            "Epoch 55/1000\n",
            "4/4 - 1s - loss: 0.6150 - mse: 0.5829 - val_loss: 0.5702 - val_mse: 0.5702 - lr: 0.0010 - 669ms/epoch - 167ms/step\n",
            "Epoch 56/1000\n",
            "4/4 - 1s - loss: 0.6122 - mse: 0.5805 - val_loss: 0.5642 - val_mse: 0.5642 - lr: 0.0010 - 700ms/epoch - 175ms/step\n",
            "Epoch 57/1000\n",
            "4/4 - 1s - loss: 0.6072 - mse: 0.5757 - val_loss: 0.5582 - val_mse: 0.5582 - lr: 0.0010 - 688ms/epoch - 172ms/step\n",
            "Epoch 58/1000\n",
            "4/4 - 1s - loss: 0.6009 - mse: 0.5697 - val_loss: 0.5533 - val_mse: 0.5533 - lr: 0.0010 - 678ms/epoch - 170ms/step\n",
            "Epoch 59/1000\n",
            "4/4 - 1s - loss: 0.5998 - mse: 0.5688 - val_loss: 0.5486 - val_mse: 0.5486 - lr: 0.0010 - 671ms/epoch - 168ms/step\n",
            "Epoch 60/1000\n",
            "4/4 - 1s - loss: 0.5960 - mse: 0.5652 - val_loss: 0.5440 - val_mse: 0.5440 - lr: 0.0010 - 694ms/epoch - 174ms/step\n",
            "Epoch 61/1000\n",
            "4/4 - 1s - loss: 0.5916 - mse: 0.5610 - val_loss: 0.5384 - val_mse: 0.5384 - lr: 0.0010 - 678ms/epoch - 169ms/step\n",
            "Epoch 62/1000\n",
            "4/4 - 1s - loss: 0.5895 - mse: 0.5589 - val_loss: 0.5335 - val_mse: 0.5335 - lr: 0.0010 - 648ms/epoch - 162ms/step\n",
            "Epoch 63/1000\n",
            "4/4 - 1s - loss: 0.5860 - mse: 0.5557 - val_loss: 0.5275 - val_mse: 0.5275 - lr: 0.0010 - 668ms/epoch - 167ms/step\n",
            "Epoch 64/1000\n",
            "4/4 - 1s - loss: 0.5805 - mse: 0.5504 - val_loss: 0.5219 - val_mse: 0.5219 - lr: 0.0010 - 680ms/epoch - 170ms/step\n",
            "Epoch 65/1000\n",
            "4/4 - 1s - loss: 0.5775 - mse: 0.5475 - val_loss: 0.5177 - val_mse: 0.5177 - lr: 0.0010 - 671ms/epoch - 168ms/step\n",
            "Epoch 66/1000\n",
            "4/4 - 1s - loss: 0.5748 - mse: 0.5449 - val_loss: 0.5137 - val_mse: 0.5137 - lr: 0.0010 - 670ms/epoch - 168ms/step\n",
            "Epoch 67/1000\n",
            "4/4 - 1s - loss: 0.5729 - mse: 0.5432 - val_loss: 0.5092 - val_mse: 0.5092 - lr: 0.0010 - 665ms/epoch - 166ms/step\n",
            "Epoch 68/1000\n",
            "4/4 - 1s - loss: 0.5694 - mse: 0.5398 - val_loss: 0.5050 - val_mse: 0.5050 - lr: 0.0010 - 665ms/epoch - 166ms/step\n",
            "Epoch 69/1000\n",
            "4/4 - 1s - loss: 0.5651 - mse: 0.5359 - val_loss: 0.5001 - val_mse: 0.5001 - lr: 0.0010 - 674ms/epoch - 168ms/step\n",
            "Epoch 70/1000\n",
            "4/4 - 1s - loss: 0.5610 - mse: 0.5321 - val_loss: 0.4959 - val_mse: 0.4959 - lr: 0.0010 - 676ms/epoch - 169ms/step\n",
            "Epoch 71/1000\n",
            "4/4 - 1s - loss: 0.5576 - mse: 0.5287 - val_loss: 0.4916 - val_mse: 0.4916 - lr: 0.0010 - 657ms/epoch - 164ms/step\n",
            "Epoch 72/1000\n",
            "4/4 - 1s - loss: 0.5553 - mse: 0.5266 - val_loss: 0.4867 - val_mse: 0.4867 - lr: 0.0010 - 674ms/epoch - 168ms/step\n",
            "Epoch 73/1000\n",
            "4/4 - 1s - loss: 0.5545 - mse: 0.5258 - val_loss: 0.4823 - val_mse: 0.4823 - lr: 0.0010 - 675ms/epoch - 169ms/step\n",
            "Epoch 74/1000\n",
            "4/4 - 1s - loss: 0.5512 - mse: 0.5225 - val_loss: 0.4792 - val_mse: 0.4792 - lr: 0.0010 - 681ms/epoch - 170ms/step\n",
            "Epoch 75/1000\n",
            "4/4 - 1s - loss: 0.5473 - mse: 0.5189 - val_loss: 0.4758 - val_mse: 0.4758 - lr: 0.0010 - 697ms/epoch - 174ms/step\n",
            "Epoch 76/1000\n",
            "4/4 - 1s - loss: 0.5464 - mse: 0.5180 - val_loss: 0.4720 - val_mse: 0.4720 - lr: 0.0010 - 697ms/epoch - 174ms/step\n",
            "Epoch 77/1000\n",
            "4/4 - 1s - loss: 0.5432 - mse: 0.5150 - val_loss: 0.4679 - val_mse: 0.4679 - lr: 0.0010 - 686ms/epoch - 171ms/step\n",
            "Epoch 78/1000\n",
            "4/4 - 1s - loss: 0.5392 - mse: 0.5113 - val_loss: 0.4645 - val_mse: 0.4645 - lr: 0.0010 - 674ms/epoch - 169ms/step\n",
            "Epoch 79/1000\n",
            "4/4 - 1s - loss: 0.5372 - mse: 0.5093 - val_loss: 0.4608 - val_mse: 0.4608 - lr: 0.0010 - 698ms/epoch - 174ms/step\n",
            "Epoch 80/1000\n",
            "4/4 - 1s - loss: 0.5352 - mse: 0.5076 - val_loss: 0.4575 - val_mse: 0.4575 - lr: 0.0010 - 696ms/epoch - 174ms/step\n",
            "Epoch 81/1000\n",
            "4/4 - 1s - loss: 0.5365 - mse: 0.5086 - val_loss: 0.4541 - val_mse: 0.4541 - lr: 0.0010 - 702ms/epoch - 175ms/step\n",
            "Epoch 82/1000\n",
            "4/4 - 1s - loss: 0.5324 - mse: 0.5047 - val_loss: 0.4510 - val_mse: 0.4510 - lr: 0.0010 - 697ms/epoch - 174ms/step\n",
            "Epoch 83/1000\n",
            "4/4 - 1s - loss: 0.5293 - mse: 0.5020 - val_loss: 0.4482 - val_mse: 0.4482 - lr: 0.0010 - 706ms/epoch - 177ms/step\n",
            "Epoch 84/1000\n",
            "4/4 - 1s - loss: 0.5270 - mse: 0.4995 - val_loss: 0.4455 - val_mse: 0.4455 - lr: 0.0010 - 690ms/epoch - 173ms/step\n",
            "Epoch 85/1000\n",
            "4/4 - 1s - loss: 0.5257 - mse: 0.4984 - val_loss: 0.4426 - val_mse: 0.4426 - lr: 0.0010 - 655ms/epoch - 164ms/step\n",
            "Epoch 86/1000\n",
            "4/4 - 1s - loss: 0.5232 - mse: 0.4961 - val_loss: 0.4392 - val_mse: 0.4392 - lr: 0.0010 - 658ms/epoch - 164ms/step\n",
            "Epoch 87/1000\n",
            "4/4 - 1s - loss: 0.5235 - mse: 0.4963 - val_loss: 0.4359 - val_mse: 0.4359 - lr: 0.0010 - 696ms/epoch - 174ms/step\n",
            "Epoch 88/1000\n",
            "4/4 - 1s - loss: 0.5199 - mse: 0.4930 - val_loss: 0.4340 - val_mse: 0.4340 - lr: 0.0010 - 674ms/epoch - 168ms/step\n",
            "Epoch 89/1000\n",
            "4/4 - 1s - loss: 0.5179 - mse: 0.4910 - val_loss: 0.4321 - val_mse: 0.4321 - lr: 0.0010 - 657ms/epoch - 164ms/step\n",
            "Epoch 90/1000\n",
            "4/4 - 1s - loss: 0.5153 - mse: 0.4886 - val_loss: 0.4302 - val_mse: 0.4302 - lr: 0.0010 - 670ms/epoch - 168ms/step\n",
            "Epoch 91/1000\n",
            "4/4 - 1s - loss: 0.5121 - mse: 0.4855 - val_loss: 0.4277 - val_mse: 0.4277 - lr: 0.0010 - 669ms/epoch - 167ms/step\n",
            "Epoch 92/1000\n",
            "4/4 - 1s - loss: 0.5107 - mse: 0.4842 - val_loss: 0.4251 - val_mse: 0.4251 - lr: 0.0010 - 675ms/epoch - 169ms/step\n",
            "Epoch 93/1000\n",
            "4/4 - 1s - loss: 0.5100 - mse: 0.4834 - val_loss: 0.4226 - val_mse: 0.4226 - lr: 0.0010 - 690ms/epoch - 173ms/step\n",
            "Epoch 94/1000\n",
            "4/4 - 1s - loss: 0.5070 - mse: 0.4807 - val_loss: 0.4203 - val_mse: 0.4203 - lr: 0.0010 - 656ms/epoch - 164ms/step\n",
            "Epoch 95/1000\n",
            "4/4 - 1s - loss: 0.5058 - mse: 0.4794 - val_loss: 0.4184 - val_mse: 0.4184 - lr: 0.0010 - 674ms/epoch - 169ms/step\n",
            "Epoch 96/1000\n",
            "4/4 - 1s - loss: 0.5058 - mse: 0.4794 - val_loss: 0.4168 - val_mse: 0.4168 - lr: 0.0010 - 676ms/epoch - 169ms/step\n",
            "Epoch 97/1000\n",
            "4/4 - 1s - loss: 0.5032 - mse: 0.4769 - val_loss: 0.4147 - val_mse: 0.4147 - lr: 0.0010 - 667ms/epoch - 167ms/step\n",
            "Epoch 98/1000\n",
            "4/4 - 1s - loss: 0.5035 - mse: 0.4774 - val_loss: 0.4127 - val_mse: 0.4127 - lr: 0.0010 - 659ms/epoch - 165ms/step\n",
            "Epoch 99/1000\n",
            "4/4 - 1s - loss: 0.4988 - mse: 0.4727 - val_loss: 0.4111 - val_mse: 0.4111 - lr: 0.0010 - 693ms/epoch - 173ms/step\n",
            "Epoch 100/1000\n",
            "4/4 - 1s - loss: 0.4983 - mse: 0.4722 - val_loss: 0.4092 - val_mse: 0.4092 - lr: 0.0010 - 674ms/epoch - 168ms/step\n",
            "Epoch 101/1000\n",
            "4/4 - 1s - loss: 0.4971 - mse: 0.4712 - val_loss: 0.4079 - val_mse: 0.4079 - lr: 0.0010 - 678ms/epoch - 170ms/step\n",
            "Epoch 102/1000\n",
            "4/4 - 1s - loss: 0.4966 - mse: 0.4707 - val_loss: 0.4068 - val_mse: 0.4068 - lr: 0.0010 - 683ms/epoch - 171ms/step\n",
            "Epoch 103/1000\n",
            "4/4 - 1s - loss: 0.4924 - mse: 0.4667 - val_loss: 0.4056 - val_mse: 0.4056 - lr: 0.0010 - 675ms/epoch - 169ms/step\n",
            "Epoch 104/1000\n",
            "4/4 - 1s - loss: 0.4939 - mse: 0.4682 - val_loss: 0.4046 - val_mse: 0.4046 - lr: 0.0010 - 678ms/epoch - 169ms/step\n",
            "Epoch 105/1000\n",
            "4/4 - 1s - loss: 0.4908 - mse: 0.4652 - val_loss: 0.4032 - val_mse: 0.4032 - lr: 0.0010 - 685ms/epoch - 171ms/step\n",
            "Epoch 106/1000\n",
            "4/4 - 1s - loss: 0.4900 - mse: 0.4645 - val_loss: 0.4014 - val_mse: 0.4014 - lr: 0.0010 - 657ms/epoch - 164ms/step\n",
            "Epoch 107/1000\n",
            "4/4 - 1s - loss: 0.4877 - mse: 0.4622 - val_loss: 0.4002 - val_mse: 0.4002 - lr: 0.0010 - 676ms/epoch - 169ms/step\n",
            "Epoch 108/1000\n",
            "4/4 - 1s - loss: 0.4880 - mse: 0.4624 - val_loss: 0.3991 - val_mse: 0.3991 - lr: 0.0010 - 691ms/epoch - 173ms/step\n",
            "Epoch 109/1000\n",
            "4/4 - 1s - loss: 0.4869 - mse: 0.4616 - val_loss: 0.3982 - val_mse: 0.3982 - lr: 0.0010 - 699ms/epoch - 175ms/step\n",
            "Epoch 110/1000\n",
            "4/4 - 1s - loss: 0.4843 - mse: 0.4590 - val_loss: 0.3970 - val_mse: 0.3970 - lr: 0.0010 - 685ms/epoch - 171ms/step\n",
            "Epoch 111/1000\n",
            "4/4 - 1s - loss: 0.4844 - mse: 0.4592 - val_loss: 0.3956 - val_mse: 0.3956 - lr: 0.0010 - 697ms/epoch - 174ms/step\n",
            "Epoch 112/1000\n",
            "4/4 - 1s - loss: 0.4833 - mse: 0.4581 - val_loss: 0.3947 - val_mse: 0.3947 - lr: 0.0010 - 692ms/epoch - 173ms/step\n",
            "Epoch 113/1000\n",
            "4/4 - 1s - loss: 0.4827 - mse: 0.4574 - val_loss: 0.3940 - val_mse: 0.3940 - lr: 0.0010 - 690ms/epoch - 173ms/step\n",
            "Epoch 114/1000\n",
            "4/4 - 1s - loss: 0.4799 - mse: 0.4549 - val_loss: 0.3936 - val_mse: 0.3936 - lr: 0.0010 - 689ms/epoch - 172ms/step\n",
            "Epoch 115/1000\n",
            "4/4 - 1s - loss: 0.4801 - mse: 0.4549 - val_loss: 0.3930 - val_mse: 0.3930 - lr: 0.0010 - 679ms/epoch - 170ms/step\n",
            "Epoch 116/1000\n",
            "4/4 - 1s - loss: 0.4782 - mse: 0.4532 - val_loss: 0.3923 - val_mse: 0.3923 - lr: 0.0010 - 673ms/epoch - 168ms/step\n",
            "Epoch 117/1000\n",
            "4/4 - 1s - loss: 0.4763 - mse: 0.4513 - val_loss: 0.3915 - val_mse: 0.3915 - lr: 0.0010 - 666ms/epoch - 166ms/step\n",
            "Epoch 118/1000\n",
            "4/4 - 1s - loss: 0.4766 - mse: 0.4516 - val_loss: 0.3908 - val_mse: 0.3908 - lr: 0.0010 - 658ms/epoch - 164ms/step\n",
            "Epoch 119/1000\n",
            "4/4 - 1s - loss: 0.4757 - mse: 0.4510 - val_loss: 0.3901 - val_mse: 0.3901 - lr: 0.0010 - 674ms/epoch - 168ms/step\n",
            "Epoch 120/1000\n",
            "4/4 - 1s - loss: 0.4744 - mse: 0.4496 - val_loss: 0.3892 - val_mse: 0.3892 - lr: 0.0010 - 662ms/epoch - 165ms/step\n",
            "Epoch 121/1000\n",
            "4/4 - 1s - loss: 0.4736 - mse: 0.4489 - val_loss: 0.3886 - val_mse: 0.3886 - lr: 0.0010 - 694ms/epoch - 173ms/step\n",
            "Epoch 122/1000\n",
            "4/4 - 1s - loss: 0.4736 - mse: 0.4487 - val_loss: 0.3883 - val_mse: 0.3883 - lr: 0.0010 - 667ms/epoch - 167ms/step\n",
            "Epoch 123/1000\n",
            "4/4 - 1s - loss: 0.4724 - mse: 0.4476 - val_loss: 0.3881 - val_mse: 0.3881 - lr: 0.0010 - 675ms/epoch - 169ms/step\n",
            "Epoch 124/1000\n",
            "4/4 - 1s - loss: 0.4720 - mse: 0.4473 - val_loss: 0.3879 - val_mse: 0.3879 - lr: 0.0010 - 678ms/epoch - 169ms/step\n",
            "Epoch 125/1000\n",
            "4/4 - 1s - loss: 0.4692 - mse: 0.4446 - val_loss: 0.3877 - val_mse: 0.3877 - lr: 0.0010 - 675ms/epoch - 169ms/step\n",
            "Epoch 126/1000\n",
            "4/4 - 1s - loss: 0.4685 - mse: 0.4440 - val_loss: 0.3872 - val_mse: 0.3872 - lr: 0.0010 - 671ms/epoch - 168ms/step\n",
            "Epoch 127/1000\n",
            "4/4 - 1s - loss: 0.4683 - mse: 0.4436 - val_loss: 0.3867 - val_mse: 0.3867 - lr: 0.0010 - 687ms/epoch - 172ms/step\n",
            "Epoch 128/1000\n",
            "4/4 - 1s - loss: 0.4688 - mse: 0.4442 - val_loss: 0.3864 - val_mse: 0.3864 - lr: 0.0010 - 682ms/epoch - 170ms/step\n",
            "Epoch 129/1000\n",
            "4/4 - 1s - loss: 0.4673 - mse: 0.4428 - val_loss: 0.3862 - val_mse: 0.3862 - lr: 0.0010 - 667ms/epoch - 167ms/step\n",
            "Epoch 130/1000\n",
            "4/4 - 1s - loss: 0.4664 - mse: 0.4419 - val_loss: 0.3860 - val_mse: 0.3860 - lr: 0.0010 - 670ms/epoch - 168ms/step\n",
            "Epoch 131/1000\n",
            "4/4 - 1s - loss: 0.4651 - mse: 0.4406 - val_loss: 0.3857 - val_mse: 0.3857 - lr: 0.0010 - 667ms/epoch - 167ms/step\n",
            "Epoch 132/1000\n",
            "4/4 - 1s - loss: 0.4648 - mse: 0.4404 - val_loss: 0.3855 - val_mse: 0.3855 - lr: 0.0010 - 678ms/epoch - 169ms/step\n",
            "Epoch 133/1000\n",
            "4/4 - 1s - loss: 0.4637 - mse: 0.4393 - val_loss: 0.3855 - val_mse: 0.3855 - lr: 0.0010 - 668ms/epoch - 167ms/step\n",
            "Epoch 134/1000\n",
            "4/4 - 1s - loss: 0.4618 - mse: 0.4375 - val_loss: 0.3854 - val_mse: 0.3854 - lr: 0.0010 - 688ms/epoch - 172ms/step\n",
            "Epoch 135/1000\n",
            "4/4 - 1s - loss: 0.4619 - mse: 0.4378 - val_loss: 0.3854 - val_mse: 0.3854 - lr: 0.0010 - 680ms/epoch - 170ms/step\n",
            "Epoch 136/1000\n",
            "4/4 - 1s - loss: 0.4624 - mse: 0.4382 - val_loss: 0.3853 - val_mse: 0.3853 - lr: 0.0010 - 670ms/epoch - 167ms/step\n",
            "Epoch 137/1000\n",
            "4/4 - 1s - loss: 0.4598 - mse: 0.4357 - val_loss: 0.3851 - val_mse: 0.3851 - lr: 0.0010 - 661ms/epoch - 165ms/step\n",
            "Epoch 138/1000\n",
            "4/4 - 1s - loss: 0.4603 - mse: 0.4360 - val_loss: 0.3849 - val_mse: 0.3849 - lr: 0.0010 - 670ms/epoch - 167ms/step\n",
            "Epoch 139/1000\n",
            "4/4 - 1s - loss: 0.4589 - mse: 0.4348 - val_loss: 0.3848 - val_mse: 0.3848 - lr: 0.0010 - 670ms/epoch - 167ms/step\n",
            "Epoch 140/1000\n",
            "4/4 - 1s - loss: 0.4586 - mse: 0.4344 - val_loss: 0.3847 - val_mse: 0.3847 - lr: 0.0010 - 677ms/epoch - 169ms/step\n",
            "Epoch 141/1000\n",
            "4/4 - 1s - loss: 0.4582 - mse: 0.4341 - val_loss: 0.3845 - val_mse: 0.3845 - lr: 0.0010 - 678ms/epoch - 170ms/step\n",
            "Epoch 142/1000\n",
            "4/4 - 1s - loss: 0.4582 - mse: 0.4342 - val_loss: 0.3845 - val_mse: 0.3845 - lr: 0.0010 - 677ms/epoch - 169ms/step\n",
            "Epoch 143/1000\n",
            "4/4 - 1s - loss: 0.4578 - mse: 0.4337 - val_loss: 0.3843 - val_mse: 0.3843 - lr: 0.0010 - 664ms/epoch - 166ms/step\n",
            "Epoch 144/1000\n",
            "4/4 - 1s - loss: 0.4562 - mse: 0.4321 - val_loss: 0.3843 - val_mse: 0.3843 - lr: 0.0010 - 674ms/epoch - 169ms/step\n",
            "Epoch 145/1000\n",
            "4/4 - 1s - loss: 0.4556 - mse: 0.4316 - val_loss: 0.3846 - val_mse: 0.3846 - lr: 0.0010 - 665ms/epoch - 166ms/step\n",
            "Epoch 146/1000\n",
            "4/4 - 1s - loss: 0.4559 - mse: 0.4319 - val_loss: 0.3847 - val_mse: 0.3847 - lr: 0.0010 - 665ms/epoch - 166ms/step\n",
            "Epoch 147/1000\n",
            "4/4 - 1s - loss: 0.4545 - mse: 0.4306 - val_loss: 0.3847 - val_mse: 0.3847 - lr: 0.0010 - 660ms/epoch - 165ms/step\n",
            "Epoch 148/1000\n",
            "4/4 - 1s - loss: 0.4542 - mse: 0.4303 - val_loss: 0.3847 - val_mse: 0.3847 - lr: 0.0010 - 671ms/epoch - 168ms/step\n",
            "Epoch 149/1000\n",
            "4/4 - 1s - loss: 0.4529 - mse: 0.4291 - val_loss: 0.3847 - val_mse: 0.3847 - lr: 0.0010 - 684ms/epoch - 171ms/step\n",
            "Epoch 150/1000\n",
            "\n",
            "Epoch 150: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "4/4 - 1s - loss: 0.4525 - mse: 0.4288 - val_loss: 0.3847 - val_mse: 0.3847 - lr: 0.0010 - 678ms/epoch - 169ms/step\n",
            "Epoch 151/1000\n",
            "4/4 - 1s - loss: 0.4531 - mse: 0.4293 - val_loss: 0.3846 - val_mse: 0.3846 - lr: 1.0000e-04 - 674ms/epoch - 169ms/step\n",
            "Epoch 152/1000\n",
            "4/4 - 1s - loss: 0.4530 - mse: 0.4292 - val_loss: 0.3846 - val_mse: 0.3846 - lr: 1.0000e-04 - 696ms/epoch - 174ms/step\n",
            "Epoch 153/1000\n",
            "4/4 - 1s - loss: 0.4525 - mse: 0.4287 - val_loss: 0.3845 - val_mse: 0.3845 - lr: 1.0000e-04 - 691ms/epoch - 173ms/step\n",
            "Epoch 154/1000\n",
            "4/4 - 1s - loss: 0.4527 - mse: 0.4289 - val_loss: 0.3844 - val_mse: 0.3844 - lr: 1.0000e-04 - 684ms/epoch - 171ms/step\n",
            "Epoch 154: early stopping\n",
            "==================================================\n",
            "Step 7\n",
            "==================================================\n",
            "Epoch 1/1000\n",
            "4/4 - 4s - loss: 3.4456 - mse: 3.1923 - val_loss: 0.9303 - val_mse: 0.9303 - lr: 0.0010 - 4s/epoch - 950ms/step\n",
            "Epoch 2/1000\n",
            "4/4 - 1s - loss: 2.0264 - mse: 1.8987 - val_loss: 0.8846 - val_mse: 0.8846 - lr: 0.0010 - 697ms/epoch - 174ms/step\n",
            "Epoch 3/1000\n",
            "4/4 - 1s - loss: 1.5843 - mse: 1.4912 - val_loss: 0.8838 - val_mse: 0.8838 - lr: 0.0010 - 692ms/epoch - 173ms/step\n",
            "Epoch 4/1000\n",
            "4/4 - 1s - loss: 1.3982 - mse: 1.3193 - val_loss: 0.8931 - val_mse: 0.8931 - lr: 0.0010 - 689ms/epoch - 172ms/step\n",
            "Epoch 5/1000\n",
            "4/4 - 1s - loss: 1.2939 - mse: 1.2213 - val_loss: 0.8895 - val_mse: 0.8895 - lr: 0.0010 - 686ms/epoch - 171ms/step\n",
            "Epoch 6/1000\n",
            "4/4 - 1s - loss: 1.1936 - mse: 1.1271 - val_loss: 0.8717 - val_mse: 0.8717 - lr: 0.0010 - 686ms/epoch - 171ms/step\n",
            "Epoch 7/1000\n",
            "4/4 - 1s - loss: 1.1221 - mse: 1.0594 - val_loss: 0.8520 - val_mse: 0.8520 - lr: 0.0010 - 701ms/epoch - 175ms/step\n",
            "Epoch 8/1000\n",
            "4/4 - 1s - loss: 1.0589 - mse: 0.9995 - val_loss: 0.8397 - val_mse: 0.8397 - lr: 0.0010 - 674ms/epoch - 169ms/step\n",
            "Epoch 9/1000\n",
            "4/4 - 1s - loss: 1.0152 - mse: 0.9583 - val_loss: 0.8355 - val_mse: 0.8355 - lr: 0.0010 - 690ms/epoch - 172ms/step\n",
            "Epoch 10/1000\n",
            "4/4 - 1s - loss: 0.9794 - mse: 0.9245 - val_loss: 0.8357 - val_mse: 0.8357 - lr: 0.0010 - 680ms/epoch - 170ms/step\n",
            "Epoch 11/1000\n",
            "4/4 - 1s - loss: 0.9488 - mse: 0.8957 - val_loss: 0.8375 - val_mse: 0.8375 - lr: 0.0010 - 706ms/epoch - 177ms/step\n",
            "Epoch 12/1000\n",
            "4/4 - 1s - loss: 0.9298 - mse: 0.8782 - val_loss: 0.8372 - val_mse: 0.8372 - lr: 0.0010 - 690ms/epoch - 172ms/step\n",
            "Epoch 13/1000\n",
            "4/4 - 1s - loss: 0.9091 - mse: 0.8587 - val_loss: 0.8334 - val_mse: 0.8334 - lr: 0.0010 - 690ms/epoch - 173ms/step\n",
            "Epoch 14/1000\n",
            "4/4 - 1s - loss: 0.8859 - mse: 0.8368 - val_loss: 0.8262 - val_mse: 0.8262 - lr: 0.0010 - 693ms/epoch - 173ms/step\n",
            "Epoch 15/1000\n",
            "4/4 - 1s - loss: 0.8720 - mse: 0.8236 - val_loss: 0.8170 - val_mse: 0.8170 - lr: 0.0010 - 685ms/epoch - 171ms/step\n",
            "Epoch 16/1000\n",
            "4/4 - 1s - loss: 0.8619 - mse: 0.8141 - val_loss: 0.8100 - val_mse: 0.8100 - lr: 0.0010 - 686ms/epoch - 172ms/step\n",
            "Epoch 17/1000\n",
            "4/4 - 1s - loss: 0.8485 - mse: 0.8016 - val_loss: 0.8067 - val_mse: 0.8067 - lr: 0.0010 - 712ms/epoch - 178ms/step\n",
            "Epoch 18/1000\n",
            "4/4 - 1s - loss: 0.8349 - mse: 0.7889 - val_loss: 0.8051 - val_mse: 0.8051 - lr: 0.0010 - 699ms/epoch - 175ms/step\n",
            "Epoch 19/1000\n",
            "4/4 - 1s - loss: 0.8238 - mse: 0.7782 - val_loss: 0.8022 - val_mse: 0.8022 - lr: 0.0010 - 701ms/epoch - 175ms/step\n",
            "Epoch 20/1000\n",
            "4/4 - 1s - loss: 0.8125 - mse: 0.7678 - val_loss: 0.7977 - val_mse: 0.7977 - lr: 0.0010 - 695ms/epoch - 174ms/step\n",
            "Epoch 21/1000\n",
            "4/4 - 1s - loss: 0.8025 - mse: 0.7580 - val_loss: 0.7921 - val_mse: 0.7921 - lr: 0.0010 - 687ms/epoch - 172ms/step\n",
            "Epoch 22/1000\n",
            "4/4 - 1s - loss: 0.7936 - mse: 0.7501 - val_loss: 0.7855 - val_mse: 0.7855 - lr: 0.0010 - 704ms/epoch - 176ms/step\n",
            "Epoch 23/1000\n",
            "4/4 - 1s - loss: 0.7820 - mse: 0.7391 - val_loss: 0.7804 - val_mse: 0.7804 - lr: 0.0010 - 697ms/epoch - 174ms/step\n",
            "Epoch 24/1000\n",
            "4/4 - 1s - loss: 0.7744 - mse: 0.7321 - val_loss: 0.7780 - val_mse: 0.7780 - lr: 0.0010 - 696ms/epoch - 174ms/step\n",
            "Epoch 25/1000\n",
            "4/4 - 1s - loss: 0.7620 - mse: 0.7203 - val_loss: 0.7750 - val_mse: 0.7750 - lr: 0.0010 - 699ms/epoch - 175ms/step\n",
            "Epoch 26/1000\n",
            "4/4 - 1s - loss: 0.7560 - mse: 0.7147 - val_loss: 0.7698 - val_mse: 0.7698 - lr: 0.0010 - 689ms/epoch - 172ms/step\n",
            "Epoch 27/1000\n",
            "4/4 - 1s - loss: 0.7502 - mse: 0.7094 - val_loss: 0.7629 - val_mse: 0.7629 - lr: 0.0010 - 700ms/epoch - 175ms/step\n",
            "Epoch 28/1000\n",
            "4/4 - 1s - loss: 0.7447 - mse: 0.7040 - val_loss: 0.7574 - val_mse: 0.7574 - lr: 0.0010 - 694ms/epoch - 173ms/step\n",
            "Epoch 29/1000\n",
            "4/4 - 1s - loss: 0.7333 - mse: 0.6936 - val_loss: 0.7546 - val_mse: 0.7546 - lr: 0.0010 - 683ms/epoch - 171ms/step\n",
            "Epoch 30/1000\n",
            "4/4 - 1s - loss: 0.7269 - mse: 0.6871 - val_loss: 0.7509 - val_mse: 0.7509 - lr: 0.0010 - 698ms/epoch - 175ms/step\n",
            "Epoch 31/1000\n",
            "4/4 - 1s - loss: 0.7249 - mse: 0.6855 - val_loss: 0.7450 - val_mse: 0.7450 - lr: 0.0010 - 709ms/epoch - 177ms/step\n",
            "Epoch 32/1000\n",
            "4/4 - 1s - loss: 0.7152 - mse: 0.6764 - val_loss: 0.7403 - val_mse: 0.7403 - lr: 0.0010 - 694ms/epoch - 174ms/step\n",
            "Epoch 33/1000\n",
            "4/4 - 1s - loss: 0.7088 - mse: 0.6705 - val_loss: 0.7357 - val_mse: 0.7357 - lr: 0.0010 - 698ms/epoch - 175ms/step\n",
            "Epoch 34/1000\n",
            "4/4 - 1s - loss: 0.7062 - mse: 0.6676 - val_loss: 0.7324 - val_mse: 0.7324 - lr: 0.0010 - 700ms/epoch - 175ms/step\n",
            "Epoch 35/1000\n",
            "4/4 - 1s - loss: 0.6981 - mse: 0.6600 - val_loss: 0.7279 - val_mse: 0.7279 - lr: 0.0010 - 703ms/epoch - 176ms/step\n",
            "Epoch 36/1000\n",
            "4/4 - 1s - loss: 0.6895 - mse: 0.6522 - val_loss: 0.7208 - val_mse: 0.7208 - lr: 0.0010 - 712ms/epoch - 178ms/step\n",
            "Epoch 37/1000\n",
            "4/4 - 1s - loss: 0.6851 - mse: 0.6481 - val_loss: 0.7145 - val_mse: 0.7145 - lr: 0.0010 - 699ms/epoch - 175ms/step\n",
            "Epoch 38/1000\n",
            "4/4 - 1s - loss: 0.6788 - mse: 0.6423 - val_loss: 0.7097 - val_mse: 0.7097 - lr: 0.0010 - 703ms/epoch - 176ms/step\n",
            "Epoch 39/1000\n",
            "4/4 - 1s - loss: 0.6779 - mse: 0.6408 - val_loss: 0.7047 - val_mse: 0.7047 - lr: 0.0010 - 699ms/epoch - 175ms/step\n",
            "Epoch 40/1000\n",
            "4/4 - 1s - loss: 0.6739 - mse: 0.6374 - val_loss: 0.6991 - val_mse: 0.6991 - lr: 0.0010 - 691ms/epoch - 173ms/step\n",
            "Epoch 41/1000\n",
            "4/4 - 1s - loss: 0.6687 - mse: 0.6325 - val_loss: 0.6945 - val_mse: 0.6945 - lr: 0.0010 - 700ms/epoch - 175ms/step\n",
            "Epoch 42/1000\n",
            "4/4 - 1s - loss: 0.6600 - mse: 0.6244 - val_loss: 0.6893 - val_mse: 0.6893 - lr: 0.0010 - 691ms/epoch - 173ms/step\n",
            "Epoch 43/1000\n",
            "4/4 - 1s - loss: 0.6536 - mse: 0.6183 - val_loss: 0.6839 - val_mse: 0.6839 - lr: 0.0010 - 699ms/epoch - 175ms/step\n",
            "Epoch 44/1000\n",
            "4/4 - 1s - loss: 0.6504 - mse: 0.6152 - val_loss: 0.6786 - val_mse: 0.6786 - lr: 0.0010 - 707ms/epoch - 177ms/step\n",
            "Epoch 45/1000\n",
            "4/4 - 1s - loss: 0.6467 - mse: 0.6119 - val_loss: 0.6732 - val_mse: 0.6732 - lr: 0.0010 - 705ms/epoch - 176ms/step\n",
            "Epoch 46/1000\n",
            "4/4 - 1s - loss: 0.6432 - mse: 0.6085 - val_loss: 0.6680 - val_mse: 0.6680 - lr: 0.0010 - 708ms/epoch - 177ms/step\n",
            "Epoch 47/1000\n",
            "4/4 - 1s - loss: 0.6419 - mse: 0.6073 - val_loss: 0.6620 - val_mse: 0.6620 - lr: 0.0010 - 712ms/epoch - 178ms/step\n",
            "Epoch 48/1000\n",
            "4/4 - 1s - loss: 0.6327 - mse: 0.5987 - val_loss: 0.6564 - val_mse: 0.6564 - lr: 0.0010 - 700ms/epoch - 175ms/step\n",
            "Epoch 49/1000\n",
            "4/4 - 1s - loss: 0.6309 - mse: 0.5969 - val_loss: 0.6508 - val_mse: 0.6508 - lr: 0.0010 - 705ms/epoch - 176ms/step\n",
            "Epoch 50/1000\n",
            "4/4 - 1s - loss: 0.6232 - mse: 0.5896 - val_loss: 0.6451 - val_mse: 0.6451 - lr: 0.0010 - 696ms/epoch - 174ms/step\n",
            "Epoch 51/1000\n",
            "4/4 - 1s - loss: 0.6202 - mse: 0.5868 - val_loss: 0.6394 - val_mse: 0.6394 - lr: 0.0010 - 695ms/epoch - 174ms/step\n",
            "Epoch 52/1000\n",
            "4/4 - 1s - loss: 0.6134 - mse: 0.5804 - val_loss: 0.6337 - val_mse: 0.6337 - lr: 0.0010 - 709ms/epoch - 177ms/step\n",
            "Epoch 53/1000\n",
            "4/4 - 1s - loss: 0.6144 - mse: 0.5814 - val_loss: 0.6283 - val_mse: 0.6283 - lr: 0.0010 - 697ms/epoch - 174ms/step\n",
            "Epoch 54/1000\n",
            "4/4 - 1s - loss: 0.6121 - mse: 0.5790 - val_loss: 0.6226 - val_mse: 0.6226 - lr: 0.0010 - 693ms/epoch - 173ms/step\n",
            "Epoch 55/1000\n",
            "4/4 - 1s - loss: 0.6075 - mse: 0.5749 - val_loss: 0.6166 - val_mse: 0.6166 - lr: 0.0010 - 702ms/epoch - 176ms/step\n",
            "Epoch 56/1000\n",
            "4/4 - 1s - loss: 0.6032 - mse: 0.5704 - val_loss: 0.6117 - val_mse: 0.6117 - lr: 0.0010 - 702ms/epoch - 175ms/step\n",
            "Epoch 57/1000\n",
            "4/4 - 1s - loss: 0.5993 - mse: 0.5668 - val_loss: 0.6068 - val_mse: 0.6068 - lr: 0.0010 - 697ms/epoch - 174ms/step\n",
            "Epoch 58/1000\n",
            "4/4 - 1s - loss: 0.5947 - mse: 0.5628 - val_loss: 0.6012 - val_mse: 0.6012 - lr: 0.0010 - 700ms/epoch - 175ms/step\n",
            "Epoch 59/1000\n",
            "4/4 - 1s - loss: 0.5919 - mse: 0.5602 - val_loss: 0.5962 - val_mse: 0.5962 - lr: 0.0010 - 710ms/epoch - 177ms/step\n",
            "Epoch 60/1000\n",
            "4/4 - 1s - loss: 0.5866 - mse: 0.5554 - val_loss: 0.5908 - val_mse: 0.5908 - lr: 0.0010 - 711ms/epoch - 178ms/step\n",
            "Epoch 61/1000\n",
            "4/4 - 1s - loss: 0.5892 - mse: 0.5575 - val_loss: 0.5853 - val_mse: 0.5853 - lr: 0.0010 - 727ms/epoch - 182ms/step\n",
            "Epoch 62/1000\n",
            "4/4 - 1s - loss: 0.5833 - mse: 0.5519 - val_loss: 0.5791 - val_mse: 0.5791 - lr: 0.0010 - 711ms/epoch - 178ms/step\n",
            "Epoch 63/1000\n",
            "4/4 - 1s - loss: 0.5812 - mse: 0.5499 - val_loss: 0.5744 - val_mse: 0.5744 - lr: 0.0010 - 691ms/epoch - 173ms/step\n",
            "Epoch 64/1000\n",
            "4/4 - 1s - loss: 0.5765 - mse: 0.5455 - val_loss: 0.5696 - val_mse: 0.5696 - lr: 0.0010 - 701ms/epoch - 175ms/step\n",
            "Epoch 65/1000\n",
            "4/4 - 1s - loss: 0.5718 - mse: 0.5411 - val_loss: 0.5640 - val_mse: 0.5640 - lr: 0.0010 - 700ms/epoch - 175ms/step\n",
            "Epoch 66/1000\n",
            "4/4 - 1s - loss: 0.5719 - mse: 0.5414 - val_loss: 0.5584 - val_mse: 0.5584 - lr: 0.0010 - 694ms/epoch - 173ms/step\n",
            "Epoch 67/1000\n",
            "4/4 - 1s - loss: 0.5670 - mse: 0.5366 - val_loss: 0.5537 - val_mse: 0.5537 - lr: 0.0010 - 703ms/epoch - 176ms/step\n",
            "Epoch 68/1000\n",
            "4/4 - 1s - loss: 0.5628 - mse: 0.5325 - val_loss: 0.5494 - val_mse: 0.5494 - lr: 0.0010 - 715ms/epoch - 179ms/step\n",
            "Epoch 69/1000\n",
            "4/4 - 1s - loss: 0.5646 - mse: 0.5340 - val_loss: 0.5448 - val_mse: 0.5448 - lr: 0.0010 - 712ms/epoch - 178ms/step\n",
            "Epoch 70/1000\n",
            "4/4 - 1s - loss: 0.5607 - mse: 0.5304 - val_loss: 0.5404 - val_mse: 0.5404 - lr: 0.0010 - 701ms/epoch - 175ms/step\n",
            "Epoch 71/1000\n",
            "4/4 - 1s - loss: 0.5581 - mse: 0.5280 - val_loss: 0.5353 - val_mse: 0.5353 - lr: 0.0010 - 707ms/epoch - 177ms/step\n",
            "Epoch 72/1000\n",
            "4/4 - 1s - loss: 0.5540 - mse: 0.5240 - val_loss: 0.5300 - val_mse: 0.5300 - lr: 0.0010 - 711ms/epoch - 178ms/step\n",
            "Epoch 73/1000\n",
            "4/4 - 1s - loss: 0.5519 - mse: 0.5222 - val_loss: 0.5254 - val_mse: 0.5254 - lr: 0.0010 - 706ms/epoch - 176ms/step\n",
            "Epoch 74/1000\n",
            "4/4 - 1s - loss: 0.5500 - mse: 0.5204 - val_loss: 0.5209 - val_mse: 0.5209 - lr: 0.0010 - 704ms/epoch - 176ms/step\n",
            "Epoch 75/1000\n",
            "4/4 - 1s - loss: 0.5493 - mse: 0.5199 - val_loss: 0.5166 - val_mse: 0.5166 - lr: 0.0010 - 702ms/epoch - 175ms/step\n",
            "Epoch 76/1000\n",
            "4/4 - 1s - loss: 0.5464 - mse: 0.5171 - val_loss: 0.5120 - val_mse: 0.5120 - lr: 0.0010 - 705ms/epoch - 176ms/step\n",
            "Epoch 77/1000\n",
            "4/4 - 1s - loss: 0.5435 - mse: 0.5143 - val_loss: 0.5082 - val_mse: 0.5082 - lr: 0.0010 - 704ms/epoch - 176ms/step\n",
            "Epoch 78/1000\n",
            "4/4 - 1s - loss: 0.5401 - mse: 0.5109 - val_loss: 0.5034 - val_mse: 0.5034 - lr: 0.0010 - 699ms/epoch - 175ms/step\n",
            "Epoch 79/1000\n",
            "4/4 - 1s - loss: 0.5389 - mse: 0.5098 - val_loss: 0.4983 - val_mse: 0.4983 - lr: 0.0010 - 693ms/epoch - 173ms/step\n",
            "Epoch 80/1000\n",
            "4/4 - 1s - loss: 0.5387 - mse: 0.5097 - val_loss: 0.4939 - val_mse: 0.4939 - lr: 0.0010 - 713ms/epoch - 178ms/step\n",
            "Epoch 81/1000\n",
            "4/4 - 1s - loss: 0.5346 - mse: 0.5058 - val_loss: 0.4895 - val_mse: 0.4895 - lr: 0.0010 - 695ms/epoch - 174ms/step\n",
            "Epoch 82/1000\n",
            "4/4 - 1s - loss: 0.5331 - mse: 0.5045 - val_loss: 0.4855 - val_mse: 0.4855 - lr: 0.0010 - 706ms/epoch - 177ms/step\n",
            "Epoch 83/1000\n",
            "4/4 - 1s - loss: 0.5302 - mse: 0.5016 - val_loss: 0.4813 - val_mse: 0.4813 - lr: 0.0010 - 703ms/epoch - 176ms/step\n",
            "Epoch 84/1000\n",
            "4/4 - 1s - loss: 0.5284 - mse: 0.5000 - val_loss: 0.4780 - val_mse: 0.4780 - lr: 0.0010 - 699ms/epoch - 175ms/step\n",
            "Epoch 85/1000\n",
            "4/4 - 1s - loss: 0.5274 - mse: 0.4992 - val_loss: 0.4744 - val_mse: 0.4744 - lr: 0.0010 - 716ms/epoch - 179ms/step\n",
            "Epoch 86/1000\n",
            "4/4 - 1s - loss: 0.5255 - mse: 0.4973 - val_loss: 0.4713 - val_mse: 0.4713 - lr: 0.0010 - 721ms/epoch - 180ms/step\n",
            "Epoch 87/1000\n",
            "4/4 - 1s - loss: 0.5228 - mse: 0.4948 - val_loss: 0.4684 - val_mse: 0.4684 - lr: 0.0010 - 699ms/epoch - 175ms/step\n",
            "Epoch 88/1000\n",
            "4/4 - 1s - loss: 0.5222 - mse: 0.4943 - val_loss: 0.4651 - val_mse: 0.4651 - lr: 0.0010 - 724ms/epoch - 181ms/step\n",
            "Epoch 89/1000\n",
            "4/4 - 1s - loss: 0.5203 - mse: 0.4922 - val_loss: 0.4611 - val_mse: 0.4611 - lr: 0.0010 - 709ms/epoch - 177ms/step\n",
            "Epoch 90/1000\n",
            "4/4 - 1s - loss: 0.5177 - mse: 0.4900 - val_loss: 0.4570 - val_mse: 0.4570 - lr: 0.0010 - 699ms/epoch - 175ms/step\n",
            "Epoch 91/1000\n",
            "4/4 - 1s - loss: 0.5162 - mse: 0.4886 - val_loss: 0.4533 - val_mse: 0.4533 - lr: 0.0010 - 734ms/epoch - 183ms/step\n",
            "Epoch 92/1000\n",
            "4/4 - 1s - loss: 0.5141 - mse: 0.4864 - val_loss: 0.4502 - val_mse: 0.4502 - lr: 0.0010 - 719ms/epoch - 180ms/step\n",
            "Epoch 93/1000\n",
            "4/4 - 1s - loss: 0.5129 - mse: 0.4853 - val_loss: 0.4476 - val_mse: 0.4476 - lr: 0.0010 - 713ms/epoch - 178ms/step\n",
            "Epoch 94/1000\n",
            "4/4 - 1s - loss: 0.5100 - mse: 0.4827 - val_loss: 0.4451 - val_mse: 0.4451 - lr: 0.0010 - 717ms/epoch - 179ms/step\n",
            "Epoch 95/1000\n",
            "4/4 - 1s - loss: 0.5098 - mse: 0.4825 - val_loss: 0.4426 - val_mse: 0.4426 - lr: 0.0010 - 724ms/epoch - 181ms/step\n",
            "Epoch 96/1000\n",
            "4/4 - 1s - loss: 0.5092 - mse: 0.4819 - val_loss: 0.4395 - val_mse: 0.4395 - lr: 0.0010 - 734ms/epoch - 184ms/step\n",
            "Epoch 97/1000\n",
            "4/4 - 1s - loss: 0.5076 - mse: 0.4802 - val_loss: 0.4366 - val_mse: 0.4366 - lr: 0.0010 - 709ms/epoch - 177ms/step\n",
            "Epoch 98/1000\n",
            "4/4 - 1s - loss: 0.5049 - mse: 0.4778 - val_loss: 0.4337 - val_mse: 0.4337 - lr: 0.0010 - 708ms/epoch - 177ms/step\n",
            "Epoch 99/1000\n",
            "4/4 - 1s - loss: 0.5045 - mse: 0.4774 - val_loss: 0.4314 - val_mse: 0.4314 - lr: 0.0010 - 706ms/epoch - 177ms/step\n",
            "Epoch 100/1000\n",
            "4/4 - 1s - loss: 0.5020 - mse: 0.4751 - val_loss: 0.4295 - val_mse: 0.4295 - lr: 0.0010 - 694ms/epoch - 174ms/step\n",
            "Epoch 101/1000\n",
            "4/4 - 1s - loss: 0.5011 - mse: 0.4741 - val_loss: 0.4273 - val_mse: 0.4273 - lr: 0.0010 - 725ms/epoch - 181ms/step\n",
            "Epoch 102/1000\n",
            "4/4 - 1s - loss: 0.4988 - mse: 0.4721 - val_loss: 0.4251 - val_mse: 0.4251 - lr: 0.0010 - 708ms/epoch - 177ms/step\n",
            "Epoch 103/1000\n",
            "4/4 - 1s - loss: 0.4992 - mse: 0.4725 - val_loss: 0.4229 - val_mse: 0.4229 - lr: 0.0010 - 710ms/epoch - 177ms/step\n",
            "Epoch 104/1000\n",
            "4/4 - 1s - loss: 0.4968 - mse: 0.4701 - val_loss: 0.4208 - val_mse: 0.4208 - lr: 0.0010 - 698ms/epoch - 174ms/step\n",
            "Epoch 105/1000\n",
            "4/4 - 1s - loss: 0.4966 - mse: 0.4699 - val_loss: 0.4189 - val_mse: 0.4189 - lr: 0.0010 - 699ms/epoch - 175ms/step\n",
            "Epoch 106/1000\n",
            "4/4 - 1s - loss: 0.4957 - mse: 0.4691 - val_loss: 0.4169 - val_mse: 0.4169 - lr: 0.0010 - 695ms/epoch - 174ms/step\n",
            "Epoch 107/1000\n",
            "4/4 - 1s - loss: 0.4934 - mse: 0.4669 - val_loss: 0.4152 - val_mse: 0.4152 - lr: 0.0010 - 703ms/epoch - 176ms/step\n",
            "Epoch 108/1000\n",
            "4/4 - 1s - loss: 0.4914 - mse: 0.4649 - val_loss: 0.4134 - val_mse: 0.4134 - lr: 0.0010 - 697ms/epoch - 174ms/step\n",
            "Epoch 109/1000\n",
            "4/4 - 1s - loss: 0.4912 - mse: 0.4648 - val_loss: 0.4116 - val_mse: 0.4116 - lr: 0.0010 - 700ms/epoch - 175ms/step\n",
            "Epoch 110/1000\n",
            "4/4 - 1s - loss: 0.4897 - mse: 0.4635 - val_loss: 0.4100 - val_mse: 0.4100 - lr: 0.0010 - 689ms/epoch - 172ms/step\n",
            "Epoch 111/1000\n",
            "4/4 - 1s - loss: 0.4887 - mse: 0.4624 - val_loss: 0.4083 - val_mse: 0.4083 - lr: 0.0010 - 686ms/epoch - 172ms/step\n",
            "Epoch 112/1000\n",
            "4/4 - 1s - loss: 0.4878 - mse: 0.4614 - val_loss: 0.4069 - val_mse: 0.4069 - lr: 0.0010 - 692ms/epoch - 173ms/step\n",
            "Epoch 113/1000\n",
            "4/4 - 1s - loss: 0.4858 - mse: 0.4597 - val_loss: 0.4057 - val_mse: 0.4057 - lr: 0.0010 - 690ms/epoch - 172ms/step\n",
            "Epoch 114/1000\n",
            "4/4 - 1s - loss: 0.4851 - mse: 0.4590 - val_loss: 0.4042 - val_mse: 0.4042 - lr: 0.0010 - 712ms/epoch - 178ms/step\n",
            "Epoch 115/1000\n",
            "4/4 - 1s - loss: 0.4854 - mse: 0.4592 - val_loss: 0.4029 - val_mse: 0.4029 - lr: 0.0010 - 701ms/epoch - 175ms/step\n",
            "Epoch 116/1000\n",
            "4/4 - 1s - loss: 0.4825 - mse: 0.4566 - val_loss: 0.4016 - val_mse: 0.4016 - lr: 0.0010 - 709ms/epoch - 177ms/step\n",
            "Epoch 117/1000\n",
            "4/4 - 1s - loss: 0.4818 - mse: 0.4559 - val_loss: 0.4007 - val_mse: 0.4007 - lr: 0.0010 - 700ms/epoch - 175ms/step\n",
            "Epoch 118/1000\n",
            "4/4 - 1s - loss: 0.4798 - mse: 0.4540 - val_loss: 0.3994 - val_mse: 0.3994 - lr: 0.0010 - 713ms/epoch - 178ms/step\n",
            "Epoch 119/1000\n",
            "4/4 - 1s - loss: 0.4806 - mse: 0.4548 - val_loss: 0.3980 - val_mse: 0.3980 - lr: 0.0010 - 704ms/epoch - 176ms/step\n",
            "Epoch 120/1000\n",
            "4/4 - 1s - loss: 0.4793 - mse: 0.4538 - val_loss: 0.3969 - val_mse: 0.3969 - lr: 0.0010 - 691ms/epoch - 173ms/step\n",
            "Epoch 121/1000\n",
            "4/4 - 1s - loss: 0.4786 - mse: 0.4530 - val_loss: 0.3959 - val_mse: 0.3959 - lr: 0.0010 - 696ms/epoch - 174ms/step\n",
            "Epoch 122/1000\n",
            "4/4 - 1s - loss: 0.4779 - mse: 0.4522 - val_loss: 0.3948 - val_mse: 0.3948 - lr: 0.0010 - 715ms/epoch - 179ms/step\n",
            "Epoch 123/1000\n",
            "4/4 - 1s - loss: 0.4771 - mse: 0.4513 - val_loss: 0.3941 - val_mse: 0.3941 - lr: 0.0010 - 689ms/epoch - 172ms/step\n",
            "Epoch 124/1000\n",
            "4/4 - 1s - loss: 0.4774 - mse: 0.4519 - val_loss: 0.3934 - val_mse: 0.3934 - lr: 0.0010 - 689ms/epoch - 172ms/step\n",
            "Epoch 125/1000\n",
            "4/4 - 1s - loss: 0.4740 - mse: 0.4486 - val_loss: 0.3926 - val_mse: 0.3926 - lr: 0.0010 - 714ms/epoch - 178ms/step\n",
            "Epoch 126/1000\n",
            "4/4 - 1s - loss: 0.4735 - mse: 0.4479 - val_loss: 0.3919 - val_mse: 0.3919 - lr: 0.0010 - 684ms/epoch - 171ms/step\n",
            "Epoch 127/1000\n",
            "4/4 - 1s - loss: 0.4728 - mse: 0.4472 - val_loss: 0.3912 - val_mse: 0.3912 - lr: 0.0010 - 702ms/epoch - 175ms/step\n",
            "Epoch 128/1000\n",
            "4/4 - 1s - loss: 0.4710 - mse: 0.4457 - val_loss: 0.3905 - val_mse: 0.3905 - lr: 0.0010 - 699ms/epoch - 175ms/step\n",
            "Epoch 129/1000\n",
            "4/4 - 1s - loss: 0.4719 - mse: 0.4465 - val_loss: 0.3897 - val_mse: 0.3897 - lr: 0.0010 - 692ms/epoch - 173ms/step\n",
            "Epoch 130/1000\n",
            "4/4 - 1s - loss: 0.4720 - mse: 0.4467 - val_loss: 0.3888 - val_mse: 0.3888 - lr: 0.0010 - 692ms/epoch - 173ms/step\n",
            "Epoch 131/1000\n",
            "4/4 - 1s - loss: 0.4705 - mse: 0.4451 - val_loss: 0.3880 - val_mse: 0.3880 - lr: 0.0010 - 691ms/epoch - 173ms/step\n",
            "Epoch 132/1000\n",
            "4/4 - 1s - loss: 0.4703 - mse: 0.4451 - val_loss: 0.3875 - val_mse: 0.3875 - lr: 0.0010 - 693ms/epoch - 173ms/step\n",
            "Epoch 133/1000\n",
            "4/4 - 1s - loss: 0.4683 - mse: 0.4432 - val_loss: 0.3870 - val_mse: 0.3870 - lr: 0.0010 - 694ms/epoch - 173ms/step\n",
            "Epoch 134/1000\n",
            "4/4 - 1s - loss: 0.4690 - mse: 0.4439 - val_loss: 0.3866 - val_mse: 0.3866 - lr: 0.0010 - 697ms/epoch - 174ms/step\n",
            "Epoch 135/1000\n",
            "4/4 - 1s - loss: 0.4681 - mse: 0.4429 - val_loss: 0.3861 - val_mse: 0.3861 - lr: 0.0010 - 696ms/epoch - 174ms/step\n",
            "Epoch 136/1000\n",
            "4/4 - 1s - loss: 0.4675 - mse: 0.4423 - val_loss: 0.3856 - val_mse: 0.3856 - lr: 0.0010 - 688ms/epoch - 172ms/step\n",
            "Epoch 137/1000\n",
            "4/4 - 1s - loss: 0.4667 - mse: 0.4417 - val_loss: 0.3851 - val_mse: 0.3851 - lr: 0.0010 - 686ms/epoch - 171ms/step\n",
            "Epoch 138/1000\n",
            "4/4 - 1s - loss: 0.4669 - mse: 0.4419 - val_loss: 0.3848 - val_mse: 0.3848 - lr: 0.0010 - 706ms/epoch - 177ms/step\n",
            "Epoch 139/1000\n",
            "4/4 - 1s - loss: 0.4652 - mse: 0.4401 - val_loss: 0.3847 - val_mse: 0.3847 - lr: 0.0010 - 690ms/epoch - 173ms/step\n",
            "Epoch 140/1000\n",
            "4/4 - 1s - loss: 0.4639 - mse: 0.4390 - val_loss: 0.3843 - val_mse: 0.3843 - lr: 0.0010 - 694ms/epoch - 173ms/step\n",
            "Epoch 141/1000\n",
            "4/4 - 1s - loss: 0.4644 - mse: 0.4394 - val_loss: 0.3840 - val_mse: 0.3840 - lr: 0.0010 - 698ms/epoch - 175ms/step\n",
            "Epoch 142/1000\n",
            "4/4 - 1s - loss: 0.4625 - mse: 0.4376 - val_loss: 0.3836 - val_mse: 0.3836 - lr: 0.0010 - 689ms/epoch - 172ms/step\n",
            "Epoch 143/1000\n",
            "4/4 - 1s - loss: 0.4639 - mse: 0.4389 - val_loss: 0.3831 - val_mse: 0.3831 - lr: 0.0010 - 690ms/epoch - 172ms/step\n",
            "Epoch 144/1000\n",
            "4/4 - 1s - loss: 0.4619 - mse: 0.4371 - val_loss: 0.3828 - val_mse: 0.3828 - lr: 0.0010 - 692ms/epoch - 173ms/step\n",
            "Epoch 145/1000\n",
            "4/4 - 1s - loss: 0.4619 - mse: 0.4370 - val_loss: 0.3825 - val_mse: 0.3825 - lr: 0.0010 - 687ms/epoch - 172ms/step\n",
            "Epoch 146/1000\n",
            "4/4 - 1s - loss: 0.4613 - mse: 0.4364 - val_loss: 0.3823 - val_mse: 0.3823 - lr: 0.0010 - 709ms/epoch - 177ms/step\n",
            "Epoch 147/1000\n",
            "4/4 - 1s - loss: 0.4617 - mse: 0.4369 - val_loss: 0.3822 - val_mse: 0.3822 - lr: 0.0010 - 700ms/epoch - 175ms/step\n",
            "Epoch 148/1000\n",
            "4/4 - 1s - loss: 0.4601 - mse: 0.4353 - val_loss: 0.3821 - val_mse: 0.3821 - lr: 0.0010 - 688ms/epoch - 172ms/step\n",
            "Epoch 149/1000\n",
            "4/4 - 1s - loss: 0.4598 - mse: 0.4352 - val_loss: 0.3820 - val_mse: 0.3820 - lr: 0.0010 - 706ms/epoch - 176ms/step\n",
            "Epoch 150/1000\n",
            "4/4 - 1s - loss: 0.4589 - mse: 0.4342 - val_loss: 0.3817 - val_mse: 0.3817 - lr: 0.0010 - 719ms/epoch - 180ms/step\n",
            "Epoch 151/1000\n",
            "4/4 - 1s - loss: 0.4590 - mse: 0.4343 - val_loss: 0.3814 - val_mse: 0.3814 - lr: 0.0010 - 705ms/epoch - 176ms/step\n",
            "Epoch 152/1000\n",
            "4/4 - 1s - loss: 0.4578 - mse: 0.4331 - val_loss: 0.3812 - val_mse: 0.3812 - lr: 0.0010 - 701ms/epoch - 175ms/step\n",
            "Epoch 153/1000\n",
            "4/4 - 1s - loss: 0.4575 - mse: 0.4328 - val_loss: 0.3810 - val_mse: 0.3810 - lr: 0.0010 - 689ms/epoch - 172ms/step\n",
            "Epoch 154/1000\n",
            "4/4 - 1s - loss: 0.4572 - mse: 0.4327 - val_loss: 0.3809 - val_mse: 0.3809 - lr: 0.0010 - 723ms/epoch - 181ms/step\n",
            "Epoch 155/1000\n",
            "4/4 - 1s - loss: 0.4558 - mse: 0.4313 - val_loss: 0.3808 - val_mse: 0.3808 - lr: 0.0010 - 712ms/epoch - 178ms/step\n",
            "Epoch 156/1000\n",
            "4/4 - 1s - loss: 0.4557 - mse: 0.4312 - val_loss: 0.3805 - val_mse: 0.3805 - lr: 0.0010 - 705ms/epoch - 176ms/step\n",
            "Epoch 157/1000\n",
            "4/4 - 1s - loss: 0.4569 - mse: 0.4322 - val_loss: 0.3805 - val_mse: 0.3805 - lr: 0.0010 - 700ms/epoch - 175ms/step\n",
            "Epoch 158/1000\n",
            "4/4 - 1s - loss: 0.4551 - mse: 0.4306 - val_loss: 0.3803 - val_mse: 0.3803 - lr: 0.0010 - 711ms/epoch - 178ms/step\n",
            "Epoch 159/1000\n",
            "4/4 - 1s - loss: 0.4562 - mse: 0.4316 - val_loss: 0.3802 - val_mse: 0.3802 - lr: 0.0010 - 717ms/epoch - 179ms/step\n",
            "Epoch 160/1000\n",
            "4/4 - 1s - loss: 0.4547 - mse: 0.4301 - val_loss: 0.3802 - val_mse: 0.3802 - lr: 0.0010 - 716ms/epoch - 179ms/step\n",
            "Epoch 161/1000\n",
            "4/4 - 1s - loss: 0.4543 - mse: 0.4299 - val_loss: 0.3800 - val_mse: 0.3800 - lr: 0.0010 - 708ms/epoch - 177ms/step\n",
            "Epoch 162/1000\n",
            "4/4 - 1s - loss: 0.4532 - mse: 0.4288 - val_loss: 0.3798 - val_mse: 0.3798 - lr: 0.0010 - 695ms/epoch - 174ms/step\n",
            "Epoch 163/1000\n",
            "4/4 - 1s - loss: 0.4528 - mse: 0.4284 - val_loss: 0.3797 - val_mse: 0.3797 - lr: 0.0010 - 704ms/epoch - 176ms/step\n",
            "Epoch 164/1000\n",
            "4/4 - 1s - loss: 0.4533 - mse: 0.4289 - val_loss: 0.3797 - val_mse: 0.3797 - lr: 0.0010 - 698ms/epoch - 175ms/step\n",
            "Epoch 165/1000\n",
            "4/4 - 1s - loss: 0.4519 - mse: 0.4275 - val_loss: 0.3797 - val_mse: 0.3797 - lr: 0.0010 - 699ms/epoch - 175ms/step\n",
            "Epoch 166/1000\n",
            "4/4 - 1s - loss: 0.4514 - mse: 0.4272 - val_loss: 0.3796 - val_mse: 0.3796 - lr: 0.0010 - 710ms/epoch - 178ms/step\n",
            "Epoch 167/1000\n",
            "4/4 - 1s - loss: 0.4521 - mse: 0.4278 - val_loss: 0.3795 - val_mse: 0.3795 - lr: 0.0010 - 709ms/epoch - 177ms/step\n",
            "Epoch 168/1000\n",
            "4/4 - 1s - loss: 0.4513 - mse: 0.4271 - val_loss: 0.3794 - val_mse: 0.3794 - lr: 0.0010 - 695ms/epoch - 174ms/step\n",
            "Epoch 169/1000\n",
            "4/4 - 1s - loss: 0.4513 - mse: 0.4270 - val_loss: 0.3792 - val_mse: 0.3792 - lr: 0.0010 - 699ms/epoch - 175ms/step\n",
            "Epoch 170/1000\n",
            "4/4 - 1s - loss: 0.4508 - mse: 0.4265 - val_loss: 0.3791 - val_mse: 0.3791 - lr: 0.0010 - 716ms/epoch - 179ms/step\n",
            "Epoch 171/1000\n",
            "4/4 - 1s - loss: 0.4504 - mse: 0.4262 - val_loss: 0.3791 - val_mse: 0.3791 - lr: 0.0010 - 687ms/epoch - 172ms/step\n",
            "Epoch 172/1000\n",
            "4/4 - 1s - loss: 0.4496 - mse: 0.4254 - val_loss: 0.3791 - val_mse: 0.3791 - lr: 0.0010 - 697ms/epoch - 174ms/step\n",
            "Epoch 173/1000\n",
            "4/4 - 1s - loss: 0.4510 - mse: 0.4268 - val_loss: 0.3791 - val_mse: 0.3791 - lr: 0.0010 - 711ms/epoch - 178ms/step\n",
            "Epoch 174/1000\n",
            "4/4 - 1s - loss: 0.4501 - mse: 0.4259 - val_loss: 0.3791 - val_mse: 0.3791 - lr: 0.0010 - 699ms/epoch - 175ms/step\n",
            "Epoch 175/1000\n",
            "4/4 - 1s - loss: 0.4495 - mse: 0.4253 - val_loss: 0.3790 - val_mse: 0.3790 - lr: 0.0010 - 696ms/epoch - 174ms/step\n",
            "Epoch 176/1000\n",
            "4/4 - 1s - loss: 0.4488 - mse: 0.4248 - val_loss: 0.3790 - val_mse: 0.3790 - lr: 0.0010 - 695ms/epoch - 174ms/step\n",
            "Epoch 177/1000\n",
            "4/4 - 1s - loss: 0.4483 - mse: 0.4242 - val_loss: 0.3790 - val_mse: 0.3790 - lr: 0.0010 - 691ms/epoch - 173ms/step\n",
            "Epoch 178/1000\n",
            "4/4 - 1s - loss: 0.4477 - mse: 0.4236 - val_loss: 0.3790 - val_mse: 0.3790 - lr: 0.0010 - 694ms/epoch - 174ms/step\n",
            "Epoch 179/1000\n",
            "4/4 - 1s - loss: 0.4482 - mse: 0.4240 - val_loss: 0.3790 - val_mse: 0.3790 - lr: 0.0010 - 691ms/epoch - 173ms/step\n",
            "Epoch 180/1000\n",
            "4/4 - 1s - loss: 0.4475 - mse: 0.4234 - val_loss: 0.3789 - val_mse: 0.3789 - lr: 0.0010 - 687ms/epoch - 172ms/step\n",
            "Epoch 181/1000\n",
            "4/4 - 1s - loss: 0.4472 - mse: 0.4231 - val_loss: 0.3788 - val_mse: 0.3788 - lr: 0.0010 - 694ms/epoch - 174ms/step\n",
            "Epoch 182/1000\n",
            "4/4 - 1s - loss: 0.4472 - mse: 0.4231 - val_loss: 0.3787 - val_mse: 0.3787 - lr: 0.0010 - 700ms/epoch - 175ms/step\n",
            "Epoch 183/1000\n",
            "4/4 - 1s - loss: 0.4462 - mse: 0.4223 - val_loss: 0.3785 - val_mse: 0.3785 - lr: 0.0010 - 683ms/epoch - 171ms/step\n",
            "Epoch 184/1000\n",
            "4/4 - 1s - loss: 0.4463 - mse: 0.4225 - val_loss: 0.3785 - val_mse: 0.3785 - lr: 0.0010 - 700ms/epoch - 175ms/step\n",
            "Epoch 185/1000\n",
            "4/4 - 1s - loss: 0.4469 - mse: 0.4228 - val_loss: 0.3784 - val_mse: 0.3784 - lr: 0.0010 - 705ms/epoch - 176ms/step\n",
            "Epoch 186/1000\n",
            "4/4 - 1s - loss: 0.4452 - mse: 0.4214 - val_loss: 0.3784 - val_mse: 0.3784 - lr: 0.0010 - 716ms/epoch - 179ms/step\n",
            "Epoch 187/1000\n",
            "4/4 - 1s - loss: 0.4452 - mse: 0.4213 - val_loss: 0.3786 - val_mse: 0.3786 - lr: 0.0010 - 706ms/epoch - 176ms/step\n",
            "Epoch 188/1000\n",
            "4/4 - 1s - loss: 0.4449 - mse: 0.4211 - val_loss: 0.3786 - val_mse: 0.3786 - lr: 0.0010 - 707ms/epoch - 177ms/step\n",
            "Epoch 189/1000\n",
            "4/4 - 1s - loss: 0.4443 - mse: 0.4205 - val_loss: 0.3785 - val_mse: 0.3785 - lr: 0.0010 - 706ms/epoch - 176ms/step\n",
            "Epoch 190/1000\n",
            "4/4 - 1s - loss: 0.4458 - mse: 0.4219 - val_loss: 0.3786 - val_mse: 0.3786 - lr: 0.0010 - 706ms/epoch - 176ms/step\n",
            "Epoch 191/1000\n",
            "4/4 - 1s - loss: 0.4449 - mse: 0.4210 - val_loss: 0.3785 - val_mse: 0.3785 - lr: 0.0010 - 701ms/epoch - 175ms/step\n",
            "Epoch 192/1000\n",
            "\n",
            "Epoch 192: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "4/4 - 1s - loss: 0.4448 - mse: 0.4210 - val_loss: 0.3784 - val_mse: 0.3784 - lr: 0.0010 - 698ms/epoch - 174ms/step\n",
            "Epoch 193/1000\n",
            "4/4 - 1s - loss: 0.4442 - mse: 0.4204 - val_loss: 0.3784 - val_mse: 0.3784 - lr: 1.0000e-04 - 696ms/epoch - 174ms/step\n",
            "Epoch 194/1000\n",
            "4/4 - 1s - loss: 0.4443 - mse: 0.4205 - val_loss: 0.3784 - val_mse: 0.3784 - lr: 1.0000e-04 - 700ms/epoch - 175ms/step\n",
            "Epoch 195/1000\n",
            "4/4 - 1s - loss: 0.4450 - mse: 0.4211 - val_loss: 0.3784 - val_mse: 0.3784 - lr: 1.0000e-04 - 696ms/epoch - 174ms/step\n",
            "Epoch 196/1000\n",
            "4/4 - 1s - loss: 0.4445 - mse: 0.4206 - val_loss: 0.3784 - val_mse: 0.3784 - lr: 1.0000e-04 - 695ms/epoch - 174ms/step\n",
            "Epoch 197/1000\n",
            "4/4 - 1s - loss: 0.4432 - mse: 0.4195 - val_loss: 0.3784 - val_mse: 0.3784 - lr: 1.0000e-04 - 698ms/epoch - 174ms/step\n",
            "Epoch 198/1000\n",
            "4/4 - 1s - loss: 0.4437 - mse: 0.4200 - val_loss: 0.3784 - val_mse: 0.3784 - lr: 1.0000e-04 - 707ms/epoch - 177ms/step\n",
            "Epoch 199/1000\n",
            "\n",
            "Epoch 199: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
            "4/4 - 1s - loss: 0.4440 - mse: 0.4202 - val_loss: 0.3784 - val_mse: 0.3784 - lr: 1.0000e-04 - 686ms/epoch - 171ms/step\n",
            "Epoch 200/1000\n",
            "4/4 - 1s - loss: 0.4449 - mse: 0.4211 - val_loss: 0.3784 - val_mse: 0.3784 - lr: 1.0000e-05 - 700ms/epoch - 175ms/step\n",
            "Epoch 201/1000\n",
            "4/4 - 1s - loss: 0.4440 - mse: 0.4201 - val_loss: 0.3784 - val_mse: 0.3784 - lr: 1.0000e-05 - 710ms/epoch - 177ms/step\n",
            "Epoch 202/1000\n",
            "4/4 - 1s - loss: 0.4440 - mse: 0.4202 - val_loss: 0.3784 - val_mse: 0.3784 - lr: 1.0000e-05 - 700ms/epoch - 175ms/step\n",
            "Epoch 203/1000\n",
            "4/4 - 1s - loss: 0.4450 - mse: 0.4211 - val_loss: 0.3784 - val_mse: 0.3784 - lr: 1.0000e-05 - 704ms/epoch - 176ms/step\n",
            "Epoch 204/1000\n",
            "4/4 - 1s - loss: 0.4445 - mse: 0.4206 - val_loss: 0.3784 - val_mse: 0.3784 - lr: 1.0000e-05 - 695ms/epoch - 174ms/step\n",
            "Epoch 205/1000\n",
            "4/4 - 1s - loss: 0.4448 - mse: 0.4210 - val_loss: 0.3784 - val_mse: 0.3784 - lr: 1.0000e-05 - 691ms/epoch - 173ms/step\n",
            "Epoch 205: early stopping\n",
            "==================================================\n",
            "Step 8\n",
            "==================================================\n",
            "Epoch 1/1000\n",
            "4/4 - 4s - loss: 2.6007 - mse: 2.4415 - val_loss: 0.9139 - val_mse: 0.9139 - lr: 0.0010 - 4s/epoch - 943ms/step\n",
            "Epoch 2/1000\n",
            "4/4 - 1s - loss: 1.8470 - mse: 1.7374 - val_loss: 0.8921 - val_mse: 0.8921 - lr: 0.0010 - 701ms/epoch - 175ms/step\n",
            "Epoch 3/1000\n",
            "4/4 - 1s - loss: 1.5333 - mse: 1.4438 - val_loss: 0.8915 - val_mse: 0.8915 - lr: 0.0010 - 694ms/epoch - 174ms/step\n",
            "Epoch 4/1000\n",
            "4/4 - 1s - loss: 1.3701 - mse: 1.2897 - val_loss: 0.8857 - val_mse: 0.8857 - lr: 0.0010 - 696ms/epoch - 174ms/step\n",
            "Epoch 5/1000\n",
            "4/4 - 1s - loss: 1.2634 - mse: 1.1889 - val_loss: 0.8713 - val_mse: 0.8713 - lr: 0.0010 - 682ms/epoch - 170ms/step\n",
            "Epoch 6/1000\n",
            "4/4 - 1s - loss: 1.2017 - mse: 1.1303 - val_loss: 0.8593 - val_mse: 0.8593 - lr: 0.0010 - 697ms/epoch - 174ms/step\n",
            "Epoch 7/1000\n",
            "4/4 - 1s - loss: 1.1490 - mse: 1.0808 - val_loss: 0.8540 - val_mse: 0.8540 - lr: 0.0010 - 692ms/epoch - 173ms/step\n",
            "Epoch 8/1000\n",
            "4/4 - 1s - loss: 1.1067 - mse: 1.0411 - val_loss: 0.8517 - val_mse: 0.8517 - lr: 0.0010 - 717ms/epoch - 179ms/step\n",
            "Epoch 9/1000\n",
            "4/4 - 1s - loss: 1.0741 - mse: 1.0104 - val_loss: 0.8489 - val_mse: 0.8489 - lr: 0.0010 - 697ms/epoch - 174ms/step\n",
            "Epoch 10/1000\n",
            "4/4 - 1s - loss: 1.0396 - mse: 0.9784 - val_loss: 0.8435 - val_mse: 0.8435 - lr: 0.0010 - 696ms/epoch - 174ms/step\n",
            "Epoch 11/1000\n",
            "4/4 - 1s - loss: 1.0201 - mse: 0.9594 - val_loss: 0.8367 - val_mse: 0.8367 - lr: 0.0010 - 690ms/epoch - 172ms/step\n",
            "Epoch 12/1000\n",
            "4/4 - 1s - loss: 0.9980 - mse: 0.9394 - val_loss: 0.8297 - val_mse: 0.8297 - lr: 0.0010 - 685ms/epoch - 171ms/step\n",
            "Epoch 13/1000\n",
            "4/4 - 1s - loss: 0.9745 - mse: 0.9173 - val_loss: 0.8238 - val_mse: 0.8238 - lr: 0.0010 - 695ms/epoch - 174ms/step\n",
            "Epoch 14/1000\n",
            "4/4 - 1s - loss: 0.9574 - mse: 0.9009 - val_loss: 0.8185 - val_mse: 0.8185 - lr: 0.0010 - 698ms/epoch - 175ms/step\n",
            "Epoch 15/1000\n",
            "4/4 - 1s - loss: 0.9418 - mse: 0.8864 - val_loss: 0.8119 - val_mse: 0.8119 - lr: 0.0010 - 689ms/epoch - 172ms/step\n",
            "Epoch 16/1000\n",
            "4/4 - 1s - loss: 0.9295 - mse: 0.8752 - val_loss: 0.8047 - val_mse: 0.8047 - lr: 0.0010 - 699ms/epoch - 175ms/step\n",
            "Epoch 17/1000\n",
            "4/4 - 1s - loss: 0.9090 - mse: 0.8564 - val_loss: 0.7971 - val_mse: 0.7971 - lr: 0.0010 - 697ms/epoch - 174ms/step\n",
            "Epoch 18/1000\n",
            "4/4 - 1s - loss: 0.8936 - mse: 0.8419 - val_loss: 0.7904 - val_mse: 0.7904 - lr: 0.0010 - 715ms/epoch - 179ms/step\n",
            "Epoch 19/1000\n",
            "4/4 - 1s - loss: 0.8864 - mse: 0.8352 - val_loss: 0.7838 - val_mse: 0.7838 - lr: 0.0010 - 721ms/epoch - 180ms/step\n",
            "Epoch 20/1000\n",
            "4/4 - 1s - loss: 0.8710 - mse: 0.8207 - val_loss: 0.7779 - val_mse: 0.7779 - lr: 0.0010 - 712ms/epoch - 178ms/step\n",
            "Epoch 21/1000\n",
            "4/4 - 1s - loss: 0.8582 - mse: 0.8086 - val_loss: 0.7734 - val_mse: 0.7734 - lr: 0.0010 - 712ms/epoch - 178ms/step\n",
            "Epoch 22/1000\n",
            "4/4 - 1s - loss: 0.8504 - mse: 0.8018 - val_loss: 0.7693 - val_mse: 0.7693 - lr: 0.0010 - 716ms/epoch - 179ms/step\n",
            "Epoch 23/1000\n",
            "4/4 - 1s - loss: 0.8352 - mse: 0.7873 - val_loss: 0.7640 - val_mse: 0.7640 - lr: 0.0010 - 695ms/epoch - 174ms/step\n",
            "Epoch 24/1000\n",
            "4/4 - 1s - loss: 0.8236 - mse: 0.7764 - val_loss: 0.7581 - val_mse: 0.7581 - lr: 0.0010 - 694ms/epoch - 173ms/step\n",
            "Epoch 25/1000\n",
            "4/4 - 1s - loss: 0.8136 - mse: 0.7672 - val_loss: 0.7518 - val_mse: 0.7518 - lr: 0.0010 - 699ms/epoch - 175ms/step\n",
            "Epoch 26/1000\n",
            "4/4 - 1s - loss: 0.8055 - mse: 0.7596 - val_loss: 0.7465 - val_mse: 0.7465 - lr: 0.0010 - 713ms/epoch - 178ms/step\n",
            "Epoch 27/1000\n",
            "4/4 - 1s - loss: 0.7972 - mse: 0.7519 - val_loss: 0.7413 - val_mse: 0.7413 - lr: 0.0010 - 711ms/epoch - 178ms/step\n",
            "Epoch 28/1000\n",
            "4/4 - 1s - loss: 0.7860 - mse: 0.7416 - val_loss: 0.7369 - val_mse: 0.7369 - lr: 0.0010 - 703ms/epoch - 176ms/step\n",
            "Epoch 29/1000\n",
            "4/4 - 1s - loss: 0.7758 - mse: 0.7320 - val_loss: 0.7317 - val_mse: 0.7317 - lr: 0.0010 - 692ms/epoch - 173ms/step\n",
            "Epoch 30/1000\n",
            "4/4 - 1s - loss: 0.7694 - mse: 0.7253 - val_loss: 0.7252 - val_mse: 0.7252 - lr: 0.0010 - 697ms/epoch - 174ms/step\n",
            "Epoch 31/1000\n",
            "4/4 - 1s - loss: 0.7631 - mse: 0.7195 - val_loss: 0.7193 - val_mse: 0.7193 - lr: 0.0010 - 696ms/epoch - 174ms/step\n",
            "Epoch 32/1000\n",
            "4/4 - 1s - loss: 0.7552 - mse: 0.7126 - val_loss: 0.7140 - val_mse: 0.7140 - lr: 0.0010 - 701ms/epoch - 175ms/step\n",
            "Epoch 33/1000\n",
            "4/4 - 1s - loss: 0.7442 - mse: 0.7023 - val_loss: 0.7079 - val_mse: 0.7079 - lr: 0.0010 - 696ms/epoch - 174ms/step\n",
            "Epoch 34/1000\n",
            "4/4 - 1s - loss: 0.7368 - mse: 0.6954 - val_loss: 0.7030 - val_mse: 0.7030 - lr: 0.0010 - 706ms/epoch - 177ms/step\n",
            "Epoch 35/1000\n",
            "4/4 - 1s - loss: 0.7303 - mse: 0.6886 - val_loss: 0.6977 - val_mse: 0.6977 - lr: 0.0010 - 691ms/epoch - 173ms/step\n",
            "Epoch 36/1000\n",
            "4/4 - 1s - loss: 0.7233 - mse: 0.6821 - val_loss: 0.6924 - val_mse: 0.6924 - lr: 0.0010 - 683ms/epoch - 171ms/step\n",
            "Epoch 37/1000\n",
            "4/4 - 1s - loss: 0.7148 - mse: 0.6746 - val_loss: 0.6870 - val_mse: 0.6870 - lr: 0.0010 - 698ms/epoch - 174ms/step\n",
            "Epoch 38/1000\n",
            "4/4 - 1s - loss: 0.7072 - mse: 0.6676 - val_loss: 0.6805 - val_mse: 0.6805 - lr: 0.0010 - 688ms/epoch - 172ms/step\n",
            "Epoch 39/1000\n",
            "4/4 - 1s - loss: 0.6995 - mse: 0.6597 - val_loss: 0.6733 - val_mse: 0.6733 - lr: 0.0010 - 694ms/epoch - 174ms/step\n",
            "Epoch 40/1000\n",
            "4/4 - 1s - loss: 0.6944 - mse: 0.6552 - val_loss: 0.6677 - val_mse: 0.6677 - lr: 0.0010 - 701ms/epoch - 175ms/step\n",
            "Epoch 41/1000\n",
            "4/4 - 1s - loss: 0.6883 - mse: 0.6500 - val_loss: 0.6635 - val_mse: 0.6635 - lr: 0.0010 - 692ms/epoch - 173ms/step\n",
            "Epoch 42/1000\n",
            "4/4 - 1s - loss: 0.6789 - mse: 0.6405 - val_loss: 0.6592 - val_mse: 0.6592 - lr: 0.0010 - 704ms/epoch - 176ms/step\n",
            "Epoch 43/1000\n",
            "4/4 - 1s - loss: 0.6785 - mse: 0.6405 - val_loss: 0.6540 - val_mse: 0.6540 - lr: 0.0010 - 705ms/epoch - 176ms/step\n",
            "Epoch 44/1000\n",
            "4/4 - 1s - loss: 0.6678 - mse: 0.6305 - val_loss: 0.6462 - val_mse: 0.6462 - lr: 0.0010 - 710ms/epoch - 177ms/step\n",
            "Epoch 45/1000\n",
            "4/4 - 1s - loss: 0.6662 - mse: 0.6289 - val_loss: 0.6391 - val_mse: 0.6391 - lr: 0.0010 - 706ms/epoch - 177ms/step\n",
            "Epoch 46/1000\n",
            "4/4 - 1s - loss: 0.6575 - mse: 0.6204 - val_loss: 0.6336 - val_mse: 0.6336 - lr: 0.0010 - 719ms/epoch - 180ms/step\n",
            "Epoch 47/1000\n",
            "4/4 - 1s - loss: 0.6541 - mse: 0.6172 - val_loss: 0.6274 - val_mse: 0.6274 - lr: 0.0010 - 695ms/epoch - 174ms/step\n",
            "Epoch 48/1000\n",
            "4/4 - 1s - loss: 0.6468 - mse: 0.6104 - val_loss: 0.6204 - val_mse: 0.6204 - lr: 0.0010 - 699ms/epoch - 175ms/step\n",
            "Epoch 49/1000\n",
            "4/4 - 1s - loss: 0.6442 - mse: 0.6082 - val_loss: 0.6141 - val_mse: 0.6141 - lr: 0.0010 - 691ms/epoch - 173ms/step\n",
            "Epoch 50/1000\n",
            "4/4 - 1s - loss: 0.6386 - mse: 0.6031 - val_loss: 0.6086 - val_mse: 0.6086 - lr: 0.0010 - 696ms/epoch - 174ms/step\n",
            "Epoch 51/1000\n",
            "4/4 - 1s - loss: 0.6347 - mse: 0.5993 - val_loss: 0.6043 - val_mse: 0.6043 - lr: 0.0010 - 708ms/epoch - 177ms/step\n",
            "Epoch 52/1000\n",
            "4/4 - 1s - loss: 0.6258 - mse: 0.5907 - val_loss: 0.6001 - val_mse: 0.6001 - lr: 0.0010 - 693ms/epoch - 173ms/step\n",
            "Epoch 53/1000\n",
            "4/4 - 1s - loss: 0.6203 - mse: 0.5858 - val_loss: 0.5954 - val_mse: 0.5954 - lr: 0.0010 - 705ms/epoch - 176ms/step\n",
            "Epoch 54/1000\n",
            "4/4 - 1s - loss: 0.6168 - mse: 0.5823 - val_loss: 0.5897 - val_mse: 0.5897 - lr: 0.0010 - 696ms/epoch - 174ms/step\n",
            "Epoch 55/1000\n",
            "4/4 - 1s - loss: 0.6156 - mse: 0.5812 - val_loss: 0.5832 - val_mse: 0.5832 - lr: 0.0010 - 698ms/epoch - 174ms/step\n",
            "Epoch 56/1000\n",
            "4/4 - 1s - loss: 0.6049 - mse: 0.5714 - val_loss: 0.5777 - val_mse: 0.5777 - lr: 0.0010 - 708ms/epoch - 177ms/step\n",
            "Epoch 57/1000\n",
            "4/4 - 1s - loss: 0.6051 - mse: 0.5714 - val_loss: 0.5729 - val_mse: 0.5729 - lr: 0.0010 - 691ms/epoch - 173ms/step\n",
            "Epoch 58/1000\n",
            "4/4 - 1s - loss: 0.5973 - mse: 0.5640 - val_loss: 0.5670 - val_mse: 0.5670 - lr: 0.0010 - 690ms/epoch - 173ms/step\n",
            "Epoch 59/1000\n",
            "4/4 - 1s - loss: 0.5973 - mse: 0.5637 - val_loss: 0.5619 - val_mse: 0.5619 - lr: 0.0010 - 688ms/epoch - 172ms/step\n",
            "Epoch 60/1000\n",
            "4/4 - 1s - loss: 0.5899 - mse: 0.5572 - val_loss: 0.5574 - val_mse: 0.5574 - lr: 0.0010 - 699ms/epoch - 175ms/step\n",
            "Epoch 61/1000\n",
            "4/4 - 1s - loss: 0.5863 - mse: 0.5537 - val_loss: 0.5536 - val_mse: 0.5536 - lr: 0.0010 - 691ms/epoch - 173ms/step\n",
            "Epoch 62/1000\n",
            "4/4 - 1s - loss: 0.5833 - mse: 0.5510 - val_loss: 0.5492 - val_mse: 0.5492 - lr: 0.0010 - 691ms/epoch - 173ms/step\n",
            "Epoch 63/1000\n",
            "4/4 - 1s - loss: 0.5830 - mse: 0.5507 - val_loss: 0.5433 - val_mse: 0.5433 - lr: 0.0010 - 687ms/epoch - 172ms/step\n",
            "Epoch 64/1000\n",
            "4/4 - 1s - loss: 0.5782 - mse: 0.5459 - val_loss: 0.5377 - val_mse: 0.5377 - lr: 0.0010 - 698ms/epoch - 175ms/step\n",
            "Epoch 65/1000\n",
            "4/4 - 1s - loss: 0.5732 - mse: 0.5414 - val_loss: 0.5319 - val_mse: 0.5319 - lr: 0.0010 - 711ms/epoch - 178ms/step\n",
            "Epoch 66/1000\n",
            "4/4 - 1s - loss: 0.5708 - mse: 0.5389 - val_loss: 0.5275 - val_mse: 0.5275 - lr: 0.0010 - 702ms/epoch - 175ms/step\n",
            "Epoch 67/1000\n",
            "4/4 - 1s - loss: 0.5687 - mse: 0.5370 - val_loss: 0.5240 - val_mse: 0.5240 - lr: 0.0010 - 698ms/epoch - 174ms/step\n",
            "Epoch 68/1000\n",
            "4/4 - 1s - loss: 0.5654 - mse: 0.5340 - val_loss: 0.5201 - val_mse: 0.5201 - lr: 0.0010 - 691ms/epoch - 173ms/step\n",
            "Epoch 69/1000\n",
            "4/4 - 1s - loss: 0.5632 - mse: 0.5317 - val_loss: 0.5155 - val_mse: 0.5155 - lr: 0.0010 - 697ms/epoch - 174ms/step\n",
            "Epoch 70/1000\n",
            "4/4 - 1s - loss: 0.5564 - mse: 0.5254 - val_loss: 0.5102 - val_mse: 0.5102 - lr: 0.0010 - 683ms/epoch - 171ms/step\n",
            "Epoch 71/1000\n",
            "4/4 - 1s - loss: 0.5557 - mse: 0.5245 - val_loss: 0.5056 - val_mse: 0.5056 - lr: 0.0010 - 679ms/epoch - 170ms/step\n",
            "Epoch 72/1000\n",
            "4/4 - 1s - loss: 0.5514 - mse: 0.5208 - val_loss: 0.5016 - val_mse: 0.5016 - lr: 0.0010 - 698ms/epoch - 175ms/step\n",
            "Epoch 73/1000\n",
            "4/4 - 1s - loss: 0.5508 - mse: 0.5202 - val_loss: 0.4973 - val_mse: 0.4973 - lr: 0.0010 - 696ms/epoch - 174ms/step\n",
            "Epoch 74/1000\n",
            "4/4 - 1s - loss: 0.5481 - mse: 0.5175 - val_loss: 0.4933 - val_mse: 0.4933 - lr: 0.0010 - 693ms/epoch - 173ms/step\n",
            "Epoch 75/1000\n",
            "4/4 - 1s - loss: 0.5444 - mse: 0.5141 - val_loss: 0.4882 - val_mse: 0.4882 - lr: 0.0010 - 683ms/epoch - 171ms/step\n",
            "Epoch 76/1000\n",
            "4/4 - 1s - loss: 0.5418 - mse: 0.5116 - val_loss: 0.4834 - val_mse: 0.4834 - lr: 0.0010 - 698ms/epoch - 175ms/step\n",
            "Epoch 77/1000\n",
            "4/4 - 1s - loss: 0.5393 - mse: 0.5094 - val_loss: 0.4797 - val_mse: 0.4797 - lr: 0.0010 - 697ms/epoch - 174ms/step\n",
            "Epoch 78/1000\n",
            "4/4 - 1s - loss: 0.5359 - mse: 0.5061 - val_loss: 0.4768 - val_mse: 0.4768 - lr: 0.0010 - 684ms/epoch - 171ms/step\n",
            "Epoch 79/1000\n",
            "4/4 - 1s - loss: 0.5357 - mse: 0.5057 - val_loss: 0.4737 - val_mse: 0.4737 - lr: 0.0010 - 680ms/epoch - 170ms/step\n",
            "Epoch 80/1000\n",
            "4/4 - 1s - loss: 0.5325 - mse: 0.5030 - val_loss: 0.4694 - val_mse: 0.4694 - lr: 0.0010 - 683ms/epoch - 171ms/step\n",
            "Epoch 81/1000\n",
            "4/4 - 1s - loss: 0.5285 - mse: 0.4992 - val_loss: 0.4659 - val_mse: 0.4659 - lr: 0.0010 - 698ms/epoch - 175ms/step\n",
            "Epoch 82/1000\n",
            "4/4 - 1s - loss: 0.5275 - mse: 0.4979 - val_loss: 0.4636 - val_mse: 0.4636 - lr: 0.0010 - 692ms/epoch - 173ms/step\n",
            "Epoch 83/1000\n",
            "4/4 - 1s - loss: 0.5260 - mse: 0.4968 - val_loss: 0.4612 - val_mse: 0.4612 - lr: 0.0010 - 696ms/epoch - 174ms/step\n",
            "Epoch 84/1000\n",
            "4/4 - 1s - loss: 0.5229 - mse: 0.4938 - val_loss: 0.4580 - val_mse: 0.4580 - lr: 0.0010 - 687ms/epoch - 172ms/step\n",
            "Epoch 85/1000\n",
            "4/4 - 1s - loss: 0.5193 - mse: 0.4906 - val_loss: 0.4549 - val_mse: 0.4549 - lr: 0.0010 - 695ms/epoch - 174ms/step\n",
            "Epoch 86/1000\n",
            "4/4 - 1s - loss: 0.5182 - mse: 0.4894 - val_loss: 0.4521 - val_mse: 0.4521 - lr: 0.0010 - 681ms/epoch - 170ms/step\n",
            "Epoch 87/1000\n",
            "4/4 - 1s - loss: 0.5147 - mse: 0.4863 - val_loss: 0.4485 - val_mse: 0.4485 - lr: 0.0010 - 692ms/epoch - 173ms/step\n",
            "Epoch 88/1000\n",
            "4/4 - 1s - loss: 0.5147 - mse: 0.4859 - val_loss: 0.4450 - val_mse: 0.4450 - lr: 0.0010 - 695ms/epoch - 174ms/step\n",
            "Epoch 89/1000\n",
            "4/4 - 1s - loss: 0.5130 - mse: 0.4845 - val_loss: 0.4429 - val_mse: 0.4429 - lr: 0.0010 - 692ms/epoch - 173ms/step\n",
            "Epoch 90/1000\n",
            "4/4 - 1s - loss: 0.5109 - mse: 0.4827 - val_loss: 0.4407 - val_mse: 0.4407 - lr: 0.0010 - 708ms/epoch - 177ms/step\n",
            "Epoch 91/1000\n",
            "4/4 - 1s - loss: 0.5089 - mse: 0.4805 - val_loss: 0.4380 - val_mse: 0.4380 - lr: 0.0010 - 689ms/epoch - 172ms/step\n",
            "Epoch 92/1000\n",
            "4/4 - 1s - loss: 0.5059 - mse: 0.4778 - val_loss: 0.4351 - val_mse: 0.4351 - lr: 0.0010 - 697ms/epoch - 174ms/step\n",
            "Epoch 93/1000\n",
            "4/4 - 1s - loss: 0.5055 - mse: 0.4774 - val_loss: 0.4327 - val_mse: 0.4327 - lr: 0.0010 - 687ms/epoch - 172ms/step\n",
            "Epoch 94/1000\n",
            "4/4 - 1s - loss: 0.5051 - mse: 0.4770 - val_loss: 0.4310 - val_mse: 0.4310 - lr: 0.0010 - 701ms/epoch - 175ms/step\n",
            "Epoch 95/1000\n",
            "4/4 - 1s - loss: 0.5038 - mse: 0.4758 - val_loss: 0.4287 - val_mse: 0.4287 - lr: 0.0010 - 687ms/epoch - 172ms/step\n",
            "Epoch 96/1000\n",
            "4/4 - 1s - loss: 0.4999 - mse: 0.4723 - val_loss: 0.4266 - val_mse: 0.4266 - lr: 0.0010 - 679ms/epoch - 170ms/step\n",
            "Epoch 97/1000\n",
            "4/4 - 1s - loss: 0.5002 - mse: 0.4722 - val_loss: 0.4240 - val_mse: 0.4240 - lr: 0.0010 - 686ms/epoch - 172ms/step\n",
            "Epoch 98/1000\n",
            "4/4 - 1s - loss: 0.4965 - mse: 0.4688 - val_loss: 0.4220 - val_mse: 0.4220 - lr: 0.0010 - 683ms/epoch - 171ms/step\n",
            "Epoch 99/1000\n",
            "4/4 - 1s - loss: 0.4947 - mse: 0.4673 - val_loss: 0.4202 - val_mse: 0.4202 - lr: 0.0010 - 676ms/epoch - 169ms/step\n",
            "Epoch 100/1000\n",
            "4/4 - 1s - loss: 0.4938 - mse: 0.4664 - val_loss: 0.4187 - val_mse: 0.4187 - lr: 0.0010 - 707ms/epoch - 177ms/step\n",
            "Epoch 101/1000\n",
            "4/4 - 1s - loss: 0.4923 - mse: 0.4649 - val_loss: 0.4168 - val_mse: 0.4168 - lr: 0.0010 - 697ms/epoch - 174ms/step\n",
            "Epoch 102/1000\n",
            "4/4 - 1s - loss: 0.4887 - mse: 0.4615 - val_loss: 0.4156 - val_mse: 0.4156 - lr: 0.0010 - 701ms/epoch - 175ms/step\n",
            "Epoch 103/1000\n",
            "4/4 - 1s - loss: 0.4903 - mse: 0.4630 - val_loss: 0.4141 - val_mse: 0.4141 - lr: 0.0010 - 697ms/epoch - 174ms/step\n",
            "Epoch 104/1000\n",
            "4/4 - 1s - loss: 0.4884 - mse: 0.4611 - val_loss: 0.4122 - val_mse: 0.4122 - lr: 0.0010 - 709ms/epoch - 177ms/step\n",
            "Epoch 105/1000\n",
            "4/4 - 1s - loss: 0.4870 - mse: 0.4600 - val_loss: 0.4104 - val_mse: 0.4104 - lr: 0.0010 - 695ms/epoch - 174ms/step\n",
            "Epoch 106/1000\n",
            "4/4 - 1s - loss: 0.4861 - mse: 0.4591 - val_loss: 0.4086 - val_mse: 0.4086 - lr: 0.0010 - 690ms/epoch - 173ms/step\n",
            "Epoch 107/1000\n",
            "4/4 - 1s - loss: 0.4851 - mse: 0.4580 - val_loss: 0.4071 - val_mse: 0.4071 - lr: 0.0010 - 691ms/epoch - 173ms/step\n",
            "Epoch 108/1000\n",
            "4/4 - 1s - loss: 0.4840 - mse: 0.4571 - val_loss: 0.4060 - val_mse: 0.4060 - lr: 0.0010 - 703ms/epoch - 176ms/step\n",
            "Epoch 109/1000\n",
            "4/4 - 1s - loss: 0.4806 - mse: 0.4539 - val_loss: 0.4053 - val_mse: 0.4053 - lr: 0.0010 - 700ms/epoch - 175ms/step\n",
            "Epoch 110/1000\n",
            "4/4 - 1s - loss: 0.4803 - mse: 0.4536 - val_loss: 0.4048 - val_mse: 0.4048 - lr: 0.0010 - 691ms/epoch - 173ms/step\n",
            "Epoch 111/1000\n",
            "4/4 - 1s - loss: 0.4813 - mse: 0.4546 - val_loss: 0.4039 - val_mse: 0.4039 - lr: 0.0010 - 689ms/epoch - 172ms/step\n",
            "Epoch 112/1000\n",
            "4/4 - 1s - loss: 0.4778 - mse: 0.4511 - val_loss: 0.4025 - val_mse: 0.4025 - lr: 0.0010 - 695ms/epoch - 174ms/step\n",
            "Epoch 113/1000\n",
            "4/4 - 1s - loss: 0.4783 - mse: 0.4517 - val_loss: 0.4008 - val_mse: 0.4008 - lr: 0.0010 - 696ms/epoch - 174ms/step\n",
            "Epoch 114/1000\n",
            "4/4 - 1s - loss: 0.4760 - mse: 0.4497 - val_loss: 0.3997 - val_mse: 0.3997 - lr: 0.0010 - 686ms/epoch - 171ms/step\n",
            "Epoch 115/1000\n",
            "4/4 - 1s - loss: 0.4757 - mse: 0.4493 - val_loss: 0.3992 - val_mse: 0.3992 - lr: 0.0010 - 703ms/epoch - 176ms/step\n",
            "Epoch 116/1000\n",
            "4/4 - 1s - loss: 0.4738 - mse: 0.4475 - val_loss: 0.3985 - val_mse: 0.3985 - lr: 0.0010 - 699ms/epoch - 175ms/step\n",
            "Epoch 117/1000\n",
            "4/4 - 1s - loss: 0.4722 - mse: 0.4459 - val_loss: 0.3972 - val_mse: 0.3972 - lr: 0.0010 - 703ms/epoch - 176ms/step\n",
            "Epoch 118/1000\n",
            "4/4 - 1s - loss: 0.4715 - mse: 0.4454 - val_loss: 0.3964 - val_mse: 0.3964 - lr: 0.0010 - 679ms/epoch - 170ms/step\n",
            "Epoch 119/1000\n",
            "4/4 - 1s - loss: 0.4712 - mse: 0.4450 - val_loss: 0.3958 - val_mse: 0.3958 - lr: 0.0010 - 689ms/epoch - 172ms/step\n",
            "Epoch 120/1000\n",
            "4/4 - 1s - loss: 0.4698 - mse: 0.4438 - val_loss: 0.3949 - val_mse: 0.3949 - lr: 0.0010 - 686ms/epoch - 172ms/step\n",
            "Epoch 121/1000\n",
            "4/4 - 1s - loss: 0.4697 - mse: 0.4436 - val_loss: 0.3938 - val_mse: 0.3938 - lr: 0.0010 - 684ms/epoch - 171ms/step\n",
            "Epoch 122/1000\n",
            "4/4 - 1s - loss: 0.4682 - mse: 0.4422 - val_loss: 0.3931 - val_mse: 0.3931 - lr: 0.0010 - 701ms/epoch - 175ms/step\n",
            "Epoch 123/1000\n",
            "4/4 - 1s - loss: 0.4674 - mse: 0.4415 - val_loss: 0.3927 - val_mse: 0.3927 - lr: 0.0010 - 687ms/epoch - 172ms/step\n",
            "Epoch 124/1000\n",
            "4/4 - 1s - loss: 0.4681 - mse: 0.4421 - val_loss: 0.3922 - val_mse: 0.3922 - lr: 0.0010 - 687ms/epoch - 172ms/step\n",
            "Epoch 125/1000\n",
            "4/4 - 1s - loss: 0.4667 - mse: 0.4408 - val_loss: 0.3922 - val_mse: 0.3922 - lr: 0.0010 - 703ms/epoch - 176ms/step\n",
            "Epoch 126/1000\n",
            "4/4 - 1s - loss: 0.4651 - mse: 0.4392 - val_loss: 0.3919 - val_mse: 0.3919 - lr: 0.0010 - 702ms/epoch - 176ms/step\n",
            "Epoch 127/1000\n",
            "4/4 - 1s - loss: 0.4654 - mse: 0.4396 - val_loss: 0.3911 - val_mse: 0.3911 - lr: 0.0010 - 689ms/epoch - 172ms/step\n",
            "Epoch 128/1000\n",
            "4/4 - 1s - loss: 0.4633 - mse: 0.4375 - val_loss: 0.3904 - val_mse: 0.3904 - lr: 0.0010 - 701ms/epoch - 175ms/step\n",
            "Epoch 129/1000\n",
            "4/4 - 1s - loss: 0.4648 - mse: 0.4390 - val_loss: 0.3899 - val_mse: 0.3899 - lr: 0.0010 - 712ms/epoch - 178ms/step\n",
            "Epoch 130/1000\n",
            "4/4 - 1s - loss: 0.4626 - mse: 0.4369 - val_loss: 0.3894 - val_mse: 0.3894 - lr: 0.0010 - 695ms/epoch - 174ms/step\n",
            "Epoch 131/1000\n",
            "4/4 - 1s - loss: 0.4615 - mse: 0.4358 - val_loss: 0.3890 - val_mse: 0.3890 - lr: 0.0010 - 706ms/epoch - 176ms/step\n",
            "Epoch 132/1000\n",
            "4/4 - 1s - loss: 0.4610 - mse: 0.4354 - val_loss: 0.3886 - val_mse: 0.3886 - lr: 0.0010 - 716ms/epoch - 179ms/step\n",
            "Epoch 133/1000\n",
            "4/4 - 1s - loss: 0.4590 - mse: 0.4335 - val_loss: 0.3881 - val_mse: 0.3881 - lr: 0.0010 - 701ms/epoch - 175ms/step\n",
            "Epoch 134/1000\n",
            "4/4 - 1s - loss: 0.4584 - mse: 0.4330 - val_loss: 0.3876 - val_mse: 0.3876 - lr: 0.0010 - 697ms/epoch - 174ms/step\n",
            "Epoch 135/1000\n",
            "4/4 - 1s - loss: 0.4578 - mse: 0.4325 - val_loss: 0.3871 - val_mse: 0.3871 - lr: 0.0010 - 704ms/epoch - 176ms/step\n",
            "Epoch 136/1000\n",
            "4/4 - 1s - loss: 0.4578 - mse: 0.4323 - val_loss: 0.3868 - val_mse: 0.3868 - lr: 0.0010 - 711ms/epoch - 178ms/step\n",
            "Epoch 137/1000\n",
            "4/4 - 1s - loss: 0.4571 - mse: 0.4317 - val_loss: 0.3867 - val_mse: 0.3867 - lr: 0.0010 - 700ms/epoch - 175ms/step\n",
            "Epoch 138/1000\n",
            "4/4 - 1s - loss: 0.4562 - mse: 0.4309 - val_loss: 0.3865 - val_mse: 0.3865 - lr: 0.0010 - 700ms/epoch - 175ms/step\n",
            "Epoch 139/1000\n",
            "4/4 - 1s - loss: 0.4570 - mse: 0.4316 - val_loss: 0.3863 - val_mse: 0.3863 - lr: 0.0010 - 692ms/epoch - 173ms/step\n",
            "Epoch 140/1000\n",
            "4/4 - 1s - loss: 0.4564 - mse: 0.4312 - val_loss: 0.3860 - val_mse: 0.3860 - lr: 0.0010 - 680ms/epoch - 170ms/step\n",
            "Epoch 141/1000\n",
            "4/4 - 1s - loss: 0.4552 - mse: 0.4299 - val_loss: 0.3856 - val_mse: 0.3856 - lr: 0.0010 - 715ms/epoch - 179ms/step\n",
            "Epoch 142/1000\n",
            "4/4 - 1s - loss: 0.4546 - mse: 0.4294 - val_loss: 0.3852 - val_mse: 0.3852 - lr: 0.0010 - 716ms/epoch - 179ms/step\n",
            "Epoch 143/1000\n",
            "4/4 - 1s - loss: 0.4535 - mse: 0.4284 - val_loss: 0.3850 - val_mse: 0.3850 - lr: 0.0010 - 695ms/epoch - 174ms/step\n",
            "Epoch 144/1000\n",
            "4/4 - 1s - loss: 0.4528 - mse: 0.4277 - val_loss: 0.3848 - val_mse: 0.3848 - lr: 0.0010 - 697ms/epoch - 174ms/step\n",
            "Epoch 145/1000\n",
            "4/4 - 1s - loss: 0.4529 - mse: 0.4278 - val_loss: 0.3847 - val_mse: 0.3847 - lr: 0.0010 - 687ms/epoch - 172ms/step\n",
            "Epoch 146/1000\n",
            "4/4 - 1s - loss: 0.4519 - mse: 0.4268 - val_loss: 0.3844 - val_mse: 0.3844 - lr: 0.0010 - 692ms/epoch - 173ms/step\n",
            "Epoch 147/1000\n",
            "4/4 - 1s - loss: 0.4505 - mse: 0.4256 - val_loss: 0.3842 - val_mse: 0.3842 - lr: 0.0010 - 700ms/epoch - 175ms/step\n",
            "Epoch 148/1000\n",
            "4/4 - 1s - loss: 0.4513 - mse: 0.4263 - val_loss: 0.3840 - val_mse: 0.3840 - lr: 0.0010 - 700ms/epoch - 175ms/step\n",
            "Epoch 149/1000\n",
            "4/4 - 1s - loss: 0.4503 - mse: 0.4254 - val_loss: 0.3839 - val_mse: 0.3839 - lr: 0.0010 - 690ms/epoch - 173ms/step\n",
            "Epoch 150/1000\n",
            "4/4 - 1s - loss: 0.4499 - mse: 0.4250 - val_loss: 0.3839 - val_mse: 0.3839 - lr: 0.0010 - 697ms/epoch - 174ms/step\n",
            "Epoch 151/1000\n",
            "4/4 - 1s - loss: 0.4499 - mse: 0.4249 - val_loss: 0.3837 - val_mse: 0.3837 - lr: 0.0010 - 718ms/epoch - 179ms/step\n",
            "Epoch 152/1000\n",
            "4/4 - 1s - loss: 0.4487 - mse: 0.4239 - val_loss: 0.3835 - val_mse: 0.3835 - lr: 0.0010 - 701ms/epoch - 175ms/step\n",
            "Epoch 153/1000\n",
            "4/4 - 1s - loss: 0.4489 - mse: 0.4240 - val_loss: 0.3835 - val_mse: 0.3835 - lr: 0.0010 - 704ms/epoch - 176ms/step\n",
            "Epoch 154/1000\n",
            "4/4 - 1s - loss: 0.4479 - mse: 0.4230 - val_loss: 0.3835 - val_mse: 0.3835 - lr: 0.0010 - 714ms/epoch - 178ms/step\n",
            "Epoch 155/1000\n",
            "4/4 - 1s - loss: 0.4487 - mse: 0.4238 - val_loss: 0.3834 - val_mse: 0.3834 - lr: 0.0010 - 682ms/epoch - 171ms/step\n",
            "Epoch 156/1000\n",
            "4/4 - 1s - loss: 0.4482 - mse: 0.4234 - val_loss: 0.3833 - val_mse: 0.3833 - lr: 0.0010 - 680ms/epoch - 170ms/step\n",
            "Epoch 157/1000\n",
            "4/4 - 1s - loss: 0.4469 - mse: 0.4221 - val_loss: 0.3833 - val_mse: 0.3833 - lr: 0.0010 - 697ms/epoch - 174ms/step\n",
            "Epoch 158/1000\n",
            "4/4 - 1s - loss: 0.4463 - mse: 0.4215 - val_loss: 0.3831 - val_mse: 0.3831 - lr: 0.0010 - 698ms/epoch - 174ms/step\n",
            "Epoch 159/1000\n",
            "4/4 - 1s - loss: 0.4459 - mse: 0.4213 - val_loss: 0.3830 - val_mse: 0.3830 - lr: 0.0010 - 692ms/epoch - 173ms/step\n",
            "Epoch 160/1000\n",
            "4/4 - 1s - loss: 0.4462 - mse: 0.4215 - val_loss: 0.3829 - val_mse: 0.3829 - lr: 0.0010 - 709ms/epoch - 177ms/step\n",
            "Epoch 161/1000\n",
            "4/4 - 1s - loss: 0.4456 - mse: 0.4210 - val_loss: 0.3827 - val_mse: 0.3827 - lr: 0.0010 - 695ms/epoch - 174ms/step\n",
            "Epoch 162/1000\n",
            "4/4 - 1s - loss: 0.4449 - mse: 0.4203 - val_loss: 0.3826 - val_mse: 0.3826 - lr: 0.0010 - 682ms/epoch - 171ms/step\n",
            "Epoch 163/1000\n",
            "4/4 - 1s - loss: 0.4440 - mse: 0.4195 - val_loss: 0.3826 - val_mse: 0.3826 - lr: 0.0010 - 693ms/epoch - 173ms/step\n",
            "Epoch 164/1000\n",
            "4/4 - 1s - loss: 0.4445 - mse: 0.4199 - val_loss: 0.3825 - val_mse: 0.3825 - lr: 0.0010 - 692ms/epoch - 173ms/step\n",
            "Epoch 165/1000\n",
            "4/4 - 1s - loss: 0.4445 - mse: 0.4199 - val_loss: 0.3824 - val_mse: 0.3824 - lr: 0.0010 - 688ms/epoch - 172ms/step\n",
            "Epoch 166/1000\n",
            "4/4 - 1s - loss: 0.4442 - mse: 0.4196 - val_loss: 0.3824 - val_mse: 0.3824 - lr: 0.0010 - 693ms/epoch - 173ms/step\n",
            "Epoch 167/1000\n",
            "4/4 - 1s - loss: 0.4439 - mse: 0.4193 - val_loss: 0.3823 - val_mse: 0.3823 - lr: 0.0010 - 696ms/epoch - 174ms/step\n",
            "Epoch 168/1000\n",
            "4/4 - 1s - loss: 0.4436 - mse: 0.4191 - val_loss: 0.3822 - val_mse: 0.3822 - lr: 0.0010 - 685ms/epoch - 171ms/step\n",
            "Epoch 169/1000\n",
            "4/4 - 1s - loss: 0.4429 - mse: 0.4184 - val_loss: 0.3822 - val_mse: 0.3822 - lr: 0.0010 - 717ms/epoch - 179ms/step\n",
            "Epoch 170/1000\n",
            "4/4 - 1s - loss: 0.4426 - mse: 0.4181 - val_loss: 0.3822 - val_mse: 0.3822 - lr: 0.0010 - 689ms/epoch - 172ms/step\n",
            "Epoch 171/1000\n",
            "4/4 - 1s - loss: 0.4428 - mse: 0.4183 - val_loss: 0.3822 - val_mse: 0.3822 - lr: 0.0010 - 685ms/epoch - 171ms/step\n",
            "Epoch 172/1000\n",
            "4/4 - 1s - loss: 0.4419 - mse: 0.4174 - val_loss: 0.3821 - val_mse: 0.3821 - lr: 0.0010 - 697ms/epoch - 174ms/step\n",
            "Epoch 173/1000\n",
            "4/4 - 1s - loss: 0.4421 - mse: 0.4176 - val_loss: 0.3820 - val_mse: 0.3820 - lr: 0.0010 - 711ms/epoch - 178ms/step\n",
            "Epoch 174/1000\n",
            "4/4 - 1s - loss: 0.4425 - mse: 0.4180 - val_loss: 0.3819 - val_mse: 0.3819 - lr: 0.0010 - 690ms/epoch - 173ms/step\n",
            "Epoch 175/1000\n",
            "4/4 - 1s - loss: 0.4416 - mse: 0.4171 - val_loss: 0.3817 - val_mse: 0.3817 - lr: 0.0010 - 689ms/epoch - 172ms/step\n",
            "Epoch 176/1000\n",
            "4/4 - 1s - loss: 0.4395 - mse: 0.4151 - val_loss: 0.3817 - val_mse: 0.3817 - lr: 0.0010 - 693ms/epoch - 173ms/step\n",
            "Epoch 177/1000\n",
            "4/4 - 1s - loss: 0.4400 - mse: 0.4157 - val_loss: 0.3817 - val_mse: 0.3817 - lr: 0.0010 - 691ms/epoch - 173ms/step\n",
            "Epoch 178/1000\n",
            "4/4 - 1s - loss: 0.4407 - mse: 0.4163 - val_loss: 0.3818 - val_mse: 0.3818 - lr: 0.0010 - 686ms/epoch - 172ms/step\n",
            "Epoch 179/1000\n",
            "4/4 - 1s - loss: 0.4396 - mse: 0.4154 - val_loss: 0.3818 - val_mse: 0.3818 - lr: 0.0010 - 697ms/epoch - 174ms/step\n",
            "Epoch 180/1000\n",
            "4/4 - 1s - loss: 0.4393 - mse: 0.4151 - val_loss: 0.3817 - val_mse: 0.3817 - lr: 0.0010 - 702ms/epoch - 176ms/step\n",
            "Epoch 181/1000\n",
            "4/4 - 1s - loss: 0.4395 - mse: 0.4153 - val_loss: 0.3817 - val_mse: 0.3817 - lr: 0.0010 - 676ms/epoch - 169ms/step\n",
            "Epoch 182/1000\n",
            "\n",
            "Epoch 182: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "4/4 - 1s - loss: 0.4390 - mse: 0.4147 - val_loss: 0.3817 - val_mse: 0.3817 - lr: 0.0010 - 696ms/epoch - 174ms/step\n",
            "Epoch 183/1000\n",
            "4/4 - 1s - loss: 0.4392 - mse: 0.4149 - val_loss: 0.3817 - val_mse: 0.3817 - lr: 1.0000e-04 - 727ms/epoch - 182ms/step\n",
            "Epoch 184/1000\n",
            "4/4 - 1s - loss: 0.4397 - mse: 0.4154 - val_loss: 0.3817 - val_mse: 0.3817 - lr: 1.0000e-04 - 689ms/epoch - 172ms/step\n",
            "Epoch 185/1000\n",
            "4/4 - 1s - loss: 0.4388 - mse: 0.4146 - val_loss: 0.3817 - val_mse: 0.3817 - lr: 1.0000e-04 - 694ms/epoch - 173ms/step\n",
            "Epoch 186/1000\n",
            "4/4 - 1s - loss: 0.4390 - mse: 0.4148 - val_loss: 0.3817 - val_mse: 0.3817 - lr: 1.0000e-04 - 881ms/epoch - 220ms/step\n",
            "Epoch 187/1000\n",
            "4/4 - 1s - loss: 0.4399 - mse: 0.4155 - val_loss: 0.3817 - val_mse: 0.3817 - lr: 1.0000e-04 - 959ms/epoch - 240ms/step\n",
            "Epoch 188/1000\n",
            "4/4 - 1s - loss: 0.4402 - mse: 0.4158 - val_loss: 0.3817 - val_mse: 0.3817 - lr: 1.0000e-04 - 698ms/epoch - 174ms/step\n",
            "Epoch 189/1000\n",
            "\n",
            "Epoch 189: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
            "4/4 - 1s - loss: 0.4391 - mse: 0.4148 - val_loss: 0.3817 - val_mse: 0.3817 - lr: 1.0000e-04 - 701ms/epoch - 175ms/step\n",
            "Epoch 190/1000\n",
            "4/4 - 1s - loss: 0.4389 - mse: 0.4147 - val_loss: 0.3817 - val_mse: 0.3817 - lr: 1.0000e-05 - 691ms/epoch - 173ms/step\n",
            "Epoch 191/1000\n",
            "4/4 - 1s - loss: 0.4389 - mse: 0.4146 - val_loss: 0.3817 - val_mse: 0.3817 - lr: 1.0000e-05 - 687ms/epoch - 172ms/step\n",
            "Epoch 192/1000\n",
            "4/4 - 1s - loss: 0.4387 - mse: 0.4145 - val_loss: 0.3817 - val_mse: 0.3817 - lr: 1.0000e-05 - 691ms/epoch - 173ms/step\n",
            "Epoch 193/1000\n",
            "4/4 - 1s - loss: 0.4393 - mse: 0.4150 - val_loss: 0.3817 - val_mse: 0.3817 - lr: 1.0000e-05 - 705ms/epoch - 176ms/step\n",
            "Epoch 194/1000\n",
            "4/4 - 1s - loss: 0.4386 - mse: 0.4143 - val_loss: 0.3817 - val_mse: 0.3817 - lr: 1.0000e-05 - 691ms/epoch - 173ms/step\n",
            "Epoch 195/1000\n",
            "4/4 - 1s - loss: 0.4392 - mse: 0.4149 - val_loss: 0.3817 - val_mse: 0.3817 - lr: 1.0000e-05 - 697ms/epoch - 174ms/step\n",
            "Epoch 196/1000\n",
            "\n",
            "Epoch 196: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
            "4/4 - 1s - loss: 0.4381 - mse: 0.4139 - val_loss: 0.3817 - val_mse: 0.3817 - lr: 1.0000e-05 - 713ms/epoch - 178ms/step\n",
            "Epoch 197/1000\n",
            "4/4 - 1s - loss: 0.4392 - mse: 0.4149 - val_loss: 0.3817 - val_mse: 0.3817 - lr: 1.0000e-06 - 720ms/epoch - 180ms/step\n",
            "Epoch 198/1000\n",
            "4/4 - 1s - loss: 0.4394 - mse: 0.4151 - val_loss: 0.3817 - val_mse: 0.3817 - lr: 1.0000e-06 - 695ms/epoch - 174ms/step\n",
            "Epoch 199/1000\n",
            "4/4 - 1s - loss: 0.4387 - mse: 0.4145 - val_loss: 0.3817 - val_mse: 0.3817 - lr: 1.0000e-06 - 704ms/epoch - 176ms/step\n",
            "Epoch 199: early stopping\n",
            "==================================================\n",
            "Step 9\n",
            "==================================================\n",
            "Epoch 1/1000\n",
            "4/4 - 4s - loss: 2.6381 - mse: 2.4783 - val_loss: 0.8062 - val_mse: 0.8062 - lr: 0.0010 - 4s/epoch - 978ms/step\n",
            "Epoch 2/1000\n",
            "4/4 - 1s - loss: 1.8266 - mse: 1.7254 - val_loss: 0.7966 - val_mse: 0.7966 - lr: 0.0010 - 704ms/epoch - 176ms/step\n",
            "Epoch 3/1000\n",
            "4/4 - 1s - loss: 1.4909 - mse: 1.4087 - val_loss: 0.8045 - val_mse: 0.8045 - lr: 0.0010 - 697ms/epoch - 174ms/step\n",
            "Epoch 4/1000\n",
            "4/4 - 1s - loss: 1.2992 - mse: 1.2288 - val_loss: 0.8070 - val_mse: 0.8070 - lr: 0.0010 - 706ms/epoch - 177ms/step\n",
            "Epoch 5/1000\n",
            "4/4 - 1s - loss: 1.1943 - mse: 1.1305 - val_loss: 0.8019 - val_mse: 0.8019 - lr: 0.0010 - 710ms/epoch - 177ms/step\n",
            "Epoch 6/1000\n",
            "4/4 - 1s - loss: 1.1239 - mse: 1.0636 - val_loss: 0.7974 - val_mse: 0.7974 - lr: 0.0010 - 718ms/epoch - 179ms/step\n",
            "Epoch 7/1000\n",
            "4/4 - 1s - loss: 1.0642 - mse: 1.0070 - val_loss: 0.7978 - val_mse: 0.7978 - lr: 0.0010 - 712ms/epoch - 178ms/step\n",
            "Epoch 8/1000\n",
            "4/4 - 1s - loss: 1.0265 - mse: 0.9708 - val_loss: 0.7995 - val_mse: 0.7995 - lr: 0.0010 - 712ms/epoch - 178ms/step\n",
            "Epoch 9/1000\n",
            "\n",
            "Epoch 9: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "4/4 - 1s - loss: 0.9910 - mse: 0.9370 - val_loss: 0.8003 - val_mse: 0.8003 - lr: 0.0010 - 720ms/epoch - 180ms/step\n",
            "Epoch 10/1000\n",
            "4/4 - 1s - loss: 0.9659 - mse: 0.9139 - val_loss: 0.8010 - val_mse: 0.8010 - lr: 1.0000e-04 - 699ms/epoch - 175ms/step\n",
            "Epoch 11/1000\n",
            "4/4 - 1s - loss: 0.9657 - mse: 0.9138 - val_loss: 0.8017 - val_mse: 0.8017 - lr: 1.0000e-04 - 696ms/epoch - 174ms/step\n",
            "Epoch 12/1000\n",
            "4/4 - 1s - loss: 0.9638 - mse: 0.9122 - val_loss: 0.8026 - val_mse: 0.8026 - lr: 1.0000e-04 - 715ms/epoch - 179ms/step\n",
            "Epoch 12: early stopping\n",
            "==================================================\n",
            "Step 10\n",
            "==================================================\n",
            "Epoch 1/1000\n",
            "4/4 - 4s - loss: 4.2024 - mse: 3.9421 - val_loss: 1.0307 - val_mse: 1.0307 - lr: 0.0010 - 4s/epoch - 981ms/step\n",
            "Epoch 2/1000\n",
            "4/4 - 1s - loss: 2.1913 - mse: 2.0605 - val_loss: 0.9145 - val_mse: 0.9145 - lr: 0.0010 - 734ms/epoch - 183ms/step\n",
            "Epoch 3/1000\n",
            "4/4 - 1s - loss: 1.6407 - mse: 1.5376 - val_loss: 0.8416 - val_mse: 0.8416 - lr: 0.0010 - 718ms/epoch - 179ms/step\n",
            "Epoch 4/1000\n",
            "4/4 - 1s - loss: 1.4899 - mse: 1.3929 - val_loss: 0.8061 - val_mse: 0.8061 - lr: 0.0010 - 707ms/epoch - 177ms/step\n",
            "Epoch 5/1000\n",
            "4/4 - 1s - loss: 1.3835 - mse: 1.2938 - val_loss: 0.7946 - val_mse: 0.7946 - lr: 0.0010 - 719ms/epoch - 180ms/step\n",
            "Epoch 6/1000\n",
            "4/4 - 1s - loss: 1.2756 - mse: 1.1938 - val_loss: 0.7933 - val_mse: 0.7933 - lr: 0.0010 - 727ms/epoch - 182ms/step\n",
            "Epoch 7/1000\n",
            "4/4 - 1s - loss: 1.2100 - mse: 1.1325 - val_loss: 0.7935 - val_mse: 0.7935 - lr: 0.0010 - 713ms/epoch - 178ms/step\n",
            "Epoch 8/1000\n",
            "4/4 - 1s - loss: 1.1682 - mse: 1.0927 - val_loss: 0.7909 - val_mse: 0.7909 - lr: 0.0010 - 699ms/epoch - 175ms/step\n",
            "Epoch 9/1000\n",
            "4/4 - 1s - loss: 1.1254 - mse: 1.0537 - val_loss: 0.7846 - val_mse: 0.7846 - lr: 0.0010 - 704ms/epoch - 176ms/step\n",
            "Epoch 10/1000\n",
            "4/4 - 1s - loss: 1.1105 - mse: 1.0404 - val_loss: 0.7763 - val_mse: 0.7763 - lr: 0.0010 - 697ms/epoch - 174ms/step\n",
            "Epoch 11/1000\n",
            "4/4 - 1s - loss: 1.0788 - mse: 1.0113 - val_loss: 0.7682 - val_mse: 0.7682 - lr: 0.0010 - 689ms/epoch - 172ms/step\n",
            "Epoch 12/1000\n",
            "4/4 - 1s - loss: 1.0579 - mse: 0.9912 - val_loss: 0.7612 - val_mse: 0.7612 - lr: 0.0010 - 693ms/epoch - 173ms/step\n",
            "Epoch 13/1000\n",
            "4/4 - 1s - loss: 1.0410 - mse: 0.9757 - val_loss: 0.7550 - val_mse: 0.7550 - lr: 0.0010 - 718ms/epoch - 179ms/step\n",
            "Epoch 14/1000\n",
            "4/4 - 1s - loss: 1.0150 - mse: 0.9525 - val_loss: 0.7506 - val_mse: 0.7506 - lr: 0.0010 - 730ms/epoch - 182ms/step\n",
            "Epoch 15/1000\n",
            "4/4 - 1s - loss: 1.0051 - mse: 0.9430 - val_loss: 0.7479 - val_mse: 0.7479 - lr: 0.0010 - 714ms/epoch - 179ms/step\n",
            "Epoch 16/1000\n",
            "4/4 - 1s - loss: 0.9901 - mse: 0.9296 - val_loss: 0.7458 - val_mse: 0.7458 - lr: 0.0010 - 721ms/epoch - 180ms/step\n",
            "Epoch 17/1000\n",
            "4/4 - 1s - loss: 0.9833 - mse: 0.9232 - val_loss: 0.7434 - val_mse: 0.7434 - lr: 0.0010 - 697ms/epoch - 174ms/step\n",
            "Epoch 18/1000\n",
            "4/4 - 1s - loss: 0.9623 - mse: 0.9034 - val_loss: 0.7401 - val_mse: 0.7401 - lr: 0.0010 - 701ms/epoch - 175ms/step\n",
            "Epoch 19/1000\n",
            "4/4 - 1s - loss: 0.9579 - mse: 0.8987 - val_loss: 0.7361 - val_mse: 0.7361 - lr: 0.0010 - 719ms/epoch - 180ms/step\n",
            "Epoch 20/1000\n",
            "4/4 - 1s - loss: 0.9459 - mse: 0.8887 - val_loss: 0.7316 - val_mse: 0.7316 - lr: 0.0010 - 716ms/epoch - 179ms/step\n",
            "Epoch 21/1000\n",
            "4/4 - 1s - loss: 0.9342 - mse: 0.8771 - val_loss: 0.7262 - val_mse: 0.7262 - lr: 0.0010 - 713ms/epoch - 178ms/step\n",
            "Epoch 22/1000\n",
            "4/4 - 1s - loss: 0.9201 - mse: 0.8653 - val_loss: 0.7210 - val_mse: 0.7210 - lr: 0.0010 - 694ms/epoch - 173ms/step\n",
            "Epoch 23/1000\n",
            "4/4 - 1s - loss: 0.9045 - mse: 0.8507 - val_loss: 0.7172 - val_mse: 0.7172 - lr: 0.0010 - 692ms/epoch - 173ms/step\n",
            "Epoch 24/1000\n",
            "4/4 - 1s - loss: 0.8997 - mse: 0.8452 - val_loss: 0.7147 - val_mse: 0.7147 - lr: 0.0010 - 702ms/epoch - 175ms/step\n",
            "Epoch 25/1000\n",
            "4/4 - 1s - loss: 0.8901 - mse: 0.8371 - val_loss: 0.7125 - val_mse: 0.7125 - lr: 0.0010 - 696ms/epoch - 174ms/step\n",
            "Epoch 26/1000\n",
            "4/4 - 1s - loss: 0.8864 - mse: 0.8335 - val_loss: 0.7099 - val_mse: 0.7099 - lr: 0.0010 - 689ms/epoch - 172ms/step\n",
            "Epoch 27/1000\n",
            "4/4 - 1s - loss: 0.8688 - mse: 0.8170 - val_loss: 0.7066 - val_mse: 0.7066 - lr: 0.0010 - 710ms/epoch - 178ms/step\n",
            "Epoch 28/1000\n",
            "4/4 - 1s - loss: 0.8656 - mse: 0.8145 - val_loss: 0.7029 - val_mse: 0.7029 - lr: 0.0010 - 710ms/epoch - 178ms/step\n",
            "Epoch 29/1000\n",
            "4/4 - 1s - loss: 0.8535 - mse: 0.8028 - val_loss: 0.6982 - val_mse: 0.6982 - lr: 0.0010 - 688ms/epoch - 172ms/step\n",
            "Epoch 30/1000\n",
            "4/4 - 1s - loss: 0.8492 - mse: 0.7993 - val_loss: 0.6942 - val_mse: 0.6942 - lr: 0.0010 - 693ms/epoch - 173ms/step\n",
            "Epoch 31/1000\n",
            "4/4 - 1s - loss: 0.8385 - mse: 0.7891 - val_loss: 0.6906 - val_mse: 0.6906 - lr: 0.0010 - 699ms/epoch - 175ms/step\n",
            "Epoch 32/1000\n",
            "4/4 - 1s - loss: 0.8266 - mse: 0.7785 - val_loss: 0.6875 - val_mse: 0.6875 - lr: 0.0010 - 695ms/epoch - 174ms/step\n",
            "Epoch 33/1000\n",
            "4/4 - 1s - loss: 0.8239 - mse: 0.7754 - val_loss: 0.6844 - val_mse: 0.6844 - lr: 0.0010 - 694ms/epoch - 173ms/step\n",
            "Epoch 34/1000\n",
            "4/4 - 1s - loss: 0.8166 - mse: 0.7689 - val_loss: 0.6799 - val_mse: 0.6799 - lr: 0.0010 - 688ms/epoch - 172ms/step\n",
            "Epoch 35/1000\n",
            "4/4 - 1s - loss: 0.8057 - mse: 0.7587 - val_loss: 0.6758 - val_mse: 0.6758 - lr: 0.0010 - 689ms/epoch - 172ms/step\n",
            "Epoch 36/1000\n",
            "4/4 - 1s - loss: 0.7960 - mse: 0.7494 - val_loss: 0.6708 - val_mse: 0.6708 - lr: 0.0010 - 694ms/epoch - 174ms/step\n",
            "Epoch 37/1000\n",
            "4/4 - 1s - loss: 0.7873 - mse: 0.7419 - val_loss: 0.6663 - val_mse: 0.6663 - lr: 0.0010 - 686ms/epoch - 171ms/step\n",
            "Epoch 38/1000\n",
            "4/4 - 1s - loss: 0.7855 - mse: 0.7398 - val_loss: 0.6615 - val_mse: 0.6615 - lr: 0.0010 - 702ms/epoch - 175ms/step\n",
            "Epoch 39/1000\n",
            "4/4 - 1s - loss: 0.7781 - mse: 0.7324 - val_loss: 0.6564 - val_mse: 0.6564 - lr: 0.0010 - 696ms/epoch - 174ms/step\n",
            "Epoch 40/1000\n",
            "4/4 - 1s - loss: 0.7676 - mse: 0.7228 - val_loss: 0.6518 - val_mse: 0.6518 - lr: 0.0010 - 689ms/epoch - 172ms/step\n",
            "Epoch 41/1000\n",
            "4/4 - 1s - loss: 0.7631 - mse: 0.7192 - val_loss: 0.6477 - val_mse: 0.6477 - lr: 0.0010 - 710ms/epoch - 178ms/step\n",
            "Epoch 42/1000\n",
            "4/4 - 1s - loss: 0.7583 - mse: 0.7145 - val_loss: 0.6439 - val_mse: 0.6439 - lr: 0.0010 - 695ms/epoch - 174ms/step\n",
            "Epoch 43/1000\n",
            "4/4 - 1s - loss: 0.7507 - mse: 0.7073 - val_loss: 0.6403 - val_mse: 0.6403 - lr: 0.0010 - 702ms/epoch - 175ms/step\n",
            "Epoch 44/1000\n",
            "4/4 - 1s - loss: 0.7421 - mse: 0.6995 - val_loss: 0.6352 - val_mse: 0.6352 - lr: 0.0010 - 710ms/epoch - 178ms/step\n",
            "Epoch 45/1000\n",
            "4/4 - 1s - loss: 0.7369 - mse: 0.6944 - val_loss: 0.6298 - val_mse: 0.6298 - lr: 0.0010 - 693ms/epoch - 173ms/step\n",
            "Epoch 46/1000\n",
            "4/4 - 1s - loss: 0.7324 - mse: 0.6902 - val_loss: 0.6248 - val_mse: 0.6248 - lr: 0.0010 - 687ms/epoch - 172ms/step\n",
            "Epoch 47/1000\n",
            "4/4 - 1s - loss: 0.7293 - mse: 0.6877 - val_loss: 0.6197 - val_mse: 0.6197 - lr: 0.0010 - 703ms/epoch - 176ms/step\n",
            "Epoch 48/1000\n",
            "4/4 - 1s - loss: 0.7214 - mse: 0.6801 - val_loss: 0.6149 - val_mse: 0.6149 - lr: 0.0010 - 699ms/epoch - 175ms/step\n",
            "Epoch 49/1000\n",
            "4/4 - 1s - loss: 0.7168 - mse: 0.6759 - val_loss: 0.6104 - val_mse: 0.6104 - lr: 0.0010 - 700ms/epoch - 175ms/step\n",
            "Epoch 50/1000\n",
            "4/4 - 1s - loss: 0.7100 - mse: 0.6699 - val_loss: 0.6062 - val_mse: 0.6062 - lr: 0.0010 - 699ms/epoch - 175ms/step\n",
            "Epoch 51/1000\n",
            "4/4 - 1s - loss: 0.7039 - mse: 0.6640 - val_loss: 0.6023 - val_mse: 0.6023 - lr: 0.0010 - 682ms/epoch - 170ms/step\n",
            "Epoch 52/1000\n",
            "4/4 - 1s - loss: 0.7006 - mse: 0.6608 - val_loss: 0.5977 - val_mse: 0.5977 - lr: 0.0010 - 701ms/epoch - 175ms/step\n",
            "Epoch 53/1000\n",
            "4/4 - 1s - loss: 0.6959 - mse: 0.6565 - val_loss: 0.5920 - val_mse: 0.5920 - lr: 0.0010 - 709ms/epoch - 177ms/step\n",
            "Epoch 54/1000\n",
            "4/4 - 1s - loss: 0.6916 - mse: 0.6525 - val_loss: 0.5859 - val_mse: 0.5859 - lr: 0.0010 - 706ms/epoch - 176ms/step\n",
            "Epoch 55/1000\n",
            "4/4 - 1s - loss: 0.6828 - mse: 0.6440 - val_loss: 0.5802 - val_mse: 0.5802 - lr: 0.0010 - 1s/epoch - 256ms/step\n",
            "Epoch 56/1000\n",
            "4/4 - 1s - loss: 0.6816 - mse: 0.6431 - val_loss: 0.5753 - val_mse: 0.5753 - lr: 0.0010 - 847ms/epoch - 212ms/step\n",
            "Epoch 57/1000\n",
            "4/4 - 1s - loss: 0.6793 - mse: 0.6409 - val_loss: 0.5708 - val_mse: 0.5708 - lr: 0.0010 - 816ms/epoch - 204ms/step\n",
            "Epoch 58/1000\n",
            "4/4 - 1s - loss: 0.6699 - mse: 0.6322 - val_loss: 0.5660 - val_mse: 0.5660 - lr: 0.0010 - 755ms/epoch - 189ms/step\n",
            "Epoch 59/1000\n",
            "4/4 - 1s - loss: 0.6675 - mse: 0.6301 - val_loss: 0.5609 - val_mse: 0.5609 - lr: 0.0010 - 766ms/epoch - 192ms/step\n",
            "Epoch 60/1000\n",
            "4/4 - 1s - loss: 0.6647 - mse: 0.6274 - val_loss: 0.5559 - val_mse: 0.5559 - lr: 0.0010 - 752ms/epoch - 188ms/step\n",
            "Epoch 61/1000\n",
            "4/4 - 1s - loss: 0.6588 - mse: 0.6217 - val_loss: 0.5516 - val_mse: 0.5516 - lr: 0.0010 - 749ms/epoch - 187ms/step\n",
            "Epoch 62/1000\n",
            "4/4 - 1s - loss: 0.6510 - mse: 0.6146 - val_loss: 0.5471 - val_mse: 0.5471 - lr: 0.0010 - 762ms/epoch - 190ms/step\n",
            "Epoch 63/1000\n",
            "4/4 - 1s - loss: 0.6483 - mse: 0.6121 - val_loss: 0.5420 - val_mse: 0.5420 - lr: 0.0010 - 753ms/epoch - 188ms/step\n",
            "Epoch 64/1000\n",
            "4/4 - 1s - loss: 0.6436 - mse: 0.6075 - val_loss: 0.5368 - val_mse: 0.5368 - lr: 0.0010 - 758ms/epoch - 189ms/step\n",
            "Epoch 65/1000\n",
            "4/4 - 1s - loss: 0.6413 - mse: 0.6051 - val_loss: 0.5318 - val_mse: 0.5318 - lr: 0.0010 - 746ms/epoch - 187ms/step\n",
            "Epoch 66/1000\n",
            "4/4 - 1s - loss: 0.6384 - mse: 0.6027 - val_loss: 0.5282 - val_mse: 0.5282 - lr: 0.0010 - 735ms/epoch - 184ms/step\n",
            "Epoch 67/1000\n",
            "4/4 - 1s - loss: 0.6345 - mse: 0.5989 - val_loss: 0.5243 - val_mse: 0.5243 - lr: 0.0010 - 1s/epoch - 254ms/step\n",
            "Epoch 68/1000\n",
            "4/4 - 2s - loss: 0.6325 - mse: 0.5971 - val_loss: 0.5205 - val_mse: 0.5205 - lr: 0.0010 - 2s/epoch - 406ms/step\n",
            "Epoch 69/1000\n",
            "4/4 - 1s - loss: 0.6254 - mse: 0.5908 - val_loss: 0.5165 - val_mse: 0.5165 - lr: 0.0010 - 1s/epoch - 335ms/step\n",
            "Epoch 70/1000\n",
            "4/4 - 1s - loss: 0.6237 - mse: 0.5892 - val_loss: 0.5125 - val_mse: 0.5125 - lr: 0.0010 - 1s/epoch - 358ms/step\n",
            "Epoch 71/1000\n",
            "4/4 - 2s - loss: 0.6200 - mse: 0.5851 - val_loss: 0.5085 - val_mse: 0.5085 - lr: 0.0010 - 2s/epoch - 385ms/step\n",
            "Epoch 72/1000\n",
            "4/4 - 1s - loss: 0.6149 - mse: 0.5804 - val_loss: 0.5044 - val_mse: 0.5044 - lr: 0.0010 - 853ms/epoch - 213ms/step\n",
            "Epoch 73/1000\n",
            "4/4 - 1s - loss: 0.6114 - mse: 0.5773 - val_loss: 0.4997 - val_mse: 0.4997 - lr: 0.0010 - 842ms/epoch - 210ms/step\n",
            "Epoch 74/1000\n",
            "4/4 - 1s - loss: 0.6073 - mse: 0.5736 - val_loss: 0.4954 - val_mse: 0.4954 - lr: 0.0010 - 826ms/epoch - 207ms/step\n",
            "Epoch 75/1000\n",
            "4/4 - 1s - loss: 0.6061 - mse: 0.5723 - val_loss: 0.4918 - val_mse: 0.4918 - lr: 0.0010 - 784ms/epoch - 196ms/step\n",
            "Epoch 76/1000\n",
            "4/4 - 1s - loss: 0.6016 - mse: 0.5681 - val_loss: 0.4887 - val_mse: 0.4887 - lr: 0.0010 - 693ms/epoch - 173ms/step\n",
            "Epoch 77/1000\n",
            "4/4 - 1s - loss: 0.5956 - mse: 0.5627 - val_loss: 0.4859 - val_mse: 0.4859 - lr: 0.0010 - 694ms/epoch - 173ms/step\n",
            "Epoch 78/1000\n",
            "4/4 - 1s - loss: 0.5974 - mse: 0.5640 - val_loss: 0.4823 - val_mse: 0.4823 - lr: 0.0010 - 684ms/epoch - 171ms/step\n",
            "Epoch 79/1000\n",
            "4/4 - 1s - loss: 0.5950 - mse: 0.5618 - val_loss: 0.4777 - val_mse: 0.4777 - lr: 0.0010 - 723ms/epoch - 181ms/step\n",
            "Epoch 80/1000\n",
            "4/4 - 1s - loss: 0.5907 - mse: 0.5579 - val_loss: 0.4735 - val_mse: 0.4735 - lr: 0.0010 - 704ms/epoch - 176ms/step\n",
            "Epoch 81/1000\n",
            "4/4 - 1s - loss: 0.5847 - mse: 0.5524 - val_loss: 0.4695 - val_mse: 0.4695 - lr: 0.0010 - 692ms/epoch - 173ms/step\n",
            "Epoch 82/1000\n",
            "4/4 - 1s - loss: 0.5824 - mse: 0.5503 - val_loss: 0.4666 - val_mse: 0.4666 - lr: 0.0010 - 688ms/epoch - 172ms/step\n",
            "Epoch 83/1000\n",
            "4/4 - 1s - loss: 0.5806 - mse: 0.5485 - val_loss: 0.4636 - val_mse: 0.4636 - lr: 0.0010 - 692ms/epoch - 173ms/step\n",
            "Epoch 84/1000\n",
            "4/4 - 1s - loss: 0.5780 - mse: 0.5463 - val_loss: 0.4608 - val_mse: 0.4608 - lr: 0.0010 - 696ms/epoch - 174ms/step\n",
            "Epoch 85/1000\n",
            "4/4 - 1s - loss: 0.5758 - mse: 0.5438 - val_loss: 0.4578 - val_mse: 0.4578 - lr: 0.0010 - 689ms/epoch - 172ms/step\n",
            "Epoch 86/1000\n",
            "4/4 - 1s - loss: 0.5728 - mse: 0.5413 - val_loss: 0.4547 - val_mse: 0.4547 - lr: 0.0010 - 679ms/epoch - 170ms/step\n",
            "Epoch 87/1000\n",
            "4/4 - 1s - loss: 0.5674 - mse: 0.5362 - val_loss: 0.4524 - val_mse: 0.4524 - lr: 0.0010 - 675ms/epoch - 169ms/step\n",
            "Epoch 88/1000\n",
            "4/4 - 1s - loss: 0.5668 - mse: 0.5356 - val_loss: 0.4504 - val_mse: 0.4504 - lr: 0.0010 - 691ms/epoch - 173ms/step\n",
            "Epoch 89/1000\n",
            "4/4 - 1s - loss: 0.5685 - mse: 0.5372 - val_loss: 0.4483 - val_mse: 0.4483 - lr: 0.0010 - 685ms/epoch - 171ms/step\n",
            "Epoch 90/1000\n",
            "4/4 - 1s - loss: 0.5636 - mse: 0.5324 - val_loss: 0.4459 - val_mse: 0.4459 - lr: 0.0010 - 667ms/epoch - 167ms/step\n",
            "Epoch 91/1000\n",
            "4/4 - 1s - loss: 0.5598 - mse: 0.5289 - val_loss: 0.4432 - val_mse: 0.4432 - lr: 0.0010 - 676ms/epoch - 169ms/step\n",
            "Epoch 92/1000\n",
            "4/4 - 1s - loss: 0.5571 - mse: 0.5264 - val_loss: 0.4404 - val_mse: 0.4404 - lr: 0.0010 - 701ms/epoch - 175ms/step\n",
            "Epoch 93/1000\n",
            "4/4 - 1s - loss: 0.5559 - mse: 0.5250 - val_loss: 0.4382 - val_mse: 0.4382 - lr: 0.0010 - 695ms/epoch - 174ms/step\n",
            "Epoch 94/1000\n",
            "4/4 - 1s - loss: 0.5540 - mse: 0.5234 - val_loss: 0.4358 - val_mse: 0.4358 - lr: 0.0010 - 717ms/epoch - 179ms/step\n",
            "Epoch 95/1000\n",
            "4/4 - 1s - loss: 0.5510 - mse: 0.5207 - val_loss: 0.4334 - val_mse: 0.4334 - lr: 0.0010 - 705ms/epoch - 176ms/step\n",
            "Epoch 96/1000\n",
            "4/4 - 1s - loss: 0.5472 - mse: 0.5170 - val_loss: 0.4311 - val_mse: 0.4311 - lr: 0.0010 - 674ms/epoch - 168ms/step\n",
            "Epoch 97/1000\n",
            "4/4 - 1s - loss: 0.5475 - mse: 0.5173 - val_loss: 0.4284 - val_mse: 0.4284 - lr: 0.0010 - 688ms/epoch - 172ms/step\n",
            "Epoch 98/1000\n",
            "4/4 - 1s - loss: 0.5436 - mse: 0.5137 - val_loss: 0.4262 - val_mse: 0.4262 - lr: 0.0010 - 700ms/epoch - 175ms/step\n",
            "Epoch 99/1000\n",
            "4/4 - 1s - loss: 0.5405 - mse: 0.5108 - val_loss: 0.4242 - val_mse: 0.4242 - lr: 0.0010 - 685ms/epoch - 171ms/step\n",
            "Epoch 100/1000\n",
            "4/4 - 1s - loss: 0.5384 - mse: 0.5088 - val_loss: 0.4228 - val_mse: 0.4228 - lr: 0.0010 - 684ms/epoch - 171ms/step\n",
            "Epoch 101/1000\n",
            "4/4 - 1s - loss: 0.5370 - mse: 0.5074 - val_loss: 0.4212 - val_mse: 0.4212 - lr: 0.0010 - 691ms/epoch - 173ms/step\n",
            "Epoch 102/1000\n",
            "4/4 - 1s - loss: 0.5354 - mse: 0.5061 - val_loss: 0.4200 - val_mse: 0.4200 - lr: 0.0010 - 689ms/epoch - 172ms/step\n",
            "Epoch 103/1000\n",
            "4/4 - 1s - loss: 0.5327 - mse: 0.5035 - val_loss: 0.4185 - val_mse: 0.4185 - lr: 0.0010 - 677ms/epoch - 169ms/step\n",
            "Epoch 104/1000\n",
            "4/4 - 1s - loss: 0.5325 - mse: 0.5032 - val_loss: 0.4169 - val_mse: 0.4169 - lr: 0.0010 - 685ms/epoch - 171ms/step\n",
            "Epoch 105/1000\n",
            "4/4 - 1s - loss: 0.5279 - mse: 0.4987 - val_loss: 0.4156 - val_mse: 0.4156 - lr: 0.0010 - 675ms/epoch - 169ms/step\n",
            "Epoch 106/1000\n",
            "4/4 - 1s - loss: 0.5279 - mse: 0.4988 - val_loss: 0.4144 - val_mse: 0.4144 - lr: 0.0010 - 688ms/epoch - 172ms/step\n",
            "Epoch 107/1000\n",
            "4/4 - 1s - loss: 0.5264 - mse: 0.4974 - val_loss: 0.4130 - val_mse: 0.4130 - lr: 0.0010 - 682ms/epoch - 170ms/step\n",
            "Epoch 108/1000\n",
            "4/4 - 1s - loss: 0.5255 - mse: 0.4967 - val_loss: 0.4112 - val_mse: 0.4112 - lr: 0.0010 - 676ms/epoch - 169ms/step\n",
            "Epoch 109/1000\n",
            "4/4 - 1s - loss: 0.5219 - mse: 0.4933 - val_loss: 0.4096 - val_mse: 0.4096 - lr: 0.0010 - 693ms/epoch - 173ms/step\n",
            "Epoch 110/1000\n",
            "4/4 - 1s - loss: 0.5217 - mse: 0.4931 - val_loss: 0.4083 - val_mse: 0.4083 - lr: 0.0010 - 681ms/epoch - 170ms/step\n",
            "Epoch 111/1000\n",
            "4/4 - 1s - loss: 0.5200 - mse: 0.4915 - val_loss: 0.4073 - val_mse: 0.4073 - lr: 0.0010 - 670ms/epoch - 167ms/step\n",
            "Epoch 112/1000\n",
            "4/4 - 1s - loss: 0.5173 - mse: 0.4889 - val_loss: 0.4065 - val_mse: 0.4065 - lr: 0.0010 - 677ms/epoch - 169ms/step\n",
            "Epoch 113/1000\n",
            "4/4 - 1s - loss: 0.5150 - mse: 0.4867 - val_loss: 0.4056 - val_mse: 0.4056 - lr: 0.0010 - 674ms/epoch - 169ms/step\n",
            "Epoch 114/1000\n",
            "4/4 - 1s - loss: 0.5134 - mse: 0.4854 - val_loss: 0.4045 - val_mse: 0.4045 - lr: 0.0010 - 684ms/epoch - 171ms/step\n",
            "Epoch 115/1000\n",
            "4/4 - 1s - loss: 0.5144 - mse: 0.4863 - val_loss: 0.4032 - val_mse: 0.4032 - lr: 0.0010 - 683ms/epoch - 171ms/step\n",
            "Epoch 116/1000\n",
            "4/4 - 1s - loss: 0.5108 - mse: 0.4827 - val_loss: 0.4022 - val_mse: 0.4022 - lr: 0.0010 - 699ms/epoch - 175ms/step\n",
            "Epoch 117/1000\n",
            "4/4 - 1s - loss: 0.5102 - mse: 0.4823 - val_loss: 0.4014 - val_mse: 0.4014 - lr: 0.0010 - 691ms/epoch - 173ms/step\n",
            "Epoch 118/1000\n",
            "4/4 - 1s - loss: 0.5082 - mse: 0.4803 - val_loss: 0.4009 - val_mse: 0.4009 - lr: 0.0010 - 672ms/epoch - 168ms/step\n",
            "Epoch 119/1000\n",
            "4/4 - 1s - loss: 0.5082 - mse: 0.4802 - val_loss: 0.4002 - val_mse: 0.4002 - lr: 0.0010 - 700ms/epoch - 175ms/step\n",
            "Epoch 120/1000\n",
            "4/4 - 1s - loss: 0.5074 - mse: 0.4794 - val_loss: 0.3994 - val_mse: 0.3994 - lr: 0.0010 - 688ms/epoch - 172ms/step\n",
            "Epoch 121/1000\n",
            "4/4 - 1s - loss: 0.5056 - mse: 0.4778 - val_loss: 0.3987 - val_mse: 0.3987 - lr: 0.0010 - 693ms/epoch - 173ms/step\n",
            "Epoch 122/1000\n",
            "4/4 - 1s - loss: 0.5033 - mse: 0.4756 - val_loss: 0.3978 - val_mse: 0.3978 - lr: 0.0010 - 692ms/epoch - 173ms/step\n",
            "Epoch 123/1000\n",
            "4/4 - 1s - loss: 0.5006 - mse: 0.4731 - val_loss: 0.3970 - val_mse: 0.3970 - lr: 0.0010 - 710ms/epoch - 177ms/step\n",
            "Epoch 124/1000\n",
            "4/4 - 1s - loss: 0.4999 - mse: 0.4725 - val_loss: 0.3965 - val_mse: 0.3965 - lr: 0.0010 - 708ms/epoch - 177ms/step\n",
            "Epoch 125/1000\n",
            "4/4 - 1s - loss: 0.4996 - mse: 0.4721 - val_loss: 0.3961 - val_mse: 0.3961 - lr: 0.0010 - 684ms/epoch - 171ms/step\n",
            "Epoch 126/1000\n",
            "4/4 - 1s - loss: 0.4972 - mse: 0.4699 - val_loss: 0.3957 - val_mse: 0.3957 - lr: 0.0010 - 688ms/epoch - 172ms/step\n",
            "Epoch 127/1000\n",
            "4/4 - 1s - loss: 0.4959 - mse: 0.4688 - val_loss: 0.3954 - val_mse: 0.3954 - lr: 0.0010 - 699ms/epoch - 175ms/step\n",
            "Epoch 128/1000\n",
            "4/4 - 1s - loss: 0.4941 - mse: 0.4670 - val_loss: 0.3949 - val_mse: 0.3949 - lr: 0.0010 - 696ms/epoch - 174ms/step\n",
            "Epoch 129/1000\n",
            "4/4 - 1s - loss: 0.4947 - mse: 0.4675 - val_loss: 0.3945 - val_mse: 0.3945 - lr: 0.0010 - 684ms/epoch - 171ms/step\n",
            "Epoch 130/1000\n",
            "4/4 - 1s - loss: 0.4927 - mse: 0.4655 - val_loss: 0.3940 - val_mse: 0.3940 - lr: 0.0010 - 681ms/epoch - 170ms/step\n",
            "Epoch 131/1000\n",
            "4/4 - 1s - loss: 0.4915 - mse: 0.4647 - val_loss: 0.3936 - val_mse: 0.3936 - lr: 0.0010 - 699ms/epoch - 175ms/step\n",
            "Epoch 132/1000\n",
            "4/4 - 1s - loss: 0.4912 - mse: 0.4642 - val_loss: 0.3933 - val_mse: 0.3933 - lr: 0.0010 - 679ms/epoch - 170ms/step\n",
            "Epoch 133/1000\n",
            "4/4 - 1s - loss: 0.4902 - mse: 0.4633 - val_loss: 0.3930 - val_mse: 0.3930 - lr: 0.0010 - 685ms/epoch - 171ms/step\n",
            "Epoch 134/1000\n",
            "4/4 - 1s - loss: 0.4882 - mse: 0.4616 - val_loss: 0.3928 - val_mse: 0.3928 - lr: 0.0010 - 685ms/epoch - 171ms/step\n",
            "Epoch 135/1000\n",
            "4/4 - 1s - loss: 0.4878 - mse: 0.4610 - val_loss: 0.3926 - val_mse: 0.3926 - lr: 0.0010 - 689ms/epoch - 172ms/step\n",
            "Epoch 136/1000\n",
            "4/4 - 1s - loss: 0.4854 - mse: 0.4589 - val_loss: 0.3924 - val_mse: 0.3924 - lr: 0.0010 - 704ms/epoch - 176ms/step\n",
            "Epoch 137/1000\n",
            "4/4 - 1s - loss: 0.4866 - mse: 0.4600 - val_loss: 0.3921 - val_mse: 0.3921 - lr: 0.0010 - 682ms/epoch - 171ms/step\n",
            "Epoch 138/1000\n",
            "4/4 - 1s - loss: 0.4850 - mse: 0.4585 - val_loss: 0.3919 - val_mse: 0.3919 - lr: 0.0010 - 695ms/epoch - 174ms/step\n",
            "Epoch 139/1000\n",
            "4/4 - 1s - loss: 0.4821 - mse: 0.4557 - val_loss: 0.3917 - val_mse: 0.3917 - lr: 0.0010 - 666ms/epoch - 167ms/step\n",
            "Epoch 140/1000\n",
            "4/4 - 1s - loss: 0.4819 - mse: 0.4557 - val_loss: 0.3915 - val_mse: 0.3915 - lr: 0.0010 - 689ms/epoch - 172ms/step\n",
            "Epoch 141/1000\n",
            "4/4 - 1s - loss: 0.4818 - mse: 0.4553 - val_loss: 0.3913 - val_mse: 0.3913 - lr: 0.0010 - 667ms/epoch - 167ms/step\n",
            "Epoch 142/1000\n",
            "4/4 - 1s - loss: 0.4801 - mse: 0.4538 - val_loss: 0.3911 - val_mse: 0.3911 - lr: 0.0010 - 677ms/epoch - 169ms/step\n",
            "Epoch 143/1000\n",
            "4/4 - 1s - loss: 0.4806 - mse: 0.4543 - val_loss: 0.3909 - val_mse: 0.3909 - lr: 0.0010 - 686ms/epoch - 171ms/step\n",
            "Epoch 144/1000\n",
            "4/4 - 1s - loss: 0.4791 - mse: 0.4529 - val_loss: 0.3908 - val_mse: 0.3908 - lr: 0.0010 - 689ms/epoch - 172ms/step\n",
            "Epoch 145/1000\n",
            "4/4 - 1s - loss: 0.4772 - mse: 0.4509 - val_loss: 0.3906 - val_mse: 0.3906 - lr: 0.0010 - 677ms/epoch - 169ms/step\n",
            "Epoch 146/1000\n",
            "4/4 - 1s - loss: 0.4781 - mse: 0.4519 - val_loss: 0.3905 - val_mse: 0.3905 - lr: 0.0010 - 696ms/epoch - 174ms/step\n",
            "Epoch 147/1000\n",
            "4/4 - 1s - loss: 0.4762 - mse: 0.4501 - val_loss: 0.3904 - val_mse: 0.3904 - lr: 0.0010 - 683ms/epoch - 171ms/step\n",
            "Epoch 148/1000\n",
            "4/4 - 1s - loss: 0.4746 - mse: 0.4485 - val_loss: 0.3903 - val_mse: 0.3903 - lr: 0.0010 - 670ms/epoch - 167ms/step\n",
            "Epoch 149/1000\n",
            "4/4 - 1s - loss: 0.4735 - mse: 0.4478 - val_loss: 0.3902 - val_mse: 0.3902 - lr: 0.0010 - 675ms/epoch - 169ms/step\n",
            "Epoch 150/1000\n",
            "4/4 - 1s - loss: 0.4728 - mse: 0.4469 - val_loss: 0.3901 - val_mse: 0.3901 - lr: 0.0010 - 678ms/epoch - 170ms/step\n",
            "Epoch 151/1000\n",
            "4/4 - 1s - loss: 0.4735 - mse: 0.4475 - val_loss: 0.3901 - val_mse: 0.3901 - lr: 0.0010 - 684ms/epoch - 171ms/step\n",
            "Epoch 152/1000\n",
            "4/4 - 1s - loss: 0.4712 - mse: 0.4454 - val_loss: 0.3899 - val_mse: 0.3899 - lr: 0.0010 - 683ms/epoch - 171ms/step\n",
            "Epoch 153/1000\n",
            "4/4 - 1s - loss: 0.4722 - mse: 0.4464 - val_loss: 0.3898 - val_mse: 0.3898 - lr: 0.0010 - 683ms/epoch - 171ms/step\n",
            "Epoch 154/1000\n",
            "4/4 - 1s - loss: 0.4707 - mse: 0.4449 - val_loss: 0.3898 - val_mse: 0.3898 - lr: 0.0010 - 666ms/epoch - 166ms/step\n",
            "Epoch 155/1000\n",
            "4/4 - 1s - loss: 0.4685 - mse: 0.4429 - val_loss: 0.3897 - val_mse: 0.3897 - lr: 0.0010 - 673ms/epoch - 168ms/step\n",
            "Epoch 156/1000\n",
            "4/4 - 1s - loss: 0.4702 - mse: 0.4445 - val_loss: 0.3897 - val_mse: 0.3897 - lr: 0.0010 - 682ms/epoch - 170ms/step\n",
            "Epoch 157/1000\n",
            "4/4 - 1s - loss: 0.4665 - mse: 0.4410 - val_loss: 0.3896 - val_mse: 0.3896 - lr: 0.0010 - 654ms/epoch - 163ms/step\n",
            "Epoch 158/1000\n",
            "4/4 - 1s - loss: 0.4676 - mse: 0.4420 - val_loss: 0.3896 - val_mse: 0.3896 - lr: 0.0010 - 666ms/epoch - 167ms/step\n",
            "Epoch 159/1000\n",
            "4/4 - 1s - loss: 0.4657 - mse: 0.4402 - val_loss: 0.3895 - val_mse: 0.3895 - lr: 0.0010 - 667ms/epoch - 167ms/step\n",
            "Epoch 160/1000\n",
            "4/4 - 1s - loss: 0.4670 - mse: 0.4414 - val_loss: 0.3894 - val_mse: 0.3894 - lr: 0.0010 - 678ms/epoch - 170ms/step\n",
            "Epoch 161/1000\n",
            "4/4 - 1s - loss: 0.4652 - mse: 0.4398 - val_loss: 0.3894 - val_mse: 0.3894 - lr: 0.0010 - 680ms/epoch - 170ms/step\n",
            "Epoch 162/1000\n",
            "4/4 - 1s - loss: 0.4639 - mse: 0.4385 - val_loss: 0.3893 - val_mse: 0.3893 - lr: 0.0010 - 666ms/epoch - 166ms/step\n",
            "Epoch 163/1000\n",
            "4/4 - 1s - loss: 0.4636 - mse: 0.4383 - val_loss: 0.3892 - val_mse: 0.3892 - lr: 0.0010 - 665ms/epoch - 166ms/step\n",
            "Epoch 164/1000\n",
            "4/4 - 1s - loss: 0.4634 - mse: 0.4380 - val_loss: 0.3892 - val_mse: 0.3892 - lr: 0.0010 - 674ms/epoch - 168ms/step\n",
            "Epoch 165/1000\n",
            "4/4 - 1s - loss: 0.4636 - mse: 0.4382 - val_loss: 0.3891 - val_mse: 0.3891 - lr: 0.0010 - 690ms/epoch - 173ms/step\n",
            "Epoch 166/1000\n",
            "4/4 - 1s - loss: 0.4604 - mse: 0.4352 - val_loss: 0.3891 - val_mse: 0.3891 - lr: 0.0010 - 680ms/epoch - 170ms/step\n",
            "Epoch 167/1000\n",
            "4/4 - 1s - loss: 0.4606 - mse: 0.4355 - val_loss: 0.3890 - val_mse: 0.3890 - lr: 0.0010 - 682ms/epoch - 171ms/step\n",
            "Epoch 168/1000\n",
            "4/4 - 1s - loss: 0.4617 - mse: 0.4364 - val_loss: 0.3889 - val_mse: 0.3889 - lr: 0.0010 - 670ms/epoch - 167ms/step\n",
            "Epoch 169/1000\n",
            "4/4 - 1s - loss: 0.4591 - mse: 0.4341 - val_loss: 0.3889 - val_mse: 0.3889 - lr: 0.0010 - 665ms/epoch - 166ms/step\n",
            "Epoch 170/1000\n",
            "4/4 - 1s - loss: 0.4604 - mse: 0.4353 - val_loss: 0.3888 - val_mse: 0.3888 - lr: 0.0010 - 672ms/epoch - 168ms/step\n",
            "Epoch 171/1000\n",
            "4/4 - 1s - loss: 0.4579 - mse: 0.4329 - val_loss: 0.3887 - val_mse: 0.3887 - lr: 0.0010 - 684ms/epoch - 171ms/step\n",
            "Epoch 172/1000\n",
            "4/4 - 1s - loss: 0.4588 - mse: 0.4337 - val_loss: 0.3887 - val_mse: 0.3887 - lr: 0.0010 - 664ms/epoch - 166ms/step\n",
            "Epoch 173/1000\n",
            "4/4 - 1s - loss: 0.4581 - mse: 0.4330 - val_loss: 0.3886 - val_mse: 0.3886 - lr: 0.0010 - 656ms/epoch - 164ms/step\n",
            "Epoch 174/1000\n",
            "4/4 - 1s - loss: 0.4578 - mse: 0.4328 - val_loss: 0.3886 - val_mse: 0.3886 - lr: 0.0010 - 675ms/epoch - 169ms/step\n",
            "Epoch 175/1000\n",
            "4/4 - 1s - loss: 0.4562 - mse: 0.4313 - val_loss: 0.3885 - val_mse: 0.3885 - lr: 0.0010 - 674ms/epoch - 169ms/step\n",
            "Epoch 176/1000\n",
            "4/4 - 1s - loss: 0.4563 - mse: 0.4313 - val_loss: 0.3885 - val_mse: 0.3885 - lr: 0.0010 - 666ms/epoch - 166ms/step\n",
            "Epoch 177/1000\n",
            "4/4 - 1s - loss: 0.4543 - mse: 0.4294 - val_loss: 0.3885 - val_mse: 0.3885 - lr: 0.0010 - 675ms/epoch - 169ms/step\n",
            "Epoch 178/1000\n",
            "4/4 - 1s - loss: 0.4559 - mse: 0.4311 - val_loss: 0.3885 - val_mse: 0.3885 - lr: 0.0010 - 665ms/epoch - 166ms/step\n",
            "Epoch 179/1000\n",
            "4/4 - 1s - loss: 0.4544 - mse: 0.4295 - val_loss: 0.3884 - val_mse: 0.3884 - lr: 0.0010 - 689ms/epoch - 172ms/step\n",
            "Epoch 180/1000\n",
            "4/4 - 1s - loss: 0.4536 - mse: 0.4288 - val_loss: 0.3882 - val_mse: 0.3882 - lr: 0.0010 - 906ms/epoch - 227ms/step\n",
            "Epoch 181/1000\n",
            "4/4 - 1s - loss: 0.4537 - mse: 0.4287 - val_loss: 0.3881 - val_mse: 0.3881 - lr: 0.0010 - 681ms/epoch - 170ms/step\n",
            "Epoch 182/1000\n",
            "4/4 - 1s - loss: 0.4537 - mse: 0.4288 - val_loss: 0.3881 - val_mse: 0.3881 - lr: 0.0010 - 668ms/epoch - 167ms/step\n",
            "Epoch 183/1000\n",
            "4/4 - 1s - loss: 0.4534 - mse: 0.4286 - val_loss: 0.3881 - val_mse: 0.3881 - lr: 0.0010 - 680ms/epoch - 170ms/step\n",
            "Epoch 184/1000\n",
            "4/4 - 1s - loss: 0.4527 - mse: 0.4279 - val_loss: 0.3881 - val_mse: 0.3881 - lr: 0.0010 - 671ms/epoch - 168ms/step\n",
            "Epoch 185/1000\n",
            "4/4 - 1s - loss: 0.4530 - mse: 0.4281 - val_loss: 0.3881 - val_mse: 0.3881 - lr: 0.0010 - 662ms/epoch - 166ms/step\n",
            "Epoch 186/1000\n",
            "4/4 - 1s - loss: 0.4512 - mse: 0.4265 - val_loss: 0.3881 - val_mse: 0.3881 - lr: 0.0010 - 680ms/epoch - 170ms/step\n",
            "Epoch 187/1000\n",
            "4/4 - 1s - loss: 0.4517 - mse: 0.4270 - val_loss: 0.3880 - val_mse: 0.3880 - lr: 0.0010 - 660ms/epoch - 165ms/step\n",
            "Epoch 188/1000\n",
            "4/4 - 1s - loss: 0.4515 - mse: 0.4269 - val_loss: 0.3879 - val_mse: 0.3879 - lr: 0.0010 - 667ms/epoch - 167ms/step\n",
            "Epoch 189/1000\n",
            "4/4 - 1s - loss: 0.4505 - mse: 0.4259 - val_loss: 0.3879 - val_mse: 0.3879 - lr: 0.0010 - 680ms/epoch - 170ms/step\n",
            "Epoch 190/1000\n",
            "4/4 - 1s - loss: 0.4511 - mse: 0.4264 - val_loss: 0.3879 - val_mse: 0.3879 - lr: 0.0010 - 656ms/epoch - 164ms/step\n",
            "Epoch 191/1000\n",
            "4/4 - 1s - loss: 0.4488 - mse: 0.4243 - val_loss: 0.3879 - val_mse: 0.3879 - lr: 0.0010 - 666ms/epoch - 167ms/step\n",
            "Epoch 192/1000\n",
            "4/4 - 1s - loss: 0.4501 - mse: 0.4254 - val_loss: 0.3879 - val_mse: 0.3879 - lr: 0.0010 - 652ms/epoch - 163ms/step\n",
            "Epoch 193/1000\n",
            "4/4 - 1s - loss: 0.4483 - mse: 0.4238 - val_loss: 0.3880 - val_mse: 0.3880 - lr: 0.0010 - 682ms/epoch - 170ms/step\n",
            "Epoch 194/1000\n",
            "4/4 - 1s - loss: 0.4485 - mse: 0.4239 - val_loss: 0.3879 - val_mse: 0.3879 - lr: 0.0010 - 658ms/epoch - 165ms/step\n",
            "Epoch 195/1000\n",
            "4/4 - 1s - loss: 0.4474 - mse: 0.4230 - val_loss: 0.3878 - val_mse: 0.3878 - lr: 0.0010 - 671ms/epoch - 168ms/step\n",
            "Epoch 196/1000\n",
            "4/4 - 1s - loss: 0.4474 - mse: 0.4231 - val_loss: 0.3878 - val_mse: 0.3878 - lr: 0.0010 - 657ms/epoch - 164ms/step\n",
            "Epoch 197/1000\n",
            "4/4 - 1s - loss: 0.4475 - mse: 0.4230 - val_loss: 0.3877 - val_mse: 0.3877 - lr: 0.0010 - 675ms/epoch - 169ms/step\n",
            "Epoch 198/1000\n",
            "4/4 - 1s - loss: 0.4476 - mse: 0.4232 - val_loss: 0.3877 - val_mse: 0.3877 - lr: 0.0010 - 672ms/epoch - 168ms/step\n",
            "Epoch 199/1000\n",
            "4/4 - 1s - loss: 0.4466 - mse: 0.4222 - val_loss: 0.3876 - val_mse: 0.3876 - lr: 0.0010 - 660ms/epoch - 165ms/step\n",
            "Epoch 200/1000\n",
            "4/4 - 1s - loss: 0.4465 - mse: 0.4221 - val_loss: 0.3876 - val_mse: 0.3876 - lr: 0.0010 - 663ms/epoch - 166ms/step\n",
            "Epoch 201/1000\n",
            "4/4 - 1s - loss: 0.4460 - mse: 0.4216 - val_loss: 0.3875 - val_mse: 0.3875 - lr: 0.0010 - 658ms/epoch - 164ms/step\n",
            "Epoch 202/1000\n",
            "4/4 - 1s - loss: 0.4455 - mse: 0.4212 - val_loss: 0.3875 - val_mse: 0.3875 - lr: 0.0010 - 670ms/epoch - 168ms/step\n",
            "Epoch 203/1000\n",
            "4/4 - 1s - loss: 0.4454 - mse: 0.4212 - val_loss: 0.3875 - val_mse: 0.3875 - lr: 0.0010 - 679ms/epoch - 170ms/step\n",
            "Epoch 204/1000\n",
            "4/4 - 1s - loss: 0.4452 - mse: 0.4209 - val_loss: 0.3876 - val_mse: 0.3876 - lr: 0.0010 - 668ms/epoch - 167ms/step\n",
            "Epoch 205/1000\n",
            "4/4 - 1s - loss: 0.4444 - mse: 0.4201 - val_loss: 0.3875 - val_mse: 0.3875 - lr: 0.0010 - 662ms/epoch - 165ms/step\n",
            "Epoch 206/1000\n",
            "4/4 - 1s - loss: 0.4448 - mse: 0.4205 - val_loss: 0.3875 - val_mse: 0.3875 - lr: 0.0010 - 654ms/epoch - 164ms/step\n",
            "Epoch 207/1000\n",
            "4/4 - 1s - loss: 0.4442 - mse: 0.4199 - val_loss: 0.3874 - val_mse: 0.3874 - lr: 0.0010 - 654ms/epoch - 163ms/step\n",
            "Epoch 208/1000\n",
            "4/4 - 1s - loss: 0.4440 - mse: 0.4198 - val_loss: 0.3873 - val_mse: 0.3873 - lr: 0.0010 - 671ms/epoch - 168ms/step\n",
            "Epoch 209/1000\n",
            "4/4 - 1s - loss: 0.4440 - mse: 0.4197 - val_loss: 0.3873 - val_mse: 0.3873 - lr: 0.0010 - 671ms/epoch - 168ms/step\n",
            "Epoch 210/1000\n",
            "4/4 - 1s - loss: 0.4435 - mse: 0.4192 - val_loss: 0.3873 - val_mse: 0.3873 - lr: 0.0010 - 668ms/epoch - 167ms/step\n",
            "Epoch 211/1000\n",
            "4/4 - 1s - loss: 0.4428 - mse: 0.4188 - val_loss: 0.3874 - val_mse: 0.3874 - lr: 0.0010 - 671ms/epoch - 168ms/step\n",
            "Epoch 212/1000\n",
            "4/4 - 1s - loss: 0.4427 - mse: 0.4185 - val_loss: 0.3874 - val_mse: 0.3874 - lr: 0.0010 - 679ms/epoch - 170ms/step\n",
            "Epoch 213/1000\n",
            "4/4 - 1s - loss: 0.4431 - mse: 0.4189 - val_loss: 0.3874 - val_mse: 0.3874 - lr: 0.0010 - 682ms/epoch - 170ms/step\n",
            "Epoch 214/1000\n",
            "\n",
            "Epoch 214: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "4/4 - 1s - loss: 0.4420 - mse: 0.4180 - val_loss: 0.3874 - val_mse: 0.3874 - lr: 0.0010 - 673ms/epoch - 168ms/step\n",
            "Epoch 215/1000\n",
            "4/4 - 1s - loss: 0.4409 - mse: 0.4169 - val_loss: 0.3874 - val_mse: 0.3874 - lr: 1.0000e-04 - 673ms/epoch - 168ms/step\n",
            "Epoch 216/1000\n",
            "4/4 - 1s - loss: 0.4420 - mse: 0.4178 - val_loss: 0.3874 - val_mse: 0.3874 - lr: 1.0000e-04 - 663ms/epoch - 166ms/step\n",
            "Epoch 217/1000\n",
            "4/4 - 1s - loss: 0.4424 - mse: 0.4184 - val_loss: 0.3874 - val_mse: 0.3874 - lr: 1.0000e-04 - 659ms/epoch - 165ms/step\n",
            "Epoch 218/1000\n",
            "4/4 - 1s - loss: 0.4417 - mse: 0.4175 - val_loss: 0.3874 - val_mse: 0.3874 - lr: 1.0000e-04 - 671ms/epoch - 168ms/step\n",
            "Epoch 219/1000\n",
            "4/4 - 1s - loss: 0.4423 - mse: 0.4182 - val_loss: 0.3873 - val_mse: 0.3873 - lr: 1.0000e-04 - 664ms/epoch - 166ms/step\n",
            "Epoch 219: early stopping\n",
            "==================================================\n",
            "Step 11\n",
            "==================================================\n",
            "Epoch 1/1000\n",
            "4/4 - 4s - loss: 4.0817 - mse: 3.8578 - val_loss: 1.0906 - val_mse: 1.0906 - lr: 0.0010 - 4s/epoch - 1s/step\n",
            "Epoch 2/1000\n",
            "4/4 - 1s - loss: 2.2646 - mse: 2.1461 - val_loss: 0.9765 - val_mse: 0.9765 - lr: 0.0010 - 658ms/epoch - 164ms/step\n",
            "Epoch 3/1000\n",
            "4/4 - 1s - loss: 1.6577 - mse: 1.5694 - val_loss: 0.9122 - val_mse: 0.9122 - lr: 0.0010 - 657ms/epoch - 164ms/step\n",
            "Epoch 4/1000\n",
            "4/4 - 1s - loss: 1.4544 - mse: 1.3784 - val_loss: 0.8884 - val_mse: 0.8884 - lr: 0.0010 - 662ms/epoch - 166ms/step\n",
            "Epoch 5/1000\n",
            "4/4 - 1s - loss: 1.3057 - mse: 1.2373 - val_loss: 0.8868 - val_mse: 0.8868 - lr: 0.0010 - 687ms/epoch - 172ms/step\n",
            "Epoch 6/1000\n",
            "4/4 - 1s - loss: 1.2358 - mse: 1.1714 - val_loss: 0.8902 - val_mse: 0.8902 - lr: 0.0010 - 669ms/epoch - 167ms/step\n",
            "Epoch 7/1000\n",
            "4/4 - 1s - loss: 1.2032 - mse: 1.1402 - val_loss: 0.8853 - val_mse: 0.8853 - lr: 0.0010 - 663ms/epoch - 166ms/step\n",
            "Epoch 8/1000\n",
            "4/4 - 1s - loss: 1.1420 - mse: 1.0817 - val_loss: 0.8705 - val_mse: 0.8705 - lr: 0.0010 - 649ms/epoch - 162ms/step\n",
            "Epoch 9/1000\n",
            "4/4 - 1s - loss: 1.1013 - mse: 1.0428 - val_loss: 0.8532 - val_mse: 0.8532 - lr: 0.0010 - 665ms/epoch - 166ms/step\n",
            "Epoch 10/1000\n",
            "4/4 - 1s - loss: 1.0611 - mse: 1.0047 - val_loss: 0.8380 - val_mse: 0.8380 - lr: 0.0010 - 669ms/epoch - 167ms/step\n",
            "Epoch 11/1000\n",
            "4/4 - 1s - loss: 1.0420 - mse: 0.9866 - val_loss: 0.8282 - val_mse: 0.8282 - lr: 0.0010 - 653ms/epoch - 163ms/step\n",
            "Epoch 12/1000\n",
            "4/4 - 1s - loss: 1.0154 - mse: 0.9613 - val_loss: 0.8233 - val_mse: 0.8233 - lr: 0.0010 - 659ms/epoch - 165ms/step\n",
            "Epoch 13/1000\n",
            "4/4 - 1s - loss: 0.9940 - mse: 0.9413 - val_loss: 0.8203 - val_mse: 0.8203 - lr: 0.0010 - 661ms/epoch - 165ms/step\n",
            "Epoch 14/1000\n",
            "4/4 - 1s - loss: 0.9700 - mse: 0.9183 - val_loss: 0.8164 - val_mse: 0.8164 - lr: 0.0010 - 650ms/epoch - 163ms/step\n",
            "Epoch 15/1000\n",
            "4/4 - 1s - loss: 0.9625 - mse: 0.9108 - val_loss: 0.8108 - val_mse: 0.8108 - lr: 0.0010 - 657ms/epoch - 164ms/step\n",
            "Epoch 16/1000\n",
            "4/4 - 1s - loss: 0.9379 - mse: 0.8881 - val_loss: 0.8030 - val_mse: 0.8030 - lr: 0.0010 - 657ms/epoch - 164ms/step\n",
            "Epoch 17/1000\n",
            "4/4 - 1s - loss: 0.9313 - mse: 0.8818 - val_loss: 0.7941 - val_mse: 0.7941 - lr: 0.0010 - 680ms/epoch - 170ms/step\n",
            "Epoch 18/1000\n",
            "4/4 - 1s - loss: 0.9141 - mse: 0.8652 - val_loss: 0.7846 - val_mse: 0.7846 - lr: 0.0010 - 663ms/epoch - 166ms/step\n",
            "Epoch 19/1000\n",
            "4/4 - 1s - loss: 0.9039 - mse: 0.8562 - val_loss: 0.7763 - val_mse: 0.7763 - lr: 0.0010 - 671ms/epoch - 168ms/step\n",
            "Epoch 20/1000\n",
            "4/4 - 1s - loss: 0.8924 - mse: 0.8450 - val_loss: 0.7693 - val_mse: 0.7693 - lr: 0.0010 - 685ms/epoch - 171ms/step\n",
            "Epoch 21/1000\n",
            "4/4 - 1s - loss: 0.8807 - mse: 0.8342 - val_loss: 0.7631 - val_mse: 0.7631 - lr: 0.0010 - 671ms/epoch - 168ms/step\n",
            "Epoch 22/1000\n",
            "4/4 - 1s - loss: 0.8694 - mse: 0.8238 - val_loss: 0.7574 - val_mse: 0.7574 - lr: 0.0010 - 653ms/epoch - 163ms/step\n",
            "Epoch 23/1000\n",
            "4/4 - 1s - loss: 0.8601 - mse: 0.8145 - val_loss: 0.7513 - val_mse: 0.7513 - lr: 0.0010 - 662ms/epoch - 166ms/step\n",
            "Epoch 24/1000\n",
            "4/4 - 1s - loss: 0.8490 - mse: 0.8042 - val_loss: 0.7450 - val_mse: 0.7450 - lr: 0.0010 - 669ms/epoch - 167ms/step\n",
            "Epoch 25/1000\n",
            "4/4 - 1s - loss: 0.8420 - mse: 0.7978 - val_loss: 0.7379 - val_mse: 0.7379 - lr: 0.0010 - 657ms/epoch - 164ms/step\n",
            "Epoch 26/1000\n",
            "4/4 - 1s - loss: 0.8319 - mse: 0.7882 - val_loss: 0.7309 - val_mse: 0.7309 - lr: 0.0010 - 671ms/epoch - 168ms/step\n",
            "Epoch 27/1000\n",
            "4/4 - 1s - loss: 0.8258 - mse: 0.7823 - val_loss: 0.7243 - val_mse: 0.7243 - lr: 0.0010 - 674ms/epoch - 169ms/step\n",
            "Epoch 28/1000\n",
            "4/4 - 1s - loss: 0.8139 - mse: 0.7709 - val_loss: 0.7188 - val_mse: 0.7188 - lr: 0.0010 - 668ms/epoch - 167ms/step\n",
            "Epoch 29/1000\n",
            "4/4 - 1s - loss: 0.8036 - mse: 0.7613 - val_loss: 0.7147 - val_mse: 0.7147 - lr: 0.0010 - 666ms/epoch - 167ms/step\n",
            "Epoch 30/1000\n",
            "4/4 - 1s - loss: 0.8008 - mse: 0.7587 - val_loss: 0.7099 - val_mse: 0.7099 - lr: 0.0010 - 668ms/epoch - 167ms/step\n",
            "Epoch 31/1000\n",
            "4/4 - 1s - loss: 0.7906 - mse: 0.7490 - val_loss: 0.7051 - val_mse: 0.7051 - lr: 0.0010 - 651ms/epoch - 163ms/step\n",
            "Epoch 32/1000\n",
            "4/4 - 1s - loss: 0.7869 - mse: 0.7455 - val_loss: 0.6992 - val_mse: 0.6992 - lr: 0.0010 - 666ms/epoch - 167ms/step\n",
            "Epoch 33/1000\n",
            "4/4 - 1s - loss: 0.7789 - mse: 0.7376 - val_loss: 0.6932 - val_mse: 0.6932 - lr: 0.0010 - 662ms/epoch - 166ms/step\n",
            "Epoch 34/1000\n",
            "4/4 - 1s - loss: 0.7714 - mse: 0.7307 - val_loss: 0.6872 - val_mse: 0.6872 - lr: 0.0010 - 671ms/epoch - 168ms/step\n",
            "Epoch 35/1000\n",
            "4/4 - 1s - loss: 0.7642 - mse: 0.7237 - val_loss: 0.6820 - val_mse: 0.6820 - lr: 0.0010 - 683ms/epoch - 171ms/step\n",
            "Epoch 36/1000\n",
            "4/4 - 1s - loss: 0.7584 - mse: 0.7185 - val_loss: 0.6771 - val_mse: 0.6771 - lr: 0.0010 - 669ms/epoch - 167ms/step\n",
            "Epoch 37/1000\n",
            "4/4 - 1s - loss: 0.7484 - mse: 0.7093 - val_loss: 0.6731 - val_mse: 0.6731 - lr: 0.0010 - 664ms/epoch - 166ms/step\n",
            "Epoch 38/1000\n",
            "4/4 - 1s - loss: 0.7432 - mse: 0.7042 - val_loss: 0.6687 - val_mse: 0.6687 - lr: 0.0010 - 674ms/epoch - 168ms/step\n",
            "Epoch 39/1000\n",
            "4/4 - 1s - loss: 0.7373 - mse: 0.6986 - val_loss: 0.6629 - val_mse: 0.6629 - lr: 0.0010 - 672ms/epoch - 168ms/step\n",
            "Epoch 40/1000\n",
            "4/4 - 1s - loss: 0.7296 - mse: 0.6913 - val_loss: 0.6573 - val_mse: 0.6573 - lr: 0.0010 - 684ms/epoch - 171ms/step\n",
            "Epoch 41/1000\n",
            "4/4 - 1s - loss: 0.7253 - mse: 0.6873 - val_loss: 0.6524 - val_mse: 0.6524 - lr: 0.0010 - 678ms/epoch - 170ms/step\n",
            "Epoch 42/1000\n",
            "4/4 - 1s - loss: 0.7190 - mse: 0.6816 - val_loss: 0.6477 - val_mse: 0.6477 - lr: 0.0010 - 666ms/epoch - 166ms/step\n",
            "Epoch 43/1000\n",
            "4/4 - 1s - loss: 0.7137 - mse: 0.6761 - val_loss: 0.6429 - val_mse: 0.6429 - lr: 0.0010 - 667ms/epoch - 167ms/step\n",
            "Epoch 44/1000\n",
            "4/4 - 1s - loss: 0.7107 - mse: 0.6734 - val_loss: 0.6377 - val_mse: 0.6377 - lr: 0.0010 - 667ms/epoch - 167ms/step\n",
            "Epoch 45/1000\n",
            "4/4 - 1s - loss: 0.7041 - mse: 0.6669 - val_loss: 0.6325 - val_mse: 0.6325 - lr: 0.0010 - 665ms/epoch - 166ms/step\n",
            "Epoch 46/1000\n",
            "4/4 - 1s - loss: 0.6989 - mse: 0.6620 - val_loss: 0.6271 - val_mse: 0.6271 - lr: 0.0010 - 660ms/epoch - 165ms/step\n",
            "Epoch 47/1000\n",
            "4/4 - 1s - loss: 0.6943 - mse: 0.6575 - val_loss: 0.6219 - val_mse: 0.6219 - lr: 0.0010 - 667ms/epoch - 167ms/step\n",
            "Epoch 48/1000\n",
            "4/4 - 1s - loss: 0.6889 - mse: 0.6529 - val_loss: 0.6176 - val_mse: 0.6176 - lr: 0.0010 - 664ms/epoch - 166ms/step\n",
            "Epoch 49/1000\n",
            "4/4 - 1s - loss: 0.6853 - mse: 0.6491 - val_loss: 0.6135 - val_mse: 0.6135 - lr: 0.0010 - 664ms/epoch - 166ms/step\n",
            "Epoch 50/1000\n",
            "4/4 - 1s - loss: 0.6760 - mse: 0.6405 - val_loss: 0.6088 - val_mse: 0.6088 - lr: 0.0010 - 665ms/epoch - 166ms/step\n",
            "Epoch 51/1000\n",
            "4/4 - 1s - loss: 0.6686 - mse: 0.6338 - val_loss: 0.6042 - val_mse: 0.6042 - lr: 0.0010 - 678ms/epoch - 169ms/step\n",
            "Epoch 52/1000\n",
            "4/4 - 1s - loss: 0.6673 - mse: 0.6324 - val_loss: 0.5991 - val_mse: 0.5991 - lr: 0.0010 - 654ms/epoch - 163ms/step\n",
            "Epoch 53/1000\n",
            "4/4 - 1s - loss: 0.6653 - mse: 0.6304 - val_loss: 0.5942 - val_mse: 0.5942 - lr: 0.0010 - 660ms/epoch - 165ms/step\n",
            "Epoch 54/1000\n",
            "4/4 - 1s - loss: 0.6623 - mse: 0.6276 - val_loss: 0.5894 - val_mse: 0.5894 - lr: 0.0010 - 667ms/epoch - 167ms/step\n",
            "Epoch 55/1000\n",
            "4/4 - 1s - loss: 0.6556 - mse: 0.6212 - val_loss: 0.5850 - val_mse: 0.5850 - lr: 0.0010 - 677ms/epoch - 169ms/step\n",
            "Epoch 56/1000\n",
            "4/4 - 1s - loss: 0.6506 - mse: 0.6164 - val_loss: 0.5811 - val_mse: 0.5811 - lr: 0.0010 - 667ms/epoch - 167ms/step\n",
            "Epoch 57/1000\n",
            "4/4 - 1s - loss: 0.6470 - mse: 0.6130 - val_loss: 0.5772 - val_mse: 0.5772 - lr: 0.0010 - 668ms/epoch - 167ms/step\n",
            "Epoch 58/1000\n",
            "4/4 - 1s - loss: 0.6413 - mse: 0.6074 - val_loss: 0.5732 - val_mse: 0.5732 - lr: 0.0010 - 657ms/epoch - 164ms/step\n",
            "Epoch 59/1000\n",
            "4/4 - 1s - loss: 0.6377 - mse: 0.6044 - val_loss: 0.5691 - val_mse: 0.5691 - lr: 0.0010 - 656ms/epoch - 164ms/step\n",
            "Epoch 60/1000\n",
            "4/4 - 1s - loss: 0.6353 - mse: 0.6019 - val_loss: 0.5645 - val_mse: 0.5645 - lr: 0.0010 - 658ms/epoch - 164ms/step\n",
            "Epoch 61/1000\n",
            "4/4 - 1s - loss: 0.6351 - mse: 0.6018 - val_loss: 0.5597 - val_mse: 0.5597 - lr: 0.0010 - 664ms/epoch - 166ms/step\n",
            "Epoch 62/1000\n",
            "4/4 - 1s - loss: 0.6278 - mse: 0.5947 - val_loss: 0.5560 - val_mse: 0.5560 - lr: 0.0010 - 658ms/epoch - 164ms/step\n",
            "Epoch 63/1000\n",
            "4/4 - 1s - loss: 0.6264 - mse: 0.5936 - val_loss: 0.5534 - val_mse: 0.5534 - lr: 0.0010 - 657ms/epoch - 164ms/step\n",
            "Epoch 64/1000\n",
            "4/4 - 1s - loss: 0.6190 - mse: 0.5865 - val_loss: 0.5506 - val_mse: 0.5506 - lr: 0.0010 - 652ms/epoch - 163ms/step\n",
            "Epoch 65/1000\n",
            "4/4 - 1s - loss: 0.6195 - mse: 0.5869 - val_loss: 0.5460 - val_mse: 0.5460 - lr: 0.0010 - 664ms/epoch - 166ms/step\n",
            "Epoch 66/1000\n",
            "4/4 - 1s - loss: 0.6148 - mse: 0.5825 - val_loss: 0.5412 - val_mse: 0.5412 - lr: 0.0010 - 669ms/epoch - 167ms/step\n",
            "Epoch 67/1000\n",
            "4/4 - 1s - loss: 0.6105 - mse: 0.5785 - val_loss: 0.5370 - val_mse: 0.5370 - lr: 0.0010 - 659ms/epoch - 165ms/step\n",
            "Epoch 68/1000\n",
            "4/4 - 1s - loss: 0.6082 - mse: 0.5761 - val_loss: 0.5337 - val_mse: 0.5337 - lr: 0.0010 - 671ms/epoch - 168ms/step\n",
            "Epoch 69/1000\n",
            "4/4 - 1s - loss: 0.6073 - mse: 0.5752 - val_loss: 0.5305 - val_mse: 0.5305 - lr: 0.0010 - 667ms/epoch - 167ms/step\n",
            "Epoch 70/1000\n",
            "4/4 - 1s - loss: 0.6032 - mse: 0.5714 - val_loss: 0.5270 - val_mse: 0.5270 - lr: 0.0010 - 676ms/epoch - 169ms/step\n",
            "Epoch 71/1000\n",
            "4/4 - 1s - loss: 0.5973 - mse: 0.5656 - val_loss: 0.5232 - val_mse: 0.5232 - lr: 0.0010 - 669ms/epoch - 167ms/step\n",
            "Epoch 72/1000\n",
            "4/4 - 1s - loss: 0.5943 - mse: 0.5629 - val_loss: 0.5194 - val_mse: 0.5194 - lr: 0.0010 - 692ms/epoch - 173ms/step\n",
            "Epoch 73/1000\n",
            "4/4 - 1s - loss: 0.5925 - mse: 0.5611 - val_loss: 0.5161 - val_mse: 0.5161 - lr: 0.0010 - 669ms/epoch - 167ms/step\n",
            "Epoch 74/1000\n",
            "4/4 - 1s - loss: 0.5874 - mse: 0.5566 - val_loss: 0.5137 - val_mse: 0.5137 - lr: 0.0010 - 655ms/epoch - 164ms/step\n",
            "Epoch 75/1000\n",
            "4/4 - 1s - loss: 0.5861 - mse: 0.5553 - val_loss: 0.5113 - val_mse: 0.5113 - lr: 0.0010 - 655ms/epoch - 164ms/step\n",
            "Epoch 76/1000\n",
            "4/4 - 1s - loss: 0.5804 - mse: 0.5499 - val_loss: 0.5086 - val_mse: 0.5086 - lr: 0.0010 - 656ms/epoch - 164ms/step\n",
            "Epoch 77/1000\n",
            "4/4 - 1s - loss: 0.5778 - mse: 0.5473 - val_loss: 0.5054 - val_mse: 0.5054 - lr: 0.0010 - 674ms/epoch - 168ms/step\n",
            "Epoch 78/1000\n",
            "4/4 - 1s - loss: 0.5775 - mse: 0.5470 - val_loss: 0.5019 - val_mse: 0.5019 - lr: 0.0010 - 662ms/epoch - 165ms/step\n",
            "Epoch 79/1000\n",
            "4/4 - 1s - loss: 0.5748 - mse: 0.5444 - val_loss: 0.4990 - val_mse: 0.4990 - lr: 0.0010 - 673ms/epoch - 168ms/step\n",
            "Epoch 80/1000\n",
            "4/4 - 1s - loss: 0.5727 - mse: 0.5426 - val_loss: 0.4968 - val_mse: 0.4968 - lr: 0.0010 - 672ms/epoch - 168ms/step\n",
            "Epoch 81/1000\n",
            "4/4 - 1s - loss: 0.5691 - mse: 0.5389 - val_loss: 0.4951 - val_mse: 0.4951 - lr: 0.0010 - 650ms/epoch - 163ms/step\n",
            "Epoch 82/1000\n",
            "4/4 - 1s - loss: 0.5661 - mse: 0.5360 - val_loss: 0.4924 - val_mse: 0.4924 - lr: 0.0010 - 653ms/epoch - 163ms/step\n",
            "Epoch 83/1000\n",
            "4/4 - 1s - loss: 0.5653 - mse: 0.5354 - val_loss: 0.4898 - val_mse: 0.4898 - lr: 0.0010 - 663ms/epoch - 166ms/step\n",
            "Epoch 84/1000\n",
            "4/4 - 1s - loss: 0.5610 - mse: 0.5314 - val_loss: 0.4872 - val_mse: 0.4872 - lr: 0.0010 - 660ms/epoch - 165ms/step\n",
            "Epoch 85/1000\n",
            "4/4 - 1s - loss: 0.5596 - mse: 0.5299 - val_loss: 0.4841 - val_mse: 0.4841 - lr: 0.0010 - 652ms/epoch - 163ms/step\n",
            "Epoch 86/1000\n",
            "4/4 - 1s - loss: 0.5543 - mse: 0.5249 - val_loss: 0.4815 - val_mse: 0.4815 - lr: 0.0010 - 657ms/epoch - 164ms/step\n",
            "Epoch 87/1000\n",
            "4/4 - 1s - loss: 0.5546 - mse: 0.5253 - val_loss: 0.4802 - val_mse: 0.4802 - lr: 0.0010 - 659ms/epoch - 165ms/step\n",
            "Epoch 88/1000\n",
            "4/4 - 1s - loss: 0.5550 - mse: 0.5257 - val_loss: 0.4792 - val_mse: 0.4792 - lr: 0.0010 - 663ms/epoch - 166ms/step\n",
            "Epoch 89/1000\n",
            "4/4 - 1s - loss: 0.5504 - mse: 0.5213 - val_loss: 0.4767 - val_mse: 0.4767 - lr: 0.0010 - 642ms/epoch - 161ms/step\n",
            "Epoch 90/1000\n",
            "4/4 - 1s - loss: 0.5460 - mse: 0.5171 - val_loss: 0.4739 - val_mse: 0.4739 - lr: 0.0010 - 667ms/epoch - 167ms/step\n",
            "Epoch 91/1000\n",
            "4/4 - 1s - loss: 0.5471 - mse: 0.5181 - val_loss: 0.4718 - val_mse: 0.4718 - lr: 0.0010 - 666ms/epoch - 167ms/step\n",
            "Epoch 92/1000\n",
            "4/4 - 1s - loss: 0.5434 - mse: 0.5147 - val_loss: 0.4694 - val_mse: 0.4694 - lr: 0.0010 - 665ms/epoch - 166ms/step\n",
            "Epoch 93/1000\n",
            "4/4 - 1s - loss: 0.5415 - mse: 0.5129 - val_loss: 0.4676 - val_mse: 0.4676 - lr: 0.0010 - 687ms/epoch - 172ms/step\n",
            "Epoch 94/1000\n",
            "4/4 - 1s - loss: 0.5379 - mse: 0.5093 - val_loss: 0.4664 - val_mse: 0.4664 - lr: 0.0010 - 663ms/epoch - 166ms/step\n",
            "Epoch 95/1000\n",
            "4/4 - 1s - loss: 0.5356 - mse: 0.5074 - val_loss: 0.4655 - val_mse: 0.4655 - lr: 0.0010 - 681ms/epoch - 170ms/step\n",
            "Epoch 96/1000\n",
            "4/4 - 1s - loss: 0.5377 - mse: 0.5091 - val_loss: 0.4641 - val_mse: 0.4641 - lr: 0.0010 - 662ms/epoch - 166ms/step\n",
            "Epoch 97/1000\n",
            "4/4 - 1s - loss: 0.5323 - mse: 0.5040 - val_loss: 0.4624 - val_mse: 0.4624 - lr: 0.0010 - 660ms/epoch - 165ms/step\n",
            "Epoch 98/1000\n",
            "4/4 - 1s - loss: 0.5301 - mse: 0.5021 - val_loss: 0.4613 - val_mse: 0.4613 - lr: 0.0010 - 658ms/epoch - 164ms/step\n",
            "Epoch 99/1000\n",
            "4/4 - 1s - loss: 0.5291 - mse: 0.5011 - val_loss: 0.4600 - val_mse: 0.4600 - lr: 0.0010 - 660ms/epoch - 165ms/step\n",
            "Epoch 100/1000\n",
            "4/4 - 1s - loss: 0.5273 - mse: 0.4993 - val_loss: 0.4584 - val_mse: 0.4584 - lr: 0.0010 - 663ms/epoch - 166ms/step\n",
            "Epoch 101/1000\n",
            "4/4 - 1s - loss: 0.5276 - mse: 0.4995 - val_loss: 0.4562 - val_mse: 0.4562 - lr: 0.0010 - 675ms/epoch - 169ms/step\n",
            "Epoch 102/1000\n",
            "4/4 - 1s - loss: 0.5217 - mse: 0.4941 - val_loss: 0.4551 - val_mse: 0.4551 - lr: 0.0010 - 663ms/epoch - 166ms/step\n",
            "Epoch 103/1000\n",
            "4/4 - 1s - loss: 0.5226 - mse: 0.4947 - val_loss: 0.4537 - val_mse: 0.4537 - lr: 0.0010 - 660ms/epoch - 165ms/step\n",
            "Epoch 104/1000\n",
            "4/4 - 1s - loss: 0.5200 - mse: 0.4924 - val_loss: 0.4527 - val_mse: 0.4527 - lr: 0.0010 - 672ms/epoch - 168ms/step\n",
            "Epoch 105/1000\n",
            "4/4 - 1s - loss: 0.5192 - mse: 0.4917 - val_loss: 0.4514 - val_mse: 0.4514 - lr: 0.0010 - 661ms/epoch - 165ms/step\n",
            "Epoch 106/1000\n",
            "4/4 - 1s - loss: 0.5158 - mse: 0.4884 - val_loss: 0.4504 - val_mse: 0.4504 - lr: 0.0010 - 677ms/epoch - 169ms/step\n",
            "Epoch 107/1000\n",
            "4/4 - 1s - loss: 0.5136 - mse: 0.4864 - val_loss: 0.4496 - val_mse: 0.4496 - lr: 0.0010 - 659ms/epoch - 165ms/step\n",
            "Epoch 108/1000\n",
            "4/4 - 1s - loss: 0.5124 - mse: 0.4853 - val_loss: 0.4489 - val_mse: 0.4489 - lr: 0.0010 - 674ms/epoch - 168ms/step\n",
            "Epoch 109/1000\n",
            "4/4 - 1s - loss: 0.5113 - mse: 0.4843 - val_loss: 0.4482 - val_mse: 0.4482 - lr: 0.0010 - 652ms/epoch - 163ms/step\n",
            "Epoch 110/1000\n",
            "4/4 - 1s - loss: 0.5085 - mse: 0.4815 - val_loss: 0.4473 - val_mse: 0.4473 - lr: 0.0010 - 691ms/epoch - 173ms/step\n",
            "Epoch 111/1000\n",
            "4/4 - 1s - loss: 0.5092 - mse: 0.4822 - val_loss: 0.4464 - val_mse: 0.4464 - lr: 0.0010 - 677ms/epoch - 169ms/step\n",
            "Epoch 112/1000\n",
            "4/4 - 1s - loss: 0.5062 - mse: 0.4793 - val_loss: 0.4453 - val_mse: 0.4453 - lr: 0.0010 - 656ms/epoch - 164ms/step\n",
            "Epoch 113/1000\n",
            "4/4 - 1s - loss: 0.5066 - mse: 0.4798 - val_loss: 0.4444 - val_mse: 0.4444 - lr: 0.0010 - 668ms/epoch - 167ms/step\n",
            "Epoch 114/1000\n",
            "4/4 - 1s - loss: 0.5056 - mse: 0.4787 - val_loss: 0.4428 - val_mse: 0.4428 - lr: 0.0010 - 663ms/epoch - 166ms/step\n",
            "Epoch 115/1000\n",
            "4/4 - 1s - loss: 0.5027 - mse: 0.4760 - val_loss: 0.4417 - val_mse: 0.4417 - lr: 0.0010 - 679ms/epoch - 170ms/step\n",
            "Epoch 116/1000\n",
            "4/4 - 1s - loss: 0.5009 - mse: 0.4744 - val_loss: 0.4410 - val_mse: 0.4410 - lr: 0.0010 - 677ms/epoch - 169ms/step\n",
            "Epoch 117/1000\n",
            "4/4 - 1s - loss: 0.4989 - mse: 0.4723 - val_loss: 0.4403 - val_mse: 0.4403 - lr: 0.0010 - 678ms/epoch - 170ms/step\n",
            "Epoch 118/1000\n",
            "4/4 - 1s - loss: 0.4985 - mse: 0.4721 - val_loss: 0.4394 - val_mse: 0.4394 - lr: 0.0010 - 672ms/epoch - 168ms/step\n",
            "Epoch 119/1000\n",
            "4/4 - 1s - loss: 0.4988 - mse: 0.4722 - val_loss: 0.4385 - val_mse: 0.4385 - lr: 0.0010 - 673ms/epoch - 168ms/step\n",
            "Epoch 120/1000\n",
            "4/4 - 1s - loss: 0.4974 - mse: 0.4709 - val_loss: 0.4382 - val_mse: 0.4382 - lr: 0.0010 - 664ms/epoch - 166ms/step\n",
            "Epoch 121/1000\n",
            "4/4 - 1s - loss: 0.4939 - mse: 0.4677 - val_loss: 0.4373 - val_mse: 0.4373 - lr: 0.0010 - 671ms/epoch - 168ms/step\n",
            "Epoch 122/1000\n",
            "4/4 - 1s - loss: 0.4937 - mse: 0.4676 - val_loss: 0.4367 - val_mse: 0.4367 - lr: 0.0010 - 676ms/epoch - 169ms/step\n",
            "Epoch 123/1000\n",
            "4/4 - 1s - loss: 0.4927 - mse: 0.4664 - val_loss: 0.4360 - val_mse: 0.4360 - lr: 0.0010 - 666ms/epoch - 166ms/step\n",
            "Epoch 124/1000\n",
            "4/4 - 1s - loss: 0.4912 - mse: 0.4649 - val_loss: 0.4353 - val_mse: 0.4353 - lr: 0.0010 - 662ms/epoch - 166ms/step\n",
            "Epoch 125/1000\n",
            "4/4 - 1s - loss: 0.4898 - mse: 0.4638 - val_loss: 0.4347 - val_mse: 0.4347 - lr: 0.0010 - 672ms/epoch - 168ms/step\n",
            "Epoch 126/1000\n",
            "4/4 - 1s - loss: 0.4879 - mse: 0.4620 - val_loss: 0.4340 - val_mse: 0.4340 - lr: 0.0010 - 658ms/epoch - 164ms/step\n",
            "Epoch 127/1000\n",
            "4/4 - 1s - loss: 0.4868 - mse: 0.4609 - val_loss: 0.4332 - val_mse: 0.4332 - lr: 0.0010 - 661ms/epoch - 165ms/step\n",
            "Epoch 128/1000\n",
            "4/4 - 1s - loss: 0.4851 - mse: 0.4593 - val_loss: 0.4330 - val_mse: 0.4330 - lr: 0.0010 - 679ms/epoch - 170ms/step\n",
            "Epoch 129/1000\n",
            "4/4 - 1s - loss: 0.4851 - mse: 0.4593 - val_loss: 0.4324 - val_mse: 0.4324 - lr: 0.0010 - 659ms/epoch - 165ms/step\n",
            "Epoch 130/1000\n",
            "4/4 - 1s - loss: 0.4834 - mse: 0.4578 - val_loss: 0.4320 - val_mse: 0.4320 - lr: 0.0010 - 675ms/epoch - 169ms/step\n",
            "Epoch 131/1000\n",
            "4/4 - 1s - loss: 0.4820 - mse: 0.4564 - val_loss: 0.4318 - val_mse: 0.4318 - lr: 0.0010 - 673ms/epoch - 168ms/step\n",
            "Epoch 132/1000\n",
            "4/4 - 1s - loss: 0.4817 - mse: 0.4559 - val_loss: 0.4318 - val_mse: 0.4318 - lr: 0.0010 - 666ms/epoch - 167ms/step\n",
            "Epoch 133/1000\n",
            "4/4 - 1s - loss: 0.4805 - mse: 0.4549 - val_loss: 0.4317 - val_mse: 0.4317 - lr: 0.0010 - 668ms/epoch - 167ms/step\n",
            "Epoch 134/1000\n",
            "4/4 - 1s - loss: 0.4797 - mse: 0.4540 - val_loss: 0.4312 - val_mse: 0.4312 - lr: 0.0010 - 668ms/epoch - 167ms/step\n",
            "Epoch 135/1000\n",
            "4/4 - 1s - loss: 0.4780 - mse: 0.4524 - val_loss: 0.4307 - val_mse: 0.4307 - lr: 0.0010 - 670ms/epoch - 167ms/step\n",
            "Epoch 136/1000\n",
            "4/4 - 1s - loss: 0.4779 - mse: 0.4524 - val_loss: 0.4308 - val_mse: 0.4308 - lr: 0.0010 - 687ms/epoch - 172ms/step\n",
            "Epoch 137/1000\n",
            "4/4 - 1s - loss: 0.4776 - mse: 0.4522 - val_loss: 0.4308 - val_mse: 0.4308 - lr: 0.0010 - 670ms/epoch - 167ms/step\n",
            "Epoch 138/1000\n",
            "4/4 - 1s - loss: 0.4766 - mse: 0.4512 - val_loss: 0.4302 - val_mse: 0.4302 - lr: 0.0010 - 682ms/epoch - 170ms/step\n",
            "Epoch 139/1000\n",
            "4/4 - 1s - loss: 0.4749 - mse: 0.4497 - val_loss: 0.4297 - val_mse: 0.4297 - lr: 0.0010 - 674ms/epoch - 169ms/step\n",
            "Epoch 140/1000\n",
            "4/4 - 1s - loss: 0.4745 - mse: 0.4492 - val_loss: 0.4287 - val_mse: 0.4287 - lr: 0.0010 - 664ms/epoch - 166ms/step\n",
            "Epoch 141/1000\n",
            "4/4 - 1s - loss: 0.4741 - mse: 0.4489 - val_loss: 0.4284 - val_mse: 0.4284 - lr: 0.0010 - 657ms/epoch - 164ms/step\n",
            "Epoch 142/1000\n",
            "4/4 - 1s - loss: 0.4731 - mse: 0.4479 - val_loss: 0.4281 - val_mse: 0.4281 - lr: 0.0010 - 669ms/epoch - 167ms/step\n",
            "Epoch 143/1000\n",
            "4/4 - 1s - loss: 0.4712 - mse: 0.4460 - val_loss: 0.4280 - val_mse: 0.4280 - lr: 0.0010 - 672ms/epoch - 168ms/step\n",
            "Epoch 144/1000\n",
            "4/4 - 1s - loss: 0.4703 - mse: 0.4453 - val_loss: 0.4277 - val_mse: 0.4277 - lr: 0.0010 - 665ms/epoch - 166ms/step\n",
            "Epoch 145/1000\n",
            "4/4 - 1s - loss: 0.4699 - mse: 0.4449 - val_loss: 0.4275 - val_mse: 0.4275 - lr: 0.0010 - 682ms/epoch - 171ms/step\n",
            "Epoch 146/1000\n",
            "4/4 - 1s - loss: 0.4687 - mse: 0.4436 - val_loss: 0.4271 - val_mse: 0.4271 - lr: 0.0010 - 667ms/epoch - 167ms/step\n",
            "Epoch 147/1000\n",
            "4/4 - 1s - loss: 0.4692 - mse: 0.4441 - val_loss: 0.4270 - val_mse: 0.4270 - lr: 0.0010 - 667ms/epoch - 167ms/step\n",
            "Epoch 148/1000\n",
            "4/4 - 1s - loss: 0.4681 - mse: 0.4431 - val_loss: 0.4268 - val_mse: 0.4268 - lr: 0.0010 - 658ms/epoch - 165ms/step\n",
            "Epoch 149/1000\n",
            "4/4 - 1s - loss: 0.4667 - mse: 0.4418 - val_loss: 0.4261 - val_mse: 0.4261 - lr: 0.0010 - 663ms/epoch - 166ms/step\n",
            "Epoch 150/1000\n",
            "4/4 - 1s - loss: 0.4655 - mse: 0.4407 - val_loss: 0.4256 - val_mse: 0.4256 - lr: 0.0010 - 655ms/epoch - 164ms/step\n",
            "Epoch 151/1000\n",
            "4/4 - 1s - loss: 0.4653 - mse: 0.4405 - val_loss: 0.4253 - val_mse: 0.4253 - lr: 0.0010 - 658ms/epoch - 165ms/step\n",
            "Epoch 152/1000\n",
            "4/4 - 1s - loss: 0.4644 - mse: 0.4396 - val_loss: 0.4247 - val_mse: 0.4247 - lr: 0.0010 - 666ms/epoch - 167ms/step\n",
            "Epoch 153/1000\n",
            "4/4 - 1s - loss: 0.4634 - mse: 0.4388 - val_loss: 0.4245 - val_mse: 0.4245 - lr: 0.0010 - 666ms/epoch - 166ms/step\n",
            "Epoch 154/1000\n",
            "4/4 - 1s - loss: 0.4634 - mse: 0.4387 - val_loss: 0.4247 - val_mse: 0.4247 - lr: 0.0010 - 674ms/epoch - 169ms/step\n",
            "Epoch 155/1000\n",
            "4/4 - 1s - loss: 0.4619 - mse: 0.4373 - val_loss: 0.4249 - val_mse: 0.4249 - lr: 0.0010 - 663ms/epoch - 166ms/step\n",
            "Epoch 156/1000\n",
            "4/4 - 1s - loss: 0.4611 - mse: 0.4367 - val_loss: 0.4248 - val_mse: 0.4248 - lr: 0.0010 - 675ms/epoch - 169ms/step\n",
            "Epoch 157/1000\n",
            "4/4 - 1s - loss: 0.4575 - mse: 0.4330 - val_loss: 0.4246 - val_mse: 0.4246 - lr: 0.0010 - 663ms/epoch - 166ms/step\n",
            "Epoch 158/1000\n",
            "4/4 - 1s - loss: 0.4598 - mse: 0.4354 - val_loss: 0.4240 - val_mse: 0.4240 - lr: 0.0010 - 657ms/epoch - 164ms/step\n",
            "Epoch 159/1000\n",
            "4/4 - 1s - loss: 0.4591 - mse: 0.4346 - val_loss: 0.4234 - val_mse: 0.4234 - lr: 0.0010 - 678ms/epoch - 170ms/step\n",
            "Epoch 160/1000\n",
            "4/4 - 1s - loss: 0.4578 - mse: 0.4334 - val_loss: 0.4229 - val_mse: 0.4229 - lr: 0.0010 - 667ms/epoch - 167ms/step\n",
            "Epoch 161/1000\n",
            "4/4 - 1s - loss: 0.4576 - mse: 0.4331 - val_loss: 0.4226 - val_mse: 0.4226 - lr: 0.0010 - 662ms/epoch - 166ms/step\n",
            "Epoch 162/1000\n",
            "4/4 - 1s - loss: 0.4568 - mse: 0.4325 - val_loss: 0.4225 - val_mse: 0.4225 - lr: 0.0010 - 663ms/epoch - 166ms/step\n",
            "Epoch 163/1000\n",
            "4/4 - 1s - loss: 0.4567 - mse: 0.4323 - val_loss: 0.4222 - val_mse: 0.4222 - lr: 0.0010 - 674ms/epoch - 169ms/step\n",
            "Epoch 164/1000\n",
            "4/4 - 1s - loss: 0.4559 - mse: 0.4315 - val_loss: 0.4221 - val_mse: 0.4221 - lr: 0.0010 - 666ms/epoch - 167ms/step\n",
            "Epoch 165/1000\n",
            "4/4 - 1s - loss: 0.4574 - mse: 0.4329 - val_loss: 0.4216 - val_mse: 0.4216 - lr: 0.0010 - 689ms/epoch - 172ms/step\n",
            "Epoch 166/1000\n",
            "4/4 - 1s - loss: 0.4543 - mse: 0.4300 - val_loss: 0.4212 - val_mse: 0.4212 - lr: 0.0010 - 681ms/epoch - 170ms/step\n",
            "Epoch 167/1000\n",
            "4/4 - 1s - loss: 0.4535 - mse: 0.4292 - val_loss: 0.4213 - val_mse: 0.4213 - lr: 0.0010 - 680ms/epoch - 170ms/step\n",
            "Epoch 168/1000\n",
            "4/4 - 1s - loss: 0.4545 - mse: 0.4302 - val_loss: 0.4214 - val_mse: 0.4214 - lr: 0.0010 - 689ms/epoch - 172ms/step\n",
            "Epoch 169/1000\n",
            "4/4 - 1s - loss: 0.4523 - mse: 0.4282 - val_loss: 0.4210 - val_mse: 0.4210 - lr: 0.0010 - 697ms/epoch - 174ms/step\n",
            "Epoch 170/1000\n",
            "4/4 - 1s - loss: 0.4536 - mse: 0.4294 - val_loss: 0.4206 - val_mse: 0.4206 - lr: 0.0010 - 679ms/epoch - 170ms/step\n",
            "Epoch 171/1000\n",
            "4/4 - 1s - loss: 0.4518 - mse: 0.4277 - val_loss: 0.4202 - val_mse: 0.4202 - lr: 0.0010 - 681ms/epoch - 170ms/step\n",
            "Epoch 172/1000\n",
            "4/4 - 1s - loss: 0.4519 - mse: 0.4277 - val_loss: 0.4202 - val_mse: 0.4202 - lr: 0.0010 - 676ms/epoch - 169ms/step\n",
            "Epoch 173/1000\n",
            "4/4 - 1s - loss: 0.4524 - mse: 0.4282 - val_loss: 0.4203 - val_mse: 0.4203 - lr: 0.0010 - 663ms/epoch - 166ms/step\n",
            "Epoch 174/1000\n",
            "4/4 - 1s - loss: 0.4498 - mse: 0.4257 - val_loss: 0.4203 - val_mse: 0.4203 - lr: 0.0010 - 665ms/epoch - 166ms/step\n",
            "Epoch 175/1000\n",
            "4/4 - 1s - loss: 0.4504 - mse: 0.4262 - val_loss: 0.4199 - val_mse: 0.4199 - lr: 0.0010 - 684ms/epoch - 171ms/step\n",
            "Epoch 176/1000\n",
            "4/4 - 1s - loss: 0.4495 - mse: 0.4256 - val_loss: 0.4193 - val_mse: 0.4193 - lr: 0.0010 - 668ms/epoch - 167ms/step\n",
            "Epoch 177/1000\n",
            "4/4 - 1s - loss: 0.4491 - mse: 0.4251 - val_loss: 0.4183 - val_mse: 0.4183 - lr: 0.0010 - 673ms/epoch - 168ms/step\n",
            "Epoch 178/1000\n",
            "4/4 - 1s - loss: 0.4489 - mse: 0.4249 - val_loss: 0.4183 - val_mse: 0.4183 - lr: 0.0010 - 666ms/epoch - 167ms/step\n",
            "Epoch 179/1000\n",
            "4/4 - 1s - loss: 0.4485 - mse: 0.4244 - val_loss: 0.4185 - val_mse: 0.4185 - lr: 0.0010 - 680ms/epoch - 170ms/step\n",
            "Epoch 180/1000\n",
            "4/4 - 1s - loss: 0.4489 - mse: 0.4250 - val_loss: 0.4191 - val_mse: 0.4191 - lr: 0.0010 - 667ms/epoch - 167ms/step\n",
            "Epoch 181/1000\n",
            "4/4 - 1s - loss: 0.4475 - mse: 0.4236 - val_loss: 0.4192 - val_mse: 0.4192 - lr: 0.0010 - 680ms/epoch - 170ms/step\n",
            "Epoch 182/1000\n",
            "4/4 - 1s - loss: 0.4473 - mse: 0.4235 - val_loss: 0.4188 - val_mse: 0.4188 - lr: 0.0010 - 667ms/epoch - 167ms/step\n",
            "Epoch 183/1000\n",
            "4/4 - 1s - loss: 0.4463 - mse: 0.4225 - val_loss: 0.4181 - val_mse: 0.4181 - lr: 0.0010 - 1s/epoch - 280ms/step\n",
            "Epoch 184/1000\n",
            "4/4 - 1s - loss: 0.4468 - mse: 0.4229 - val_loss: 0.4177 - val_mse: 0.4177 - lr: 0.0010 - 698ms/epoch - 175ms/step\n",
            "Epoch 185/1000\n",
            "4/4 - 1s - loss: 0.4458 - mse: 0.4221 - val_loss: 0.4174 - val_mse: 0.4174 - lr: 0.0010 - 701ms/epoch - 175ms/step\n",
            "Epoch 186/1000\n",
            "4/4 - 1s - loss: 0.4460 - mse: 0.4222 - val_loss: 0.4174 - val_mse: 0.4174 - lr: 0.0010 - 678ms/epoch - 169ms/step\n",
            "Epoch 187/1000\n",
            "4/4 - 1s - loss: 0.4447 - mse: 0.4211 - val_loss: 0.4174 - val_mse: 0.4174 - lr: 0.0010 - 689ms/epoch - 172ms/step\n",
            "Epoch 188/1000\n",
            "4/4 - 1s - loss: 0.4443 - mse: 0.4205 - val_loss: 0.4175 - val_mse: 0.4175 - lr: 0.0010 - 696ms/epoch - 174ms/step\n",
            "Epoch 189/1000\n",
            "4/4 - 1s - loss: 0.4436 - mse: 0.4199 - val_loss: 0.4173 - val_mse: 0.4173 - lr: 0.0010 - 654ms/epoch - 163ms/step\n",
            "Epoch 190/1000\n",
            "4/4 - 1s - loss: 0.4437 - mse: 0.4200 - val_loss: 0.4172 - val_mse: 0.4172 - lr: 0.0010 - 676ms/epoch - 169ms/step\n",
            "Epoch 191/1000\n",
            "4/4 - 1s - loss: 0.4432 - mse: 0.4195 - val_loss: 0.4173 - val_mse: 0.4173 - lr: 0.0010 - 676ms/epoch - 169ms/step\n",
            "Epoch 192/1000\n",
            "4/4 - 1s - loss: 0.4426 - mse: 0.4190 - val_loss: 0.4170 - val_mse: 0.4170 - lr: 0.0010 - 657ms/epoch - 164ms/step\n",
            "Epoch 193/1000\n",
            "4/4 - 1s - loss: 0.4427 - mse: 0.4190 - val_loss: 0.4168 - val_mse: 0.4168 - lr: 0.0010 - 671ms/epoch - 168ms/step\n",
            "Epoch 194/1000\n",
            "4/4 - 1s - loss: 0.4428 - mse: 0.4191 - val_loss: 0.4168 - val_mse: 0.4168 - lr: 0.0010 - 687ms/epoch - 172ms/step\n",
            "Epoch 195/1000\n",
            "4/4 - 1s - loss: 0.4418 - mse: 0.4183 - val_loss: 0.4166 - val_mse: 0.4166 - lr: 0.0010 - 681ms/epoch - 170ms/step\n",
            "Epoch 196/1000\n",
            "4/4 - 1s - loss: 0.4419 - mse: 0.4182 - val_loss: 0.4164 - val_mse: 0.4164 - lr: 0.0010 - 669ms/epoch - 167ms/step\n",
            "Epoch 197/1000\n",
            "4/4 - 1s - loss: 0.4410 - mse: 0.4175 - val_loss: 0.4162 - val_mse: 0.4162 - lr: 0.0010 - 668ms/epoch - 167ms/step\n",
            "Epoch 198/1000\n",
            "4/4 - 1s - loss: 0.4411 - mse: 0.4177 - val_loss: 0.4162 - val_mse: 0.4162 - lr: 0.0010 - 679ms/epoch - 170ms/step\n",
            "Epoch 199/1000\n",
            "4/4 - 1s - loss: 0.4398 - mse: 0.4164 - val_loss: 0.4161 - val_mse: 0.4161 - lr: 0.0010 - 699ms/epoch - 175ms/step\n",
            "Epoch 200/1000\n",
            "4/4 - 1s - loss: 0.4415 - mse: 0.4180 - val_loss: 0.4159 - val_mse: 0.4159 - lr: 0.0010 - 673ms/epoch - 168ms/step\n",
            "Epoch 201/1000\n",
            "4/4 - 1s - loss: 0.4406 - mse: 0.4171 - val_loss: 0.4158 - val_mse: 0.4158 - lr: 0.0010 - 669ms/epoch - 167ms/step\n",
            "Epoch 202/1000\n",
            "4/4 - 1s - loss: 0.4399 - mse: 0.4164 - val_loss: 0.4157 - val_mse: 0.4157 - lr: 0.0010 - 677ms/epoch - 169ms/step\n",
            "Epoch 203/1000\n",
            "4/4 - 1s - loss: 0.4398 - mse: 0.4163 - val_loss: 0.4162 - val_mse: 0.4162 - lr: 0.0010 - 685ms/epoch - 171ms/step\n",
            "Epoch 204/1000\n",
            "4/4 - 1s - loss: 0.4392 - mse: 0.4158 - val_loss: 0.4158 - val_mse: 0.4158 - lr: 0.0010 - 690ms/epoch - 173ms/step\n",
            "Epoch 205/1000\n",
            "4/4 - 1s - loss: 0.4394 - mse: 0.4159 - val_loss: 0.4157 - val_mse: 0.4157 - lr: 0.0010 - 684ms/epoch - 171ms/step\n",
            "Epoch 206/1000\n",
            "4/4 - 1s - loss: 0.4388 - mse: 0.4154 - val_loss: 0.4154 - val_mse: 0.4154 - lr: 0.0010 - 661ms/epoch - 165ms/step\n",
            "Epoch 207/1000\n",
            "4/4 - 1s - loss: 0.4386 - mse: 0.4152 - val_loss: 0.4153 - val_mse: 0.4153 - lr: 0.0010 - 652ms/epoch - 163ms/step\n",
            "Epoch 208/1000\n",
            "4/4 - 1s - loss: 0.4390 - mse: 0.4154 - val_loss: 0.4152 - val_mse: 0.4152 - lr: 0.0010 - 690ms/epoch - 173ms/step\n",
            "Epoch 209/1000\n",
            "4/4 - 1s - loss: 0.4375 - mse: 0.4142 - val_loss: 0.4155 - val_mse: 0.4155 - lr: 0.0010 - 673ms/epoch - 168ms/step\n",
            "Epoch 210/1000\n",
            "4/4 - 1s - loss: 0.4386 - mse: 0.4150 - val_loss: 0.4152 - val_mse: 0.4152 - lr: 0.0010 - 677ms/epoch - 169ms/step\n",
            "Epoch 211/1000\n",
            "4/4 - 1s - loss: 0.4385 - mse: 0.4150 - val_loss: 0.4149 - val_mse: 0.4149 - lr: 0.0010 - 684ms/epoch - 171ms/step\n",
            "Epoch 212/1000\n",
            "4/4 - 1s - loss: 0.4368 - mse: 0.4135 - val_loss: 0.4149 - val_mse: 0.4149 - lr: 0.0010 - 676ms/epoch - 169ms/step\n",
            "Epoch 213/1000\n",
            "4/4 - 1s - loss: 0.4369 - mse: 0.4136 - val_loss: 0.4149 - val_mse: 0.4149 - lr: 0.0010 - 696ms/epoch - 174ms/step\n",
            "Epoch 214/1000\n",
            "4/4 - 1s - loss: 0.4367 - mse: 0.4133 - val_loss: 0.4149 - val_mse: 0.4149 - lr: 0.0010 - 684ms/epoch - 171ms/step\n",
            "Epoch 215/1000\n",
            "4/4 - 1s - loss: 0.4358 - mse: 0.4125 - val_loss: 0.4146 - val_mse: 0.4146 - lr: 0.0010 - 681ms/epoch - 170ms/step\n",
            "Epoch 216/1000\n",
            "4/4 - 1s - loss: 0.4364 - mse: 0.4131 - val_loss: 0.4142 - val_mse: 0.4142 - lr: 0.0010 - 704ms/epoch - 176ms/step\n",
            "Epoch 217/1000\n",
            "4/4 - 1s - loss: 0.4362 - mse: 0.4128 - val_loss: 0.4141 - val_mse: 0.4141 - lr: 0.0010 - 687ms/epoch - 172ms/step\n",
            "Epoch 218/1000\n",
            "4/4 - 1s - loss: 0.4360 - mse: 0.4127 - val_loss: 0.4142 - val_mse: 0.4142 - lr: 0.0010 - 673ms/epoch - 168ms/step\n",
            "Epoch 219/1000\n",
            "4/4 - 1s - loss: 0.4366 - mse: 0.4133 - val_loss: 0.4143 - val_mse: 0.4143 - lr: 0.0010 - 675ms/epoch - 169ms/step\n",
            "Epoch 220/1000\n",
            "4/4 - 1s - loss: 0.4360 - mse: 0.4127 - val_loss: 0.4142 - val_mse: 0.4142 - lr: 0.0010 - 699ms/epoch - 175ms/step\n",
            "Epoch 221/1000\n",
            "4/4 - 1s - loss: 0.4347 - mse: 0.4115 - val_loss: 0.4141 - val_mse: 0.4141 - lr: 0.0010 - 691ms/epoch - 173ms/step\n",
            "Epoch 222/1000\n",
            "4/4 - 1s - loss: 0.4353 - mse: 0.4120 - val_loss: 0.4140 - val_mse: 0.4140 - lr: 0.0010 - 683ms/epoch - 171ms/step\n",
            "Epoch 223/1000\n",
            "4/4 - 1s - loss: 0.4339 - mse: 0.4107 - val_loss: 0.4139 - val_mse: 0.4139 - lr: 0.0010 - 681ms/epoch - 170ms/step\n",
            "Epoch 224/1000\n",
            "4/4 - 1s - loss: 0.4339 - mse: 0.4108 - val_loss: 0.4139 - val_mse: 0.4139 - lr: 0.0010 - 684ms/epoch - 171ms/step\n",
            "Epoch 225/1000\n",
            "4/4 - 1s - loss: 0.4345 - mse: 0.4113 - val_loss: 0.4138 - val_mse: 0.4138 - lr: 0.0010 - 688ms/epoch - 172ms/step\n",
            "Epoch 226/1000\n",
            "4/4 - 1s - loss: 0.4329 - mse: 0.4099 - val_loss: 0.4136 - val_mse: 0.4136 - lr: 0.0010 - 687ms/epoch - 172ms/step\n",
            "Epoch 227/1000\n",
            "4/4 - 1s - loss: 0.4342 - mse: 0.4110 - val_loss: 0.4133 - val_mse: 0.4133 - lr: 0.0010 - 685ms/epoch - 171ms/step\n",
            "Epoch 228/1000\n",
            "4/4 - 1s - loss: 0.4336 - mse: 0.4104 - val_loss: 0.4132 - val_mse: 0.4132 - lr: 0.0010 - 700ms/epoch - 175ms/step\n",
            "Epoch 229/1000\n",
            "4/4 - 1s - loss: 0.4336 - mse: 0.4105 - val_loss: 0.4136 - val_mse: 0.4136 - lr: 0.0010 - 665ms/epoch - 166ms/step\n",
            "Epoch 230/1000\n",
            "4/4 - 1s - loss: 0.4335 - mse: 0.4104 - val_loss: 0.4138 - val_mse: 0.4138 - lr: 0.0010 - 683ms/epoch - 171ms/step\n",
            "Epoch 231/1000\n",
            "4/4 - 1s - loss: 0.4332 - mse: 0.4101 - val_loss: 0.4134 - val_mse: 0.4134 - lr: 0.0010 - 684ms/epoch - 171ms/step\n",
            "Epoch 232/1000\n",
            "4/4 - 1s - loss: 0.4329 - mse: 0.4099 - val_loss: 0.4130 - val_mse: 0.4130 - lr: 0.0010 - 685ms/epoch - 171ms/step\n",
            "Epoch 233/1000\n",
            "4/4 - 1s - loss: 0.4332 - mse: 0.4100 - val_loss: 0.4128 - val_mse: 0.4128 - lr: 0.0010 - 693ms/epoch - 173ms/step\n",
            "Epoch 234/1000\n",
            "4/4 - 1s - loss: 0.4326 - mse: 0.4095 - val_loss: 0.4128 - val_mse: 0.4128 - lr: 0.0010 - 693ms/epoch - 173ms/step\n",
            "Epoch 235/1000\n",
            "4/4 - 1s - loss: 0.4323 - mse: 0.4092 - val_loss: 0.4129 - val_mse: 0.4129 - lr: 0.0010 - 700ms/epoch - 175ms/step\n",
            "Epoch 236/1000\n",
            "4/4 - 1s - loss: 0.4324 - mse: 0.4092 - val_loss: 0.4132 - val_mse: 0.4132 - lr: 0.0010 - 673ms/epoch - 168ms/step\n",
            "Epoch 237/1000\n",
            "4/4 - 1s - loss: 0.4322 - mse: 0.4091 - val_loss: 0.4129 - val_mse: 0.4129 - lr: 0.0010 - 674ms/epoch - 168ms/step\n",
            "Epoch 238/1000\n",
            "4/4 - 1s - loss: 0.4322 - mse: 0.4092 - val_loss: 0.4124 - val_mse: 0.4124 - lr: 0.0010 - 675ms/epoch - 169ms/step\n",
            "Epoch 239/1000\n",
            "4/4 - 1s - loss: 0.4312 - mse: 0.4081 - val_loss: 0.4123 - val_mse: 0.4123 - lr: 0.0010 - 665ms/epoch - 166ms/step\n",
            "Epoch 240/1000\n",
            "4/4 - 1s - loss: 0.4323 - mse: 0.4092 - val_loss: 0.4122 - val_mse: 0.4122 - lr: 0.0010 - 663ms/epoch - 166ms/step\n",
            "Epoch 241/1000\n",
            "4/4 - 1s - loss: 0.4316 - mse: 0.4086 - val_loss: 0.4125 - val_mse: 0.4125 - lr: 0.0010 - 658ms/epoch - 165ms/step\n",
            "Epoch 242/1000\n",
            "4/4 - 1s - loss: 0.4312 - mse: 0.4083 - val_loss: 0.4126 - val_mse: 0.4126 - lr: 0.0010 - 674ms/epoch - 169ms/step\n",
            "Epoch 243/1000\n",
            "4/4 - 1s - loss: 0.4314 - mse: 0.4084 - val_loss: 0.4123 - val_mse: 0.4123 - lr: 0.0010 - 665ms/epoch - 166ms/step\n",
            "Epoch 244/1000\n",
            "4/4 - 1s - loss: 0.4305 - mse: 0.4076 - val_loss: 0.4120 - val_mse: 0.4120 - lr: 0.0010 - 661ms/epoch - 165ms/step\n",
            "Epoch 245/1000\n",
            "4/4 - 1s - loss: 0.4317 - mse: 0.4086 - val_loss: 0.4122 - val_mse: 0.4122 - lr: 0.0010 - 674ms/epoch - 169ms/step\n",
            "Epoch 246/1000\n",
            "4/4 - 1s - loss: 0.4310 - mse: 0.4080 - val_loss: 0.4123 - val_mse: 0.4123 - lr: 0.0010 - 662ms/epoch - 165ms/step\n",
            "Epoch 247/1000\n",
            "4/4 - 1s - loss: 0.4299 - mse: 0.4069 - val_loss: 0.4126 - val_mse: 0.4126 - lr: 0.0010 - 665ms/epoch - 166ms/step\n",
            "Epoch 248/1000\n",
            "4/4 - 1s - loss: 0.4297 - mse: 0.4068 - val_loss: 0.4123 - val_mse: 0.4123 - lr: 0.0010 - 689ms/epoch - 172ms/step\n",
            "Epoch 249/1000\n",
            "4/4 - 1s - loss: 0.4303 - mse: 0.4073 - val_loss: 0.4119 - val_mse: 0.4119 - lr: 0.0010 - 663ms/epoch - 166ms/step\n",
            "Epoch 250/1000\n",
            "4/4 - 1s - loss: 0.4301 - mse: 0.4070 - val_loss: 0.4116 - val_mse: 0.4116 - lr: 0.0010 - 665ms/epoch - 166ms/step\n",
            "Epoch 251/1000\n",
            "4/4 - 1s - loss: 0.4301 - mse: 0.4072 - val_loss: 0.4114 - val_mse: 0.4114 - lr: 0.0010 - 690ms/epoch - 172ms/step\n",
            "Epoch 252/1000\n",
            "4/4 - 1s - loss: 0.4300 - mse: 0.4071 - val_loss: 0.4116 - val_mse: 0.4116 - lr: 0.0010 - 668ms/epoch - 167ms/step\n",
            "Epoch 253/1000\n",
            "4/4 - 1s - loss: 0.4303 - mse: 0.4074 - val_loss: 0.4118 - val_mse: 0.4118 - lr: 0.0010 - 711ms/epoch - 178ms/step\n",
            "Epoch 254/1000\n",
            "4/4 - 1s - loss: 0.4296 - mse: 0.4066 - val_loss: 0.4114 - val_mse: 0.4114 - lr: 0.0010 - 680ms/epoch - 170ms/step\n",
            "Epoch 255/1000\n",
            "4/4 - 1s - loss: 0.4291 - mse: 0.4062 - val_loss: 0.4115 - val_mse: 0.4115 - lr: 0.0010 - 689ms/epoch - 172ms/step\n",
            "Epoch 256/1000\n",
            "4/4 - 1s - loss: 0.4302 - mse: 0.4072 - val_loss: 0.4118 - val_mse: 0.4118 - lr: 0.0010 - 682ms/epoch - 171ms/step\n",
            "Epoch 257/1000\n",
            "4/4 - 1s - loss: 0.4294 - mse: 0.4064 - val_loss: 0.4120 - val_mse: 0.4120 - lr: 0.0010 - 682ms/epoch - 170ms/step\n",
            "Epoch 258/1000\n",
            "\n",
            "Epoch 258: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "4/4 - 1s - loss: 0.4290 - mse: 0.4061 - val_loss: 0.4116 - val_mse: 0.4116 - lr: 0.0010 - 661ms/epoch - 165ms/step\n",
            "Epoch 259/1000\n",
            "4/4 - 1s - loss: 0.4290 - mse: 0.4062 - val_loss: 0.4115 - val_mse: 0.4115 - lr: 1.0000e-04 - 682ms/epoch - 171ms/step\n",
            "Epoch 260/1000\n",
            "4/4 - 1s - loss: 0.4290 - mse: 0.4062 - val_loss: 0.4114 - val_mse: 0.4114 - lr: 1.0000e-04 - 677ms/epoch - 169ms/step\n",
            "Epoch 261/1000\n",
            "4/4 - 1s - loss: 0.4295 - mse: 0.4066 - val_loss: 0.4112 - val_mse: 0.4112 - lr: 1.0000e-04 - 670ms/epoch - 167ms/step\n",
            "Epoch 262/1000\n",
            "4/4 - 1s - loss: 0.4292 - mse: 0.4063 - val_loss: 0.4111 - val_mse: 0.4111 - lr: 1.0000e-04 - 685ms/epoch - 171ms/step\n",
            "Epoch 263/1000\n",
            "4/4 - 1s - loss: 0.4289 - mse: 0.4061 - val_loss: 0.4111 - val_mse: 0.4111 - lr: 1.0000e-04 - 674ms/epoch - 169ms/step\n",
            "Epoch 264/1000\n",
            "4/4 - 1s - loss: 0.4289 - mse: 0.4060 - val_loss: 0.4110 - val_mse: 0.4110 - lr: 1.0000e-04 - 691ms/epoch - 173ms/step\n",
            "Epoch 265/1000\n",
            "4/4 - 1s - loss: 0.4291 - mse: 0.4062 - val_loss: 0.4108 - val_mse: 0.4108 - lr: 1.0000e-04 - 674ms/epoch - 169ms/step\n",
            "Epoch 266/1000\n",
            "4/4 - 1s - loss: 0.4289 - mse: 0.4059 - val_loss: 0.4107 - val_mse: 0.4107 - lr: 1.0000e-04 - 670ms/epoch - 168ms/step\n",
            "Epoch 267/1000\n",
            "4/4 - 1s - loss: 0.4297 - mse: 0.4068 - val_loss: 0.4106 - val_mse: 0.4106 - lr: 1.0000e-04 - 664ms/epoch - 166ms/step\n",
            "Epoch 268/1000\n",
            "4/4 - 1s - loss: 0.4287 - mse: 0.4058 - val_loss: 0.4105 - val_mse: 0.4105 - lr: 1.0000e-04 - 673ms/epoch - 168ms/step\n",
            "Epoch 269/1000\n",
            "4/4 - 1s - loss: 0.4289 - mse: 0.4060 - val_loss: 0.4104 - val_mse: 0.4104 - lr: 1.0000e-04 - 681ms/epoch - 170ms/step\n",
            "Epoch 270/1000\n",
            "4/4 - 1s - loss: 0.4293 - mse: 0.4064 - val_loss: 0.4103 - val_mse: 0.4103 - lr: 1.0000e-04 - 660ms/epoch - 165ms/step\n",
            "Epoch 271/1000\n",
            "4/4 - 1s - loss: 0.4290 - mse: 0.4061 - val_loss: 0.4102 - val_mse: 0.4102 - lr: 1.0000e-04 - 668ms/epoch - 167ms/step\n",
            "Epoch 272/1000\n",
            "4/4 - 1s - loss: 0.4288 - mse: 0.4059 - val_loss: 0.4101 - val_mse: 0.4101 - lr: 1.0000e-04 - 693ms/epoch - 173ms/step\n",
            "Epoch 273/1000\n",
            "4/4 - 1s - loss: 0.4300 - mse: 0.4070 - val_loss: 0.4100 - val_mse: 0.4100 - lr: 1.0000e-04 - 663ms/epoch - 166ms/step\n",
            "Epoch 274/1000\n",
            "4/4 - 1s - loss: 0.4288 - mse: 0.4059 - val_loss: 0.4099 - val_mse: 0.4099 - lr: 1.0000e-04 - 674ms/epoch - 168ms/step\n",
            "Epoch 275/1000\n",
            "4/4 - 1s - loss: 0.4282 - mse: 0.4054 - val_loss: 0.4099 - val_mse: 0.4099 - lr: 1.0000e-04 - 682ms/epoch - 171ms/step\n",
            "Epoch 276/1000\n",
            "4/4 - 1s - loss: 0.4289 - mse: 0.4060 - val_loss: 0.4098 - val_mse: 0.4098 - lr: 1.0000e-04 - 670ms/epoch - 168ms/step\n",
            "Epoch 277/1000\n",
            "4/4 - 1s - loss: 0.4290 - mse: 0.4061 - val_loss: 0.4098 - val_mse: 0.4098 - lr: 1.0000e-04 - 686ms/epoch - 172ms/step\n",
            "Epoch 278/1000\n",
            "4/4 - 1s - loss: 0.4291 - mse: 0.4062 - val_loss: 0.4097 - val_mse: 0.4097 - lr: 1.0000e-04 - 677ms/epoch - 169ms/step\n",
            "Epoch 279/1000\n",
            "4/4 - 1s - loss: 0.4291 - mse: 0.4062 - val_loss: 0.4097 - val_mse: 0.4097 - lr: 1.0000e-04 - 671ms/epoch - 168ms/step\n",
            "Epoch 280/1000\n",
            "4/4 - 1s - loss: 0.4284 - mse: 0.4057 - val_loss: 0.4096 - val_mse: 0.4096 - lr: 1.0000e-04 - 667ms/epoch - 167ms/step\n",
            "Epoch 281/1000\n",
            "4/4 - 1s - loss: 0.4287 - mse: 0.4058 - val_loss: 0.4096 - val_mse: 0.4096 - lr: 1.0000e-04 - 661ms/epoch - 165ms/step\n",
            "Epoch 282/1000\n",
            "4/4 - 1s - loss: 0.4288 - mse: 0.4060 - val_loss: 0.4095 - val_mse: 0.4095 - lr: 1.0000e-04 - 670ms/epoch - 167ms/step\n",
            "Epoch 283/1000\n",
            "4/4 - 1s - loss: 0.4288 - mse: 0.4059 - val_loss: 0.4094 - val_mse: 0.4094 - lr: 1.0000e-04 - 673ms/epoch - 168ms/step\n",
            "Epoch 284/1000\n",
            "4/4 - 1s - loss: 0.4300 - mse: 0.4070 - val_loss: 0.4094 - val_mse: 0.4094 - lr: 1.0000e-04 - 680ms/epoch - 170ms/step\n",
            "Epoch 285/1000\n",
            "4/4 - 1s - loss: 0.4288 - mse: 0.4059 - val_loss: 0.4093 - val_mse: 0.4093 - lr: 1.0000e-04 - 654ms/epoch - 164ms/step\n",
            "Epoch 286/1000\n",
            "4/4 - 1s - loss: 0.4291 - mse: 0.4062 - val_loss: 0.4093 - val_mse: 0.4093 - lr: 1.0000e-04 - 685ms/epoch - 171ms/step\n",
            "Epoch 287/1000\n",
            "4/4 - 1s - loss: 0.4282 - mse: 0.4054 - val_loss: 0.4092 - val_mse: 0.4092 - lr: 1.0000e-04 - 685ms/epoch - 171ms/step\n",
            "Epoch 288/1000\n",
            "4/4 - 1s - loss: 0.4289 - mse: 0.4060 - val_loss: 0.4092 - val_mse: 0.4092 - lr: 1.0000e-04 - 668ms/epoch - 167ms/step\n",
            "Epoch 289/1000\n",
            "4/4 - 1s - loss: 0.4290 - mse: 0.4061 - val_loss: 0.4092 - val_mse: 0.4092 - lr: 1.0000e-04 - 683ms/epoch - 171ms/step\n",
            "Epoch 290/1000\n",
            "4/4 - 1s - loss: 0.4288 - mse: 0.4059 - val_loss: 0.4092 - val_mse: 0.4092 - lr: 1.0000e-04 - 664ms/epoch - 166ms/step\n",
            "Epoch 291/1000\n",
            "4/4 - 1s - loss: 0.4280 - mse: 0.4052 - val_loss: 0.4092 - val_mse: 0.4092 - lr: 1.0000e-04 - 701ms/epoch - 175ms/step\n",
            "Epoch 292/1000\n",
            "4/4 - 1s - loss: 0.4287 - mse: 0.4058 - val_loss: 0.4091 - val_mse: 0.4091 - lr: 1.0000e-04 - 698ms/epoch - 174ms/step\n",
            "Epoch 293/1000\n",
            "4/4 - 1s - loss: 0.4283 - mse: 0.4055 - val_loss: 0.4091 - val_mse: 0.4091 - lr: 1.0000e-04 - 698ms/epoch - 174ms/step\n",
            "Epoch 294/1000\n",
            "4/4 - 1s - loss: 0.4286 - mse: 0.4057 - val_loss: 0.4090 - val_mse: 0.4090 - lr: 1.0000e-04 - 683ms/epoch - 171ms/step\n",
            "Epoch 295/1000\n",
            "4/4 - 1s - loss: 0.4283 - mse: 0.4054 - val_loss: 0.4090 - val_mse: 0.4090 - lr: 1.0000e-04 - 682ms/epoch - 170ms/step\n",
            "Epoch 296/1000\n",
            "4/4 - 1s - loss: 0.4286 - mse: 0.4058 - val_loss: 0.4089 - val_mse: 0.4089 - lr: 1.0000e-04 - 692ms/epoch - 173ms/step\n",
            "Epoch 297/1000\n",
            "4/4 - 1s - loss: 0.4286 - mse: 0.4058 - val_loss: 0.4089 - val_mse: 0.4089 - lr: 1.0000e-04 - 695ms/epoch - 174ms/step\n",
            "Epoch 298/1000\n",
            "4/4 - 1s - loss: 0.4290 - mse: 0.4061 - val_loss: 0.4090 - val_mse: 0.4090 - lr: 1.0000e-04 - 716ms/epoch - 179ms/step\n",
            "Epoch 299/1000\n",
            "4/4 - 1s - loss: 0.4289 - mse: 0.4061 - val_loss: 0.4090 - val_mse: 0.4090 - lr: 1.0000e-04 - 698ms/epoch - 175ms/step\n",
            "Epoch 300/1000\n",
            "4/4 - 1s - loss: 0.4293 - mse: 0.4065 - val_loss: 0.4090 - val_mse: 0.4090 - lr: 1.0000e-04 - 688ms/epoch - 172ms/step\n",
            "Epoch 301/1000\n",
            "\n",
            "Epoch 301: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
            "4/4 - 1s - loss: 0.4290 - mse: 0.4061 - val_loss: 0.4089 - val_mse: 0.4089 - lr: 1.0000e-04 - 663ms/epoch - 166ms/step\n",
            "Epoch 302/1000\n",
            "4/4 - 1s - loss: 0.4295 - mse: 0.4065 - val_loss: 0.4089 - val_mse: 0.4089 - lr: 1.0000e-05 - 678ms/epoch - 170ms/step\n",
            "Epoch 303/1000\n",
            "4/4 - 1s - loss: 0.4286 - mse: 0.4057 - val_loss: 0.4089 - val_mse: 0.4089 - lr: 1.0000e-05 - 668ms/epoch - 167ms/step\n",
            "Epoch 304/1000\n",
            "4/4 - 1s - loss: 0.4288 - mse: 0.4060 - val_loss: 0.4089 - val_mse: 0.4089 - lr: 1.0000e-05 - 682ms/epoch - 171ms/step\n",
            "Epoch 305/1000\n",
            "4/4 - 1s - loss: 0.4285 - mse: 0.4056 - val_loss: 0.4088 - val_mse: 0.4088 - lr: 1.0000e-05 - 687ms/epoch - 172ms/step\n",
            "Epoch 306/1000\n",
            "4/4 - 1s - loss: 0.4291 - mse: 0.4062 - val_loss: 0.4088 - val_mse: 0.4088 - lr: 1.0000e-05 - 678ms/epoch - 169ms/step\n",
            "Epoch 307/1000\n",
            "4/4 - 1s - loss: 0.4290 - mse: 0.4061 - val_loss: 0.4088 - val_mse: 0.4088 - lr: 1.0000e-05 - 691ms/epoch - 173ms/step\n",
            "Epoch 308/1000\n",
            "4/4 - 1s - loss: 0.4282 - mse: 0.4053 - val_loss: 0.4088 - val_mse: 0.4088 - lr: 1.0000e-05 - 690ms/epoch - 173ms/step\n",
            "Epoch 309/1000\n",
            "4/4 - 1s - loss: 0.4286 - mse: 0.4057 - val_loss: 0.4087 - val_mse: 0.4087 - lr: 1.0000e-05 - 687ms/epoch - 172ms/step\n",
            "Epoch 310/1000\n",
            "4/4 - 1s - loss: 0.4287 - mse: 0.4058 - val_loss: 0.4087 - val_mse: 0.4087 - lr: 1.0000e-05 - 691ms/epoch - 173ms/step\n",
            "Epoch 311/1000\n",
            "4/4 - 1s - loss: 0.4280 - mse: 0.4051 - val_loss: 0.4087 - val_mse: 0.4087 - lr: 1.0000e-05 - 685ms/epoch - 171ms/step\n",
            "Epoch 312/1000\n",
            "4/4 - 1s - loss: 0.4288 - mse: 0.4059 - val_loss: 0.4087 - val_mse: 0.4087 - lr: 1.0000e-05 - 687ms/epoch - 172ms/step\n",
            "Epoch 313/1000\n",
            "4/4 - 1s - loss: 0.4279 - mse: 0.4051 - val_loss: 0.4087 - val_mse: 0.4087 - lr: 1.0000e-05 - 704ms/epoch - 176ms/step\n",
            "Epoch 314/1000\n",
            "4/4 - 1s - loss: 0.4290 - mse: 0.4061 - val_loss: 0.4086 - val_mse: 0.4086 - lr: 1.0000e-05 - 700ms/epoch - 175ms/step\n",
            "Epoch 315/1000\n",
            "4/4 - 1s - loss: 0.4286 - mse: 0.4057 - val_loss: 0.4086 - val_mse: 0.4086 - lr: 1.0000e-05 - 685ms/epoch - 171ms/step\n",
            "Epoch 316/1000\n",
            "4/4 - 1s - loss: 0.4281 - mse: 0.4054 - val_loss: 0.4086 - val_mse: 0.4086 - lr: 1.0000e-05 - 686ms/epoch - 171ms/step\n",
            "Epoch 317/1000\n",
            "4/4 - 1s - loss: 0.4286 - mse: 0.4057 - val_loss: 0.4086 - val_mse: 0.4086 - lr: 1.0000e-05 - 677ms/epoch - 169ms/step\n",
            "Epoch 318/1000\n",
            "4/4 - 1s - loss: 0.4281 - mse: 0.4053 - val_loss: 0.4086 - val_mse: 0.4086 - lr: 1.0000e-05 - 670ms/epoch - 168ms/step\n",
            "Epoch 319/1000\n",
            "4/4 - 1s - loss: 0.4279 - mse: 0.4051 - val_loss: 0.4086 - val_mse: 0.4086 - lr: 1.0000e-05 - 668ms/epoch - 167ms/step\n",
            "Epoch 320/1000\n",
            "4/4 - 1s - loss: 0.4284 - mse: 0.4055 - val_loss: 0.4085 - val_mse: 0.4085 - lr: 1.0000e-05 - 681ms/epoch - 170ms/step\n",
            "Epoch 321/1000\n",
            "4/4 - 1s - loss: 0.4279 - mse: 0.4050 - val_loss: 0.4085 - val_mse: 0.4085 - lr: 1.0000e-05 - 673ms/epoch - 168ms/step\n",
            "Epoch 322/1000\n",
            "4/4 - 1s - loss: 0.4291 - mse: 0.4062 - val_loss: 0.4085 - val_mse: 0.4085 - lr: 1.0000e-05 - 685ms/epoch - 171ms/step\n",
            "Epoch 323/1000\n",
            "4/4 - 1s - loss: 0.4287 - mse: 0.4058 - val_loss: 0.4085 - val_mse: 0.4085 - lr: 1.0000e-05 - 693ms/epoch - 173ms/step\n",
            "Epoch 324/1000\n",
            "4/4 - 1s - loss: 0.4283 - mse: 0.4055 - val_loss: 0.4085 - val_mse: 0.4085 - lr: 1.0000e-05 - 674ms/epoch - 169ms/step\n",
            "Epoch 325/1000\n",
            "4/4 - 1s - loss: 0.4291 - mse: 0.4062 - val_loss: 0.4085 - val_mse: 0.4085 - lr: 1.0000e-05 - 676ms/epoch - 169ms/step\n",
            "Epoch 326/1000\n",
            "4/4 - 1s - loss: 0.4286 - mse: 0.4057 - val_loss: 0.4085 - val_mse: 0.4085 - lr: 1.0000e-05 - 675ms/epoch - 169ms/step\n",
            "Epoch 327/1000\n",
            "4/4 - 1s - loss: 0.4284 - mse: 0.4056 - val_loss: 0.4085 - val_mse: 0.4085 - lr: 1.0000e-05 - 685ms/epoch - 171ms/step\n",
            "Epoch 328/1000\n",
            "4/4 - 1s - loss: 0.4278 - mse: 0.4051 - val_loss: 0.4084 - val_mse: 0.4084 - lr: 1.0000e-05 - 682ms/epoch - 170ms/step\n",
            "Epoch 329/1000\n",
            "4/4 - 1s - loss: 0.4287 - mse: 0.4058 - val_loss: 0.4084 - val_mse: 0.4084 - lr: 1.0000e-05 - 672ms/epoch - 168ms/step\n",
            "Epoch 330/1000\n",
            "4/4 - 1s - loss: 0.4282 - mse: 0.4053 - val_loss: 0.4084 - val_mse: 0.4084 - lr: 1.0000e-05 - 677ms/epoch - 169ms/step\n",
            "Epoch 331/1000\n",
            "4/4 - 1s - loss: 0.4288 - mse: 0.4059 - val_loss: 0.4084 - val_mse: 0.4084 - lr: 1.0000e-05 - 658ms/epoch - 164ms/step\n",
            "Epoch 332/1000\n",
            "\n",
            "Epoch 332: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
            "4/4 - 1s - loss: 0.4282 - mse: 0.4054 - val_loss: 0.4084 - val_mse: 0.4084 - lr: 1.0000e-05 - 671ms/epoch - 168ms/step\n",
            "Epoch 333/1000\n",
            "4/4 - 1s - loss: 0.4286 - mse: 0.4057 - val_loss: 0.4084 - val_mse: 0.4084 - lr: 1.0000e-06 - 665ms/epoch - 166ms/step\n",
            "Epoch 334/1000\n",
            "4/4 - 1s - loss: 0.4279 - mse: 0.4051 - val_loss: 0.4084 - val_mse: 0.4084 - lr: 1.0000e-06 - 660ms/epoch - 165ms/step\n",
            "Epoch 335/1000\n",
            "4/4 - 1s - loss: 0.4285 - mse: 0.4057 - val_loss: 0.4084 - val_mse: 0.4084 - lr: 1.0000e-06 - 667ms/epoch - 167ms/step\n",
            "Epoch 336/1000\n",
            "4/4 - 1s - loss: 0.4281 - mse: 0.4053 - val_loss: 0.4084 - val_mse: 0.4084 - lr: 1.0000e-06 - 675ms/epoch - 169ms/step\n",
            "Epoch 337/1000\n",
            "4/4 - 1s - loss: 0.4288 - mse: 0.4059 - val_loss: 0.4084 - val_mse: 0.4084 - lr: 1.0000e-06 - 675ms/epoch - 169ms/step\n",
            "Epoch 338/1000\n",
            "4/4 - 1s - loss: 0.4292 - mse: 0.4062 - val_loss: 0.4084 - val_mse: 0.4084 - lr: 1.0000e-06 - 678ms/epoch - 169ms/step\n",
            "Epoch 339/1000\n",
            "4/4 - 1s - loss: 0.4290 - mse: 0.4061 - val_loss: 0.4084 - val_mse: 0.4084 - lr: 1.0000e-06 - 661ms/epoch - 165ms/step\n",
            "Epoch 340/1000\n",
            "4/4 - 1s - loss: 0.4290 - mse: 0.4061 - val_loss: 0.4084 - val_mse: 0.4084 - lr: 1.0000e-06 - 677ms/epoch - 169ms/step\n",
            "Epoch 341/1000\n",
            "4/4 - 1s - loss: 0.4289 - mse: 0.4061 - val_loss: 0.4083 - val_mse: 0.4083 - lr: 1.0000e-06 - 691ms/epoch - 173ms/step\n",
            "Epoch 342/1000\n",
            "4/4 - 1s - loss: 0.4283 - mse: 0.4054 - val_loss: 0.4083 - val_mse: 0.4083 - lr: 1.0000e-06 - 676ms/epoch - 169ms/step\n",
            "Epoch 343/1000\n",
            "4/4 - 1s - loss: 0.4293 - mse: 0.4064 - val_loss: 0.4083 - val_mse: 0.4083 - lr: 1.0000e-06 - 700ms/epoch - 175ms/step\n",
            "Epoch 344/1000\n",
            "\n",
            "Epoch 344: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
            "4/4 - 1s - loss: 0.4277 - mse: 0.4050 - val_loss: 0.4083 - val_mse: 0.4083 - lr: 1.0000e-06 - 678ms/epoch - 169ms/step\n",
            "Epoch 345/1000\n",
            "4/4 - 1s - loss: 0.4286 - mse: 0.4058 - val_loss: 0.4083 - val_mse: 0.4083 - lr: 1.0000e-07 - 677ms/epoch - 169ms/step\n",
            "Epoch 346/1000\n",
            "4/4 - 1s - loss: 0.4292 - mse: 0.4063 - val_loss: 0.4083 - val_mse: 0.4083 - lr: 1.0000e-07 - 681ms/epoch - 170ms/step\n",
            "Epoch 347/1000\n",
            "4/4 - 1s - loss: 0.4284 - mse: 0.4055 - val_loss: 0.4083 - val_mse: 0.4083 - lr: 1.0000e-07 - 679ms/epoch - 170ms/step\n",
            "Epoch 348/1000\n",
            "4/4 - 1s - loss: 0.4293 - mse: 0.4063 - val_loss: 0.4083 - val_mse: 0.4083 - lr: 1.0000e-07 - 681ms/epoch - 170ms/step\n",
            "Epoch 349/1000\n",
            "4/4 - 1s - loss: 0.4292 - mse: 0.4063 - val_loss: 0.4083 - val_mse: 0.4083 - lr: 1.0000e-07 - 684ms/epoch - 171ms/step\n",
            "Epoch 350/1000\n",
            "4/4 - 1s - loss: 0.4282 - mse: 0.4053 - val_loss: 0.4083 - val_mse: 0.4083 - lr: 1.0000e-07 - 662ms/epoch - 166ms/step\n",
            "Epoch 351/1000\n",
            "\n",
            "Epoch 351: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-08.\n",
            "4/4 - 1s - loss: 0.4287 - mse: 0.4058 - val_loss: 0.4083 - val_mse: 0.4083 - lr: 1.0000e-07 - 680ms/epoch - 170ms/step\n",
            "Epoch 352/1000\n",
            "4/4 - 1s - loss: 0.4293 - mse: 0.4063 - val_loss: 0.4083 - val_mse: 0.4083 - lr: 1.0000e-08 - 678ms/epoch - 169ms/step\n",
            "Epoch 353/1000\n",
            "4/4 - 1s - loss: 0.4274 - mse: 0.4046 - val_loss: 0.4083 - val_mse: 0.4083 - lr: 1.0000e-08 - 671ms/epoch - 168ms/step\n",
            "Epoch 354/1000\n",
            "4/4 - 1s - loss: 0.4286 - mse: 0.4058 - val_loss: 0.4083 - val_mse: 0.4083 - lr: 1.0000e-08 - 666ms/epoch - 166ms/step\n",
            "Epoch 355/1000\n",
            "4/4 - 1s - loss: 0.4286 - mse: 0.4057 - val_loss: 0.4083 - val_mse: 0.4083 - lr: 1.0000e-08 - 680ms/epoch - 170ms/step\n",
            "Epoch 356/1000\n",
            "4/4 - 1s - loss: 0.4277 - mse: 0.4049 - val_loss: 0.4083 - val_mse: 0.4083 - lr: 1.0000e-08 - 683ms/epoch - 171ms/step\n",
            "Epoch 357/1000\n",
            "4/4 - 1s - loss: 0.4286 - mse: 0.4057 - val_loss: 0.4083 - val_mse: 0.4083 - lr: 1.0000e-08 - 675ms/epoch - 169ms/step\n",
            "Epoch 358/1000\n",
            "\n",
            "Epoch 358: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-09.\n",
            "4/4 - 1s - loss: 0.4279 - mse: 0.4051 - val_loss: 0.4083 - val_mse: 0.4083 - lr: 1.0000e-08 - 706ms/epoch - 177ms/step\n",
            "Epoch 359/1000\n",
            "4/4 - 1s - loss: 0.4287 - mse: 0.4059 - val_loss: 0.4083 - val_mse: 0.4083 - lr: 1.0000e-09 - 695ms/epoch - 174ms/step\n",
            "Epoch 360/1000\n",
            "4/4 - 1s - loss: 0.4286 - mse: 0.4056 - val_loss: 0.4083 - val_mse: 0.4083 - lr: 1.0000e-09 - 689ms/epoch - 172ms/step\n",
            "Epoch 361/1000\n",
            "4/4 - 1s - loss: 0.4279 - mse: 0.4051 - val_loss: 0.4083 - val_mse: 0.4083 - lr: 1.0000e-09 - 688ms/epoch - 172ms/step\n",
            "Epoch 362/1000\n",
            "4/4 - 1s - loss: 0.4290 - mse: 0.4061 - val_loss: 0.4083 - val_mse: 0.4083 - lr: 1.0000e-09 - 691ms/epoch - 173ms/step\n",
            "Epoch 363/1000\n",
            "4/4 - 1s - loss: 0.4284 - mse: 0.4055 - val_loss: 0.4083 - val_mse: 0.4083 - lr: 1.0000e-09 - 672ms/epoch - 168ms/step\n",
            "Epoch 364/1000\n",
            "4/4 - 1s - loss: 0.4295 - mse: 0.4065 - val_loss: 0.4083 - val_mse: 0.4083 - lr: 1.0000e-09 - 674ms/epoch - 168ms/step\n",
            "Epoch 365/1000\n",
            "4/4 - 1s - loss: 0.4283 - mse: 0.4054 - val_loss: 0.4083 - val_mse: 0.4083 - lr: 1.0000e-09 - 672ms/epoch - 168ms/step\n",
            "Epoch 366/1000\n",
            "4/4 - 1s - loss: 0.4283 - mse: 0.4054 - val_loss: 0.4083 - val_mse: 0.4083 - lr: 1.0000e-09 - 674ms/epoch - 169ms/step\n",
            "Epoch 367/1000\n",
            "4/4 - 1s - loss: 0.4286 - mse: 0.4057 - val_loss: 0.4083 - val_mse: 0.4083 - lr: 1.0000e-09 - 663ms/epoch - 166ms/step\n",
            "Epoch 368/1000\n",
            "4/4 - 1s - loss: 0.4291 - mse: 0.4062 - val_loss: 0.4083 - val_mse: 0.4083 - lr: 1.0000e-09 - 667ms/epoch - 167ms/step\n",
            "Epoch 369/1000\n",
            "4/4 - 1s - loss: 0.4287 - mse: 0.4059 - val_loss: 0.4083 - val_mse: 0.4083 - lr: 1.0000e-09 - 662ms/epoch - 165ms/step\n",
            "Epoch 370/1000\n",
            "\n",
            "Epoch 370: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-10.\n",
            "4/4 - 1s - loss: 0.4283 - mse: 0.4055 - val_loss: 0.4083 - val_mse: 0.4083 - lr: 1.0000e-09 - 675ms/epoch - 169ms/step\n",
            "Epoch 371/1000\n",
            "4/4 - 1s - loss: 0.4283 - mse: 0.4055 - val_loss: 0.4083 - val_mse: 0.4083 - lr: 1.0000e-10 - 674ms/epoch - 168ms/step\n",
            "Epoch 372/1000\n",
            "4/4 - 1s - loss: 0.4286 - mse: 0.4058 - val_loss: 0.4083 - val_mse: 0.4083 - lr: 1.0000e-10 - 669ms/epoch - 167ms/step\n",
            "Epoch 373/1000\n",
            "4/4 - 1s - loss: 0.4284 - mse: 0.4056 - val_loss: 0.4083 - val_mse: 0.4083 - lr: 1.0000e-10 - 669ms/epoch - 167ms/step\n",
            "Epoch 374/1000\n",
            "4/4 - 1s - loss: 0.4292 - mse: 0.4063 - val_loss: 0.4083 - val_mse: 0.4083 - lr: 1.0000e-10 - 699ms/epoch - 175ms/step\n",
            "Epoch 375/1000\n",
            "4/4 - 1s - loss: 0.4286 - mse: 0.4057 - val_loss: 0.4083 - val_mse: 0.4083 - lr: 1.0000e-10 - 671ms/epoch - 168ms/step\n",
            "Epoch 376/1000\n",
            "4/4 - 1s - loss: 0.4287 - mse: 0.4058 - val_loss: 0.4083 - val_mse: 0.4083 - lr: 1.0000e-10 - 658ms/epoch - 165ms/step\n",
            "Epoch 377/1000\n",
            "\n",
            "Epoch 377: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-11.\n",
            "4/4 - 1s - loss: 0.4284 - mse: 0.4055 - val_loss: 0.4083 - val_mse: 0.4083 - lr: 1.0000e-10 - 680ms/epoch - 170ms/step\n",
            "Epoch 378/1000\n",
            "4/4 - 1s - loss: 0.4287 - mse: 0.4058 - val_loss: 0.4083 - val_mse: 0.4083 - lr: 1.0000e-11 - 668ms/epoch - 167ms/step\n",
            "Epoch 379/1000\n",
            "4/4 - 1s - loss: 0.4293 - mse: 0.4065 - val_loss: 0.4083 - val_mse: 0.4083 - lr: 1.0000e-11 - 663ms/epoch - 166ms/step\n",
            "Epoch 380/1000\n",
            "4/4 - 1s - loss: 0.4283 - mse: 0.4054 - val_loss: 0.4083 - val_mse: 0.4083 - lr: 1.0000e-11 - 685ms/epoch - 171ms/step\n",
            "Epoch 381/1000\n",
            "4/4 - 1s - loss: 0.4292 - mse: 0.4062 - val_loss: 0.4083 - val_mse: 0.4083 - lr: 1.0000e-11 - 663ms/epoch - 166ms/step\n",
            "Epoch 382/1000\n",
            "4/4 - 1s - loss: 0.4287 - mse: 0.4058 - val_loss: 0.4083 - val_mse: 0.4083 - lr: 1.0000e-11 - 665ms/epoch - 166ms/step\n",
            "Epoch 383/1000\n",
            "4/4 - 1s - loss: 0.4285 - mse: 0.4057 - val_loss: 0.4083 - val_mse: 0.4083 - lr: 1.0000e-11 - 661ms/epoch - 165ms/step\n",
            "Epoch 384/1000\n",
            "\n",
            "Epoch 384: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-12.\n",
            "4/4 - 1s - loss: 0.4289 - mse: 0.4060 - val_loss: 0.4082 - val_mse: 0.4082 - lr: 1.0000e-11 - 667ms/epoch - 167ms/step\n",
            "Epoch 385/1000\n",
            "4/4 - 1s - loss: 0.4288 - mse: 0.4059 - val_loss: 0.4083 - val_mse: 0.4083 - lr: 1.0000e-12 - 684ms/epoch - 171ms/step\n",
            "Epoch 386/1000\n",
            "4/4 - 1s - loss: 0.4284 - mse: 0.4055 - val_loss: 0.4082 - val_mse: 0.4082 - lr: 1.0000e-12 - 679ms/epoch - 170ms/step\n",
            "Epoch 387/1000\n",
            "4/4 - 1s - loss: 0.4288 - mse: 0.4059 - val_loss: 0.4083 - val_mse: 0.4083 - lr: 1.0000e-12 - 678ms/epoch - 169ms/step\n",
            "Epoch 388/1000\n",
            "4/4 - 1s - loss: 0.4289 - mse: 0.4060 - val_loss: 0.4082 - val_mse: 0.4082 - lr: 1.0000e-12 - 684ms/epoch - 171ms/step\n",
            "Epoch 389/1000\n",
            "4/4 - 1s - loss: 0.4292 - mse: 0.4063 - val_loss: 0.4082 - val_mse: 0.4082 - lr: 1.0000e-12 - 660ms/epoch - 165ms/step\n",
            "Epoch 390/1000\n",
            "4/4 - 1s - loss: 0.4288 - mse: 0.4059 - val_loss: 0.4082 - val_mse: 0.4082 - lr: 1.0000e-12 - 661ms/epoch - 165ms/step\n",
            "Epoch 391/1000\n",
            "\n",
            "Epoch 391: ReduceLROnPlateau reducing learning rate to 1.0000001044244145e-13.\n",
            "4/4 - 1s - loss: 0.4290 - mse: 0.4061 - val_loss: 0.4082 - val_mse: 0.4082 - lr: 1.0000e-12 - 669ms/epoch - 167ms/step\n",
            "Epoch 392/1000\n",
            "4/4 - 1s - loss: 0.4283 - mse: 0.4055 - val_loss: 0.4082 - val_mse: 0.4082 - lr: 1.0000e-13 - 685ms/epoch - 171ms/step\n",
            "Epoch 393/1000\n",
            "4/4 - 1s - loss: 0.4280 - mse: 0.4052 - val_loss: 0.4082 - val_mse: 0.4082 - lr: 1.0000e-13 - 661ms/epoch - 165ms/step\n",
            "Epoch 394/1000\n",
            "4/4 - 1s - loss: 0.4288 - mse: 0.4059 - val_loss: 0.4082 - val_mse: 0.4082 - lr: 1.0000e-13 - 656ms/epoch - 164ms/step\n",
            "Epoch 395/1000\n",
            "4/4 - 1s - loss: 0.4279 - mse: 0.4051 - val_loss: 0.4082 - val_mse: 0.4082 - lr: 1.0000e-13 - 668ms/epoch - 167ms/step\n",
            "Epoch 396/1000\n",
            "4/4 - 1s - loss: 0.4278 - mse: 0.4049 - val_loss: 0.4082 - val_mse: 0.4082 - lr: 1.0000e-13 - 670ms/epoch - 167ms/step\n",
            "Epoch 397/1000\n",
            "4/4 - 1s - loss: 0.4285 - mse: 0.4056 - val_loss: 0.4082 - val_mse: 0.4082 - lr: 1.0000e-13 - 673ms/epoch - 168ms/step\n",
            "Epoch 398/1000\n",
            "\n",
            "Epoch 398: ReduceLROnPlateau reducing learning rate to 1.0000001179769417e-14.\n",
            "4/4 - 1s - loss: 0.4285 - mse: 0.4057 - val_loss: 0.4082 - val_mse: 0.4082 - lr: 1.0000e-13 - 665ms/epoch - 166ms/step\n",
            "Epoch 399/1000\n",
            "4/4 - 1s - loss: 0.4295 - mse: 0.4065 - val_loss: 0.4082 - val_mse: 0.4082 - lr: 1.0000e-14 - 667ms/epoch - 167ms/step\n",
            "Epoch 400/1000\n",
            "4/4 - 1s - loss: 0.4290 - mse: 0.4061 - val_loss: 0.4082 - val_mse: 0.4082 - lr: 1.0000e-14 - 663ms/epoch - 166ms/step\n",
            "Epoch 401/1000\n",
            "4/4 - 1s - loss: 0.4288 - mse: 0.4058 - val_loss: 0.4082 - val_mse: 0.4082 - lr: 1.0000e-14 - 668ms/epoch - 167ms/step\n",
            "Epoch 402/1000\n",
            "4/4 - 1s - loss: 0.4286 - mse: 0.4057 - val_loss: 0.4082 - val_mse: 0.4082 - lr: 1.0000e-14 - 676ms/epoch - 169ms/step\n",
            "Epoch 403/1000\n",
            "4/4 - 1s - loss: 0.4286 - mse: 0.4058 - val_loss: 0.4082 - val_mse: 0.4082 - lr: 1.0000e-14 - 670ms/epoch - 167ms/step\n",
            "Epoch 404/1000\n",
            "4/4 - 1s - loss: 0.4287 - mse: 0.4058 - val_loss: 0.4082 - val_mse: 0.4082 - lr: 1.0000e-14 - 670ms/epoch - 168ms/step\n",
            "Epoch 405/1000\n",
            "\n",
            "Epoch 405: ReduceLROnPlateau reducing learning rate to 1.0000001518582595e-15.\n",
            "4/4 - 1s - loss: 0.4284 - mse: 0.4056 - val_loss: 0.4082 - val_mse: 0.4082 - lr: 1.0000e-14 - 671ms/epoch - 168ms/step\n",
            "Epoch 406/1000\n",
            "4/4 - 1s - loss: 0.4285 - mse: 0.4057 - val_loss: 0.4082 - val_mse: 0.4082 - lr: 1.0000e-15 - 669ms/epoch - 167ms/step\n",
            "Epoch 407/1000\n",
            "4/4 - 1s - loss: 0.4288 - mse: 0.4060 - val_loss: 0.4082 - val_mse: 0.4082 - lr: 1.0000e-15 - 688ms/epoch - 172ms/step\n",
            "Epoch 408/1000\n",
            "4/4 - 1s - loss: 0.4282 - mse: 0.4055 - val_loss: 0.4082 - val_mse: 0.4082 - lr: 1.0000e-15 - 685ms/epoch - 171ms/step\n",
            "Epoch 409/1000\n",
            "4/4 - 1s - loss: 0.4284 - mse: 0.4056 - val_loss: 0.4082 - val_mse: 0.4082 - lr: 1.0000e-15 - 678ms/epoch - 169ms/step\n",
            "Epoch 410/1000\n",
            "4/4 - 1s - loss: 0.4286 - mse: 0.4058 - val_loss: 0.4082 - val_mse: 0.4082 - lr: 1.0000e-15 - 675ms/epoch - 169ms/step\n",
            "Epoch 411/1000\n",
            "4/4 - 1s - loss: 0.4291 - mse: 0.4062 - val_loss: 0.4082 - val_mse: 0.4082 - lr: 1.0000e-15 - 677ms/epoch - 169ms/step\n",
            "Epoch 412/1000\n",
            "\n",
            "Epoch 412: ReduceLROnPlateau reducing learning rate to 1.0000001095066122e-16.\n",
            "4/4 - 1s - loss: 0.4288 - mse: 0.4059 - val_loss: 0.4082 - val_mse: 0.4082 - lr: 1.0000e-15 - 677ms/epoch - 169ms/step\n",
            "Epoch 412: early stopping\n",
            "==================================================\n",
            "Step 12\n",
            "==================================================\n",
            "Epoch 1/1000\n",
            "4/4 - 4s - loss: 3.8678 - mse: 3.5720 - val_loss: 0.9831 - val_mse: 0.9831 - lr: 0.0010 - 4s/epoch - 967ms/step\n",
            "Epoch 2/1000\n",
            "4/4 - 1s - loss: 2.5122 - mse: 2.3226 - val_loss: 0.9304 - val_mse: 0.9304 - lr: 0.0010 - 663ms/epoch - 166ms/step\n",
            "Epoch 3/1000\n",
            "4/4 - 1s - loss: 1.9585 - mse: 1.8291 - val_loss: 0.9233 - val_mse: 0.9233 - lr: 0.0010 - 670ms/epoch - 167ms/step\n",
            "Epoch 4/1000\n",
            "4/4 - 1s - loss: 1.6825 - mse: 1.5774 - val_loss: 0.9245 - val_mse: 0.9245 - lr: 0.0010 - 682ms/epoch - 171ms/step\n",
            "Epoch 5/1000\n",
            "4/4 - 1s - loss: 1.5446 - mse: 1.4472 - val_loss: 0.9142 - val_mse: 0.9142 - lr: 0.0010 - 663ms/epoch - 166ms/step\n",
            "Epoch 6/1000\n",
            "4/4 - 1s - loss: 1.4467 - mse: 1.3552 - val_loss: 0.8938 - val_mse: 0.8938 - lr: 0.0010 - 657ms/epoch - 164ms/step\n",
            "Epoch 7/1000\n",
            "4/4 - 1s - loss: 1.3656 - mse: 1.2798 - val_loss: 0.8750 - val_mse: 0.8750 - lr: 0.0010 - 674ms/epoch - 169ms/step\n",
            "Epoch 8/1000\n",
            "4/4 - 1s - loss: 1.3011 - mse: 1.2224 - val_loss: 0.8643 - val_mse: 0.8643 - lr: 0.0010 - 667ms/epoch - 167ms/step\n",
            "Epoch 9/1000\n",
            "4/4 - 1s - loss: 1.2548 - mse: 1.1792 - val_loss: 0.8638 - val_mse: 0.8638 - lr: 0.0010 - 655ms/epoch - 164ms/step\n",
            "Epoch 10/1000\n",
            "4/4 - 1s - loss: 1.2189 - mse: 1.1442 - val_loss: 0.8687 - val_mse: 0.8687 - lr: 0.0010 - 673ms/epoch - 168ms/step\n",
            "Epoch 11/1000\n",
            "4/4 - 1s - loss: 1.1922 - mse: 1.1201 - val_loss: 0.8734 - val_mse: 0.8734 - lr: 0.0010 - 655ms/epoch - 164ms/step\n",
            "Epoch 12/1000\n",
            "4/4 - 1s - loss: 1.1617 - mse: 1.0918 - val_loss: 0.8746 - val_mse: 0.8746 - lr: 0.0010 - 674ms/epoch - 169ms/step\n",
            "Epoch 13/1000\n",
            "4/4 - 1s - loss: 1.1333 - mse: 1.0651 - val_loss: 0.8720 - val_mse: 0.8720 - lr: 0.0010 - 660ms/epoch - 165ms/step\n",
            "Epoch 14/1000\n",
            "4/4 - 1s - loss: 1.1071 - mse: 1.0407 - val_loss: 0.8674 - val_mse: 0.8674 - lr: 0.0010 - 662ms/epoch - 166ms/step\n",
            "Epoch 15/1000\n",
            "4/4 - 1s - loss: 1.0865 - mse: 1.0218 - val_loss: 0.8634 - val_mse: 0.8634 - lr: 0.0010 - 660ms/epoch - 165ms/step\n",
            "Epoch 16/1000\n",
            "4/4 - 1s - loss: 1.0691 - mse: 1.0054 - val_loss: 0.8623 - val_mse: 0.8623 - lr: 0.0010 - 672ms/epoch - 168ms/step\n",
            "Epoch 17/1000\n",
            "4/4 - 1s - loss: 1.0501 - mse: 0.9881 - val_loss: 0.8627 - val_mse: 0.8627 - lr: 0.0010 - 655ms/epoch - 164ms/step\n",
            "Epoch 18/1000\n",
            "4/4 - 1s - loss: 1.0243 - mse: 0.9646 - val_loss: 0.8635 - val_mse: 0.8635 - lr: 0.0010 - 657ms/epoch - 164ms/step\n",
            "Epoch 19/1000\n",
            "4/4 - 1s - loss: 1.0148 - mse: 0.9549 - val_loss: 0.8664 - val_mse: 0.8664 - lr: 0.0010 - 656ms/epoch - 164ms/step\n",
            "Epoch 20/1000\n",
            "4/4 - 1s - loss: 0.9969 - mse: 0.9384 - val_loss: 0.8675 - val_mse: 0.8675 - lr: 0.0010 - 647ms/epoch - 162ms/step\n",
            "Epoch 21/1000\n",
            "4/4 - 1s - loss: 0.9787 - mse: 0.9217 - val_loss: 0.8670 - val_mse: 0.8670 - lr: 0.0010 - 672ms/epoch - 168ms/step\n",
            "Epoch 22/1000\n",
            "4/4 - 1s - loss: 0.9683 - mse: 0.9115 - val_loss: 0.8673 - val_mse: 0.8673 - lr: 0.0010 - 667ms/epoch - 167ms/step\n",
            "Epoch 23/1000\n",
            "\n",
            "Epoch 23: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "4/4 - 1s - loss: 0.9556 - mse: 0.9003 - val_loss: 0.8683 - val_mse: 0.8683 - lr: 0.0010 - 669ms/epoch - 167ms/step\n",
            "Epoch 24/1000\n",
            "4/4 - 1s - loss: 0.9462 - mse: 0.8914 - val_loss: 0.8755 - val_mse: 0.8755 - lr: 1.0000e-04 - 660ms/epoch - 165ms/step\n",
            "Epoch 25/1000\n",
            "4/4 - 1s - loss: 0.9459 - mse: 0.8911 - val_loss: 0.8822 - val_mse: 0.8822 - lr: 1.0000e-04 - 658ms/epoch - 165ms/step\n",
            "Epoch 26/1000\n",
            "4/4 - 1s - loss: 0.9417 - mse: 0.8869 - val_loss: 0.8882 - val_mse: 0.8882 - lr: 1.0000e-04 - 666ms/epoch - 167ms/step\n",
            "Epoch 26: early stopping\n",
            "==================================================\n",
            "Step 13\n",
            "==================================================\n",
            "Epoch 1/1000\n",
            "4/4 - 4s - loss: 3.4583 - mse: 3.2586 - val_loss: 1.0051 - val_mse: 1.0051 - lr: 0.0010 - 4s/epoch - 1s/step\n",
            "Epoch 2/1000\n",
            "4/4 - 1s - loss: 2.0051 - mse: 1.8860 - val_loss: 0.9068 - val_mse: 0.9068 - lr: 0.0010 - 654ms/epoch - 164ms/step\n",
            "Epoch 3/1000\n",
            "4/4 - 1s - loss: 1.6760 - mse: 1.5774 - val_loss: 0.8733 - val_mse: 0.8733 - lr: 0.0010 - 664ms/epoch - 166ms/step\n",
            "Epoch 4/1000\n",
            "4/4 - 1s - loss: 1.5273 - mse: 1.4373 - val_loss: 0.8745 - val_mse: 0.8745 - lr: 0.0010 - 652ms/epoch - 163ms/step\n",
            "Epoch 5/1000\n",
            "4/4 - 1s - loss: 1.4147 - mse: 1.3316 - val_loss: 0.8826 - val_mse: 0.8826 - lr: 0.0010 - 660ms/epoch - 165ms/step\n",
            "Epoch 6/1000\n",
            "4/4 - 1s - loss: 1.3351 - mse: 1.2571 - val_loss: 0.8816 - val_mse: 0.8816 - lr: 0.0010 - 723ms/epoch - 181ms/step\n",
            "Epoch 7/1000\n",
            "4/4 - 1s - loss: 1.2572 - mse: 1.1838 - val_loss: 0.8720 - val_mse: 0.8720 - lr: 0.0010 - 687ms/epoch - 172ms/step\n",
            "Epoch 8/1000\n",
            "4/4 - 1s - loss: 1.1938 - mse: 1.1251 - val_loss: 0.8607 - val_mse: 0.8607 - lr: 0.0010 - 648ms/epoch - 162ms/step\n",
            "Epoch 9/1000\n",
            "4/4 - 1s - loss: 1.1616 - mse: 1.0949 - val_loss: 0.8523 - val_mse: 0.8523 - lr: 0.0010 - 672ms/epoch - 168ms/step\n",
            "Epoch 10/1000\n",
            "4/4 - 1s - loss: 1.1309 - mse: 1.0663 - val_loss: 0.8479 - val_mse: 0.8479 - lr: 0.0010 - 662ms/epoch - 165ms/step\n",
            "Epoch 11/1000\n",
            "4/4 - 1s - loss: 1.1024 - mse: 1.0401 - val_loss: 0.8442 - val_mse: 0.8442 - lr: 0.0010 - 637ms/epoch - 159ms/step\n",
            "Epoch 12/1000\n",
            "4/4 - 1s - loss: 1.0728 - mse: 1.0120 - val_loss: 0.8381 - val_mse: 0.8381 - lr: 0.0010 - 650ms/epoch - 162ms/step\n",
            "Epoch 13/1000\n",
            "4/4 - 1s - loss: 1.0451 - mse: 0.9857 - val_loss: 0.8280 - val_mse: 0.8280 - lr: 0.0010 - 656ms/epoch - 164ms/step\n",
            "Epoch 14/1000\n",
            "4/4 - 1s - loss: 1.0213 - mse: 0.9639 - val_loss: 0.8161 - val_mse: 0.8161 - lr: 0.0010 - 628ms/epoch - 157ms/step\n",
            "Epoch 15/1000\n",
            "4/4 - 1s - loss: 1.0028 - mse: 0.9468 - val_loss: 0.8051 - val_mse: 0.8051 - lr: 0.0010 - 652ms/epoch - 163ms/step\n",
            "Epoch 16/1000\n",
            "4/4 - 1s - loss: 0.9919 - mse: 0.9368 - val_loss: 0.7955 - val_mse: 0.7955 - lr: 0.0010 - 654ms/epoch - 164ms/step\n",
            "Epoch 17/1000\n",
            "4/4 - 1s - loss: 0.9695 - mse: 0.9160 - val_loss: 0.7869 - val_mse: 0.7869 - lr: 0.0010 - 639ms/epoch - 160ms/step\n",
            "Epoch 18/1000\n",
            "4/4 - 1s - loss: 0.9550 - mse: 0.9024 - val_loss: 0.7795 - val_mse: 0.7795 - lr: 0.0010 - 653ms/epoch - 163ms/step\n",
            "Epoch 19/1000\n",
            "4/4 - 1s - loss: 0.9459 - mse: 0.8941 - val_loss: 0.7726 - val_mse: 0.7726 - lr: 0.0010 - 646ms/epoch - 162ms/step\n",
            "Epoch 20/1000\n",
            "4/4 - 1s - loss: 0.9284 - mse: 0.8775 - val_loss: 0.7655 - val_mse: 0.7655 - lr: 0.0010 - 646ms/epoch - 162ms/step\n",
            "Epoch 21/1000\n",
            "4/4 - 1s - loss: 0.9157 - mse: 0.8654 - val_loss: 0.7584 - val_mse: 0.7584 - lr: 0.0010 - 663ms/epoch - 166ms/step\n",
            "Epoch 22/1000\n",
            "4/4 - 1s - loss: 0.9006 - mse: 0.8516 - val_loss: 0.7509 - val_mse: 0.7509 - lr: 0.0010 - 670ms/epoch - 168ms/step\n",
            "Epoch 23/1000\n",
            "4/4 - 1s - loss: 0.8894 - mse: 0.8411 - val_loss: 0.7425 - val_mse: 0.7425 - lr: 0.0010 - 644ms/epoch - 161ms/step\n",
            "Epoch 24/1000\n",
            "4/4 - 1s - loss: 0.8819 - mse: 0.8339 - val_loss: 0.7343 - val_mse: 0.7343 - lr: 0.0010 - 653ms/epoch - 163ms/step\n",
            "Epoch 25/1000\n",
            "4/4 - 1s - loss: 0.8747 - mse: 0.8273 - val_loss: 0.7273 - val_mse: 0.7273 - lr: 0.0010 - 664ms/epoch - 166ms/step\n",
            "Epoch 26/1000\n",
            "4/4 - 1s - loss: 0.8629 - mse: 0.8164 - val_loss: 0.7206 - val_mse: 0.7206 - lr: 0.0010 - 662ms/epoch - 166ms/step\n",
            "Epoch 27/1000\n",
            "4/4 - 1s - loss: 0.8519 - mse: 0.8057 - val_loss: 0.7142 - val_mse: 0.7142 - lr: 0.0010 - 662ms/epoch - 165ms/step\n",
            "Epoch 28/1000\n",
            "4/4 - 1s - loss: 0.8441 - mse: 0.7986 - val_loss: 0.7078 - val_mse: 0.7078 - lr: 0.0010 - 659ms/epoch - 165ms/step\n",
            "Epoch 29/1000\n",
            "4/4 - 1s - loss: 0.8272 - mse: 0.7828 - val_loss: 0.7017 - val_mse: 0.7017 - lr: 0.0010 - 666ms/epoch - 166ms/step\n",
            "Epoch 30/1000\n",
            "4/4 - 1s - loss: 0.8223 - mse: 0.7782 - val_loss: 0.6958 - val_mse: 0.6958 - lr: 0.0010 - 673ms/epoch - 168ms/step\n",
            "Epoch 31/1000\n",
            "4/4 - 1s - loss: 0.8152 - mse: 0.7715 - val_loss: 0.6894 - val_mse: 0.6894 - lr: 0.0010 - 644ms/epoch - 161ms/step\n",
            "Epoch 32/1000\n",
            "4/4 - 1s - loss: 0.8027 - mse: 0.7594 - val_loss: 0.6827 - val_mse: 0.6827 - lr: 0.0010 - 649ms/epoch - 162ms/step\n",
            "Epoch 33/1000\n",
            "4/4 - 1s - loss: 0.8030 - mse: 0.7598 - val_loss: 0.6760 - val_mse: 0.6760 - lr: 0.0010 - 655ms/epoch - 164ms/step\n",
            "Epoch 34/1000\n",
            "4/4 - 1s - loss: 0.7890 - mse: 0.7470 - val_loss: 0.6701 - val_mse: 0.6701 - lr: 0.0010 - 649ms/epoch - 162ms/step\n",
            "Epoch 35/1000\n",
            "4/4 - 1s - loss: 0.7845 - mse: 0.7427 - val_loss: 0.6643 - val_mse: 0.6643 - lr: 0.0010 - 655ms/epoch - 164ms/step\n",
            "Epoch 36/1000\n",
            "4/4 - 1s - loss: 0.7793 - mse: 0.7375 - val_loss: 0.6583 - val_mse: 0.6583 - lr: 0.0010 - 643ms/epoch - 161ms/step\n",
            "Epoch 37/1000\n",
            "4/4 - 1s - loss: 0.7664 - mse: 0.7259 - val_loss: 0.6524 - val_mse: 0.6524 - lr: 0.0010 - 683ms/epoch - 171ms/step\n",
            "Epoch 38/1000\n",
            "4/4 - 1s - loss: 0.7583 - mse: 0.7181 - val_loss: 0.6466 - val_mse: 0.6466 - lr: 0.0010 - 657ms/epoch - 164ms/step\n",
            "Epoch 39/1000\n",
            "4/4 - 1s - loss: 0.7535 - mse: 0.7136 - val_loss: 0.6408 - val_mse: 0.6408 - lr: 0.0010 - 639ms/epoch - 160ms/step\n",
            "Epoch 40/1000\n",
            "4/4 - 1s - loss: 0.7488 - mse: 0.7092 - val_loss: 0.6354 - val_mse: 0.6354 - lr: 0.0010 - 651ms/epoch - 163ms/step\n",
            "Epoch 41/1000\n",
            "4/4 - 1s - loss: 0.7417 - mse: 0.7026 - val_loss: 0.6302 - val_mse: 0.6302 - lr: 0.0010 - 652ms/epoch - 163ms/step\n",
            "Epoch 42/1000\n",
            "4/4 - 1s - loss: 0.7348 - mse: 0.6962 - val_loss: 0.6255 - val_mse: 0.6255 - lr: 0.0010 - 648ms/epoch - 162ms/step\n",
            "Epoch 43/1000\n",
            "4/4 - 1s - loss: 0.7298 - mse: 0.6913 - val_loss: 0.6209 - val_mse: 0.6209 - lr: 0.0010 - 648ms/epoch - 162ms/step\n",
            "Epoch 44/1000\n",
            "4/4 - 1s - loss: 0.7237 - mse: 0.6854 - val_loss: 0.6159 - val_mse: 0.6159 - lr: 0.0010 - 658ms/epoch - 165ms/step\n",
            "Epoch 45/1000\n",
            "4/4 - 1s - loss: 0.7159 - mse: 0.6782 - val_loss: 0.6106 - val_mse: 0.6106 - lr: 0.0010 - 660ms/epoch - 165ms/step\n",
            "Epoch 46/1000\n",
            "4/4 - 1s - loss: 0.7116 - mse: 0.6741 - val_loss: 0.6051 - val_mse: 0.6051 - lr: 0.0010 - 663ms/epoch - 166ms/step\n",
            "Epoch 47/1000\n",
            "4/4 - 1s - loss: 0.7063 - mse: 0.6691 - val_loss: 0.6003 - val_mse: 0.6003 - lr: 0.0010 - 679ms/epoch - 170ms/step\n",
            "Epoch 48/1000\n",
            "4/4 - 1s - loss: 0.7017 - mse: 0.6647 - val_loss: 0.5957 - val_mse: 0.5957 - lr: 0.0010 - 681ms/epoch - 170ms/step\n",
            "Epoch 49/1000\n",
            "4/4 - 1s - loss: 0.6976 - mse: 0.6607 - val_loss: 0.5913 - val_mse: 0.5913 - lr: 0.0010 - 676ms/epoch - 169ms/step\n",
            "Epoch 50/1000\n",
            "4/4 - 1s - loss: 0.6944 - mse: 0.6578 - val_loss: 0.5865 - val_mse: 0.5865 - lr: 0.0010 - 654ms/epoch - 163ms/step\n",
            "Epoch 51/1000\n",
            "4/4 - 1s - loss: 0.6858 - mse: 0.6499 - val_loss: 0.5813 - val_mse: 0.5813 - lr: 0.0010 - 677ms/epoch - 169ms/step\n",
            "Epoch 52/1000\n",
            "4/4 - 1s - loss: 0.6834 - mse: 0.6475 - val_loss: 0.5763 - val_mse: 0.5763 - lr: 0.0010 - 659ms/epoch - 165ms/step\n",
            "Epoch 53/1000\n",
            "4/4 - 1s - loss: 0.6771 - mse: 0.6418 - val_loss: 0.5715 - val_mse: 0.5715 - lr: 0.0010 - 680ms/epoch - 170ms/step\n",
            "Epoch 54/1000\n",
            "4/4 - 1s - loss: 0.6726 - mse: 0.6373 - val_loss: 0.5673 - val_mse: 0.5673 - lr: 0.0010 - 667ms/epoch - 167ms/step\n",
            "Epoch 55/1000\n",
            "4/4 - 1s - loss: 0.6673 - mse: 0.6324 - val_loss: 0.5628 - val_mse: 0.5628 - lr: 0.0010 - 665ms/epoch - 166ms/step\n",
            "Epoch 56/1000\n",
            "4/4 - 1s - loss: 0.6650 - mse: 0.6299 - val_loss: 0.5583 - val_mse: 0.5583 - lr: 0.0010 - 641ms/epoch - 160ms/step\n",
            "Epoch 57/1000\n",
            "4/4 - 1s - loss: 0.6606 - mse: 0.6259 - val_loss: 0.5538 - val_mse: 0.5538 - lr: 0.0010 - 657ms/epoch - 164ms/step\n",
            "Epoch 58/1000\n",
            "4/4 - 1s - loss: 0.6546 - mse: 0.6204 - val_loss: 0.5493 - val_mse: 0.5493 - lr: 0.0010 - 669ms/epoch - 167ms/step\n",
            "Epoch 59/1000\n",
            "4/4 - 1s - loss: 0.6522 - mse: 0.6179 - val_loss: 0.5452 - val_mse: 0.5452 - lr: 0.0010 - 653ms/epoch - 163ms/step\n",
            "Epoch 60/1000\n",
            "4/4 - 1s - loss: 0.6494 - mse: 0.6156 - val_loss: 0.5413 - val_mse: 0.5413 - lr: 0.0010 - 672ms/epoch - 168ms/step\n",
            "Epoch 61/1000\n",
            "4/4 - 1s - loss: 0.6433 - mse: 0.6094 - val_loss: 0.5372 - val_mse: 0.5372 - lr: 0.0010 - 650ms/epoch - 163ms/step\n",
            "Epoch 62/1000\n",
            "4/4 - 1s - loss: 0.6437 - mse: 0.6098 - val_loss: 0.5332 - val_mse: 0.5332 - lr: 0.0010 - 643ms/epoch - 161ms/step\n",
            "Epoch 63/1000\n",
            "4/4 - 1s - loss: 0.6389 - mse: 0.6055 - val_loss: 0.5292 - val_mse: 0.5292 - lr: 0.0010 - 661ms/epoch - 165ms/step\n",
            "Epoch 64/1000\n",
            "4/4 - 1s - loss: 0.6314 - mse: 0.5985 - val_loss: 0.5254 - val_mse: 0.5254 - lr: 0.0010 - 649ms/epoch - 162ms/step\n",
            "Epoch 65/1000\n",
            "4/4 - 1s - loss: 0.6307 - mse: 0.5979 - val_loss: 0.5216 - val_mse: 0.5216 - lr: 0.0010 - 666ms/epoch - 167ms/step\n",
            "Epoch 66/1000\n",
            "4/4 - 1s - loss: 0.6273 - mse: 0.5942 - val_loss: 0.5182 - val_mse: 0.5182 - lr: 0.0010 - 659ms/epoch - 165ms/step\n",
            "Epoch 67/1000\n",
            "4/4 - 1s - loss: 0.6211 - mse: 0.5887 - val_loss: 0.5149 - val_mse: 0.5149 - lr: 0.0010 - 668ms/epoch - 167ms/step\n",
            "Epoch 68/1000\n",
            "4/4 - 1s - loss: 0.6199 - mse: 0.5876 - val_loss: 0.5114 - val_mse: 0.5114 - lr: 0.0010 - 694ms/epoch - 174ms/step\n",
            "Epoch 69/1000\n",
            "4/4 - 1s - loss: 0.6162 - mse: 0.5840 - val_loss: 0.5070 - val_mse: 0.5070 - lr: 0.0010 - 662ms/epoch - 165ms/step\n",
            "Epoch 70/1000\n",
            "4/4 - 1s - loss: 0.6141 - mse: 0.5822 - val_loss: 0.5029 - val_mse: 0.5029 - lr: 0.0010 - 668ms/epoch - 167ms/step\n",
            "Epoch 71/1000\n",
            "4/4 - 1s - loss: 0.6101 - mse: 0.5783 - val_loss: 0.4995 - val_mse: 0.4995 - lr: 0.0010 - 654ms/epoch - 163ms/step\n",
            "Epoch 72/1000\n",
            "4/4 - 1s - loss: 0.6078 - mse: 0.5760 - val_loss: 0.4960 - val_mse: 0.4960 - lr: 0.0010 - 661ms/epoch - 165ms/step\n",
            "Epoch 73/1000\n",
            "4/4 - 1s - loss: 0.6043 - mse: 0.5725 - val_loss: 0.4928 - val_mse: 0.4928 - lr: 0.0010 - 658ms/epoch - 165ms/step\n",
            "Epoch 74/1000\n",
            "4/4 - 1s - loss: 0.6009 - mse: 0.5696 - val_loss: 0.4897 - val_mse: 0.4897 - lr: 0.0010 - 666ms/epoch - 167ms/step\n",
            "Epoch 75/1000\n",
            "4/4 - 1s - loss: 0.5975 - mse: 0.5665 - val_loss: 0.4866 - val_mse: 0.4866 - lr: 0.0010 - 675ms/epoch - 169ms/step\n",
            "Epoch 76/1000\n",
            "4/4 - 1s - loss: 0.5954 - mse: 0.5645 - val_loss: 0.4839 - val_mse: 0.4839 - lr: 0.0010 - 657ms/epoch - 164ms/step\n",
            "Epoch 77/1000\n",
            "4/4 - 1s - loss: 0.5942 - mse: 0.5631 - val_loss: 0.4812 - val_mse: 0.4812 - lr: 0.0010 - 679ms/epoch - 170ms/step\n",
            "Epoch 78/1000\n",
            "4/4 - 1s - loss: 0.5901 - mse: 0.5591 - val_loss: 0.4780 - val_mse: 0.4780 - lr: 0.0010 - 668ms/epoch - 167ms/step\n",
            "Epoch 79/1000\n",
            "4/4 - 1s - loss: 0.5867 - mse: 0.5562 - val_loss: 0.4751 - val_mse: 0.4751 - lr: 0.0010 - 664ms/epoch - 166ms/step\n",
            "Epoch 80/1000\n",
            "4/4 - 1s - loss: 0.5848 - mse: 0.5543 - val_loss: 0.4718 - val_mse: 0.4718 - lr: 0.0010 - 671ms/epoch - 168ms/step\n",
            "Epoch 81/1000\n",
            "4/4 - 1s - loss: 0.5828 - mse: 0.5523 - val_loss: 0.4690 - val_mse: 0.4690 - lr: 0.0010 - 659ms/epoch - 165ms/step\n",
            "Epoch 82/1000\n",
            "4/4 - 1s - loss: 0.5804 - mse: 0.5501 - val_loss: 0.4667 - val_mse: 0.4667 - lr: 0.0010 - 659ms/epoch - 165ms/step\n",
            "Epoch 83/1000\n",
            "4/4 - 1s - loss: 0.5773 - mse: 0.5475 - val_loss: 0.4644 - val_mse: 0.4644 - lr: 0.0010 - 674ms/epoch - 169ms/step\n",
            "Epoch 84/1000\n",
            "4/4 - 1s - loss: 0.5749 - mse: 0.5450 - val_loss: 0.4620 - val_mse: 0.4620 - lr: 0.0010 - 670ms/epoch - 167ms/step\n",
            "Epoch 85/1000\n",
            "4/4 - 1s - loss: 0.5736 - mse: 0.5437 - val_loss: 0.4595 - val_mse: 0.4595 - lr: 0.0010 - 654ms/epoch - 164ms/step\n",
            "Epoch 86/1000\n",
            "4/4 - 1s - loss: 0.5711 - mse: 0.5412 - val_loss: 0.4568 - val_mse: 0.4568 - lr: 0.0010 - 665ms/epoch - 166ms/step\n",
            "Epoch 87/1000\n",
            "4/4 - 1s - loss: 0.5688 - mse: 0.5391 - val_loss: 0.4544 - val_mse: 0.4544 - lr: 0.0010 - 667ms/epoch - 167ms/step\n",
            "Epoch 88/1000\n",
            "4/4 - 1s - loss: 0.5662 - mse: 0.5366 - val_loss: 0.4523 - val_mse: 0.4523 - lr: 0.0010 - 657ms/epoch - 164ms/step\n",
            "Epoch 89/1000\n",
            "4/4 - 1s - loss: 0.5640 - mse: 0.5346 - val_loss: 0.4506 - val_mse: 0.4506 - lr: 0.0010 - 655ms/epoch - 164ms/step\n",
            "Epoch 90/1000\n",
            "4/4 - 1s - loss: 0.5616 - mse: 0.5324 - val_loss: 0.4486 - val_mse: 0.4486 - lr: 0.0010 - 664ms/epoch - 166ms/step\n",
            "Epoch 91/1000\n",
            "4/4 - 1s - loss: 0.5606 - mse: 0.5313 - val_loss: 0.4467 - val_mse: 0.4467 - lr: 0.0010 - 655ms/epoch - 164ms/step\n",
            "Epoch 92/1000\n",
            "4/4 - 1s - loss: 0.5574 - mse: 0.5284 - val_loss: 0.4450 - val_mse: 0.4450 - lr: 0.0010 - 661ms/epoch - 165ms/step\n",
            "Epoch 93/1000\n",
            "4/4 - 1s - loss: 0.5565 - mse: 0.5275 - val_loss: 0.4435 - val_mse: 0.4435 - lr: 0.0010 - 656ms/epoch - 164ms/step\n",
            "Epoch 94/1000\n",
            "4/4 - 1s - loss: 0.5529 - mse: 0.5243 - val_loss: 0.4416 - val_mse: 0.4416 - lr: 0.0010 - 666ms/epoch - 166ms/step\n",
            "Epoch 95/1000\n",
            "4/4 - 1s - loss: 0.5544 - mse: 0.5254 - val_loss: 0.4397 - val_mse: 0.4397 - lr: 0.0010 - 664ms/epoch - 166ms/step\n",
            "Epoch 96/1000\n",
            "4/4 - 1s - loss: 0.5509 - mse: 0.5221 - val_loss: 0.4379 - val_mse: 0.4379 - lr: 0.0010 - 661ms/epoch - 165ms/step\n",
            "Epoch 97/1000\n",
            "4/4 - 1s - loss: 0.5477 - mse: 0.5192 - val_loss: 0.4363 - val_mse: 0.4363 - lr: 0.0010 - 671ms/epoch - 168ms/step\n",
            "Epoch 98/1000\n",
            "4/4 - 1s - loss: 0.5456 - mse: 0.5172 - val_loss: 0.4348 - val_mse: 0.4348 - lr: 0.0010 - 662ms/epoch - 165ms/step\n",
            "Epoch 99/1000\n",
            "4/4 - 1s - loss: 0.5439 - mse: 0.5155 - val_loss: 0.4335 - val_mse: 0.4335 - lr: 0.0010 - 669ms/epoch - 167ms/step\n",
            "Epoch 100/1000\n",
            "4/4 - 1s - loss: 0.5415 - mse: 0.5134 - val_loss: 0.4321 - val_mse: 0.4321 - lr: 0.0010 - 670ms/epoch - 168ms/step\n",
            "Epoch 101/1000\n",
            "4/4 - 1s - loss: 0.5426 - mse: 0.5144 - val_loss: 0.4309 - val_mse: 0.4309 - lr: 0.0010 - 663ms/epoch - 166ms/step\n",
            "Epoch 102/1000\n",
            "4/4 - 1s - loss: 0.5406 - mse: 0.5123 - val_loss: 0.4294 - val_mse: 0.4294 - lr: 0.0010 - 657ms/epoch - 164ms/step\n",
            "Epoch 103/1000\n",
            "4/4 - 1s - loss: 0.5390 - mse: 0.5109 - val_loss: 0.4279 - val_mse: 0.4279 - lr: 0.0010 - 673ms/epoch - 168ms/step\n",
            "Epoch 104/1000\n",
            "4/4 - 1s - loss: 0.5364 - mse: 0.5084 - val_loss: 0.4264 - val_mse: 0.4264 - lr: 0.0010 - 659ms/epoch - 165ms/step\n",
            "Epoch 105/1000\n",
            "4/4 - 1s - loss: 0.5352 - mse: 0.5074 - val_loss: 0.4252 - val_mse: 0.4252 - lr: 0.0010 - 663ms/epoch - 166ms/step\n",
            "Epoch 106/1000\n",
            "4/4 - 1s - loss: 0.5335 - mse: 0.5057 - val_loss: 0.4242 - val_mse: 0.4242 - lr: 0.0010 - 661ms/epoch - 165ms/step\n",
            "Epoch 107/1000\n",
            "4/4 - 1s - loss: 0.5319 - mse: 0.5042 - val_loss: 0.4233 - val_mse: 0.4233 - lr: 0.0010 - 666ms/epoch - 166ms/step\n",
            "Epoch 108/1000\n",
            "4/4 - 1s - loss: 0.5316 - mse: 0.5039 - val_loss: 0.4227 - val_mse: 0.4227 - lr: 0.0010 - 655ms/epoch - 164ms/step\n",
            "Epoch 109/1000\n",
            "4/4 - 1s - loss: 0.5298 - mse: 0.5022 - val_loss: 0.4220 - val_mse: 0.4220 - lr: 0.0010 - 656ms/epoch - 164ms/step\n",
            "Epoch 110/1000\n",
            "4/4 - 1s - loss: 0.5283 - mse: 0.5009 - val_loss: 0.4207 - val_mse: 0.4207 - lr: 0.0010 - 666ms/epoch - 167ms/step\n",
            "Epoch 111/1000\n",
            "4/4 - 1s - loss: 0.5267 - mse: 0.4993 - val_loss: 0.4195 - val_mse: 0.4195 - lr: 0.0010 - 653ms/epoch - 163ms/step\n",
            "Epoch 112/1000\n",
            "4/4 - 1s - loss: 0.5251 - mse: 0.4976 - val_loss: 0.4189 - val_mse: 0.4189 - lr: 0.0010 - 665ms/epoch - 166ms/step\n",
            "Epoch 113/1000\n",
            "4/4 - 1s - loss: 0.5228 - mse: 0.4957 - val_loss: 0.4185 - val_mse: 0.4185 - lr: 0.0010 - 643ms/epoch - 161ms/step\n",
            "Epoch 114/1000\n",
            "4/4 - 1s - loss: 0.5218 - mse: 0.4947 - val_loss: 0.4179 - val_mse: 0.4179 - lr: 0.0010 - 701ms/epoch - 175ms/step\n",
            "Epoch 115/1000\n",
            "4/4 - 1s - loss: 0.5203 - mse: 0.4933 - val_loss: 0.4174 - val_mse: 0.4174 - lr: 0.0010 - 662ms/epoch - 165ms/step\n",
            "Epoch 116/1000\n",
            "4/4 - 1s - loss: 0.5208 - mse: 0.4936 - val_loss: 0.4170 - val_mse: 0.4170 - lr: 0.0010 - 672ms/epoch - 168ms/step\n",
            "Epoch 117/1000\n",
            "4/4 - 1s - loss: 0.5186 - mse: 0.4915 - val_loss: 0.4164 - val_mse: 0.4164 - lr: 0.0010 - 662ms/epoch - 165ms/step\n",
            "Epoch 118/1000\n",
            "4/4 - 1s - loss: 0.5171 - mse: 0.4903 - val_loss: 0.4159 - val_mse: 0.4159 - lr: 0.0010 - 656ms/epoch - 164ms/step\n",
            "Epoch 119/1000\n",
            "4/4 - 1s - loss: 0.5167 - mse: 0.4898 - val_loss: 0.4154 - val_mse: 0.4154 - lr: 0.0010 - 679ms/epoch - 170ms/step\n",
            "Epoch 120/1000\n",
            "4/4 - 1s - loss: 0.5169 - mse: 0.4900 - val_loss: 0.4150 - val_mse: 0.4150 - lr: 0.0010 - 659ms/epoch - 165ms/step\n",
            "Epoch 121/1000\n",
            "4/4 - 1s - loss: 0.5152 - mse: 0.4884 - val_loss: 0.4146 - val_mse: 0.4146 - lr: 0.0010 - 676ms/epoch - 169ms/step\n",
            "Epoch 122/1000\n",
            "4/4 - 1s - loss: 0.5148 - mse: 0.4881 - val_loss: 0.4142 - val_mse: 0.4142 - lr: 0.0010 - 670ms/epoch - 168ms/step\n",
            "Epoch 123/1000\n",
            "4/4 - 1s - loss: 0.5116 - mse: 0.4849 - val_loss: 0.4139 - val_mse: 0.4139 - lr: 0.0010 - 674ms/epoch - 168ms/step\n",
            "Epoch 124/1000\n",
            "4/4 - 1s - loss: 0.5100 - mse: 0.4834 - val_loss: 0.4136 - val_mse: 0.4136 - lr: 0.0010 - 666ms/epoch - 166ms/step\n",
            "Epoch 125/1000\n",
            "4/4 - 1s - loss: 0.5091 - mse: 0.4826 - val_loss: 0.4132 - val_mse: 0.4132 - lr: 0.0010 - 661ms/epoch - 165ms/step\n",
            "Epoch 126/1000\n",
            "4/4 - 1s - loss: 0.5089 - mse: 0.4824 - val_loss: 0.4128 - val_mse: 0.4128 - lr: 0.0010 - 676ms/epoch - 169ms/step\n",
            "Epoch 127/1000\n",
            "4/4 - 1s - loss: 0.5086 - mse: 0.4822 - val_loss: 0.4125 - val_mse: 0.4125 - lr: 0.0010 - 658ms/epoch - 165ms/step\n",
            "Epoch 128/1000\n",
            "4/4 - 1s - loss: 0.5089 - mse: 0.4823 - val_loss: 0.4124 - val_mse: 0.4124 - lr: 0.0010 - 666ms/epoch - 166ms/step\n",
            "Epoch 129/1000\n",
            "4/4 - 1s - loss: 0.5075 - mse: 0.4812 - val_loss: 0.4126 - val_mse: 0.4126 - lr: 0.0010 - 683ms/epoch - 171ms/step\n",
            "Epoch 130/1000\n",
            "4/4 - 1s - loss: 0.5054 - mse: 0.4789 - val_loss: 0.4125 - val_mse: 0.4125 - lr: 0.0010 - 658ms/epoch - 165ms/step\n",
            "Epoch 131/1000\n",
            "4/4 - 1s - loss: 0.5050 - mse: 0.4786 - val_loss: 0.4123 - val_mse: 0.4123 - lr: 0.0010 - 653ms/epoch - 163ms/step\n",
            "Epoch 132/1000\n",
            "4/4 - 1s - loss: 0.5039 - mse: 0.4776 - val_loss: 0.4118 - val_mse: 0.4118 - lr: 0.0010 - 659ms/epoch - 165ms/step\n",
            "Epoch 133/1000\n",
            "4/4 - 1s - loss: 0.5017 - mse: 0.4756 - val_loss: 0.4114 - val_mse: 0.4114 - lr: 0.0010 - 668ms/epoch - 167ms/step\n",
            "Epoch 134/1000\n",
            "4/4 - 1s - loss: 0.5015 - mse: 0.4753 - val_loss: 0.4112 - val_mse: 0.4112 - lr: 0.0010 - 649ms/epoch - 162ms/step\n",
            "Epoch 135/1000\n",
            "4/4 - 1s - loss: 0.5014 - mse: 0.4751 - val_loss: 0.4113 - val_mse: 0.4113 - lr: 0.0010 - 667ms/epoch - 167ms/step\n",
            "Epoch 136/1000\n",
            "4/4 - 1s - loss: 0.5000 - mse: 0.4740 - val_loss: 0.4113 - val_mse: 0.4113 - lr: 0.0010 - 663ms/epoch - 166ms/step\n",
            "Epoch 137/1000\n",
            "4/4 - 1s - loss: 0.5002 - mse: 0.4741 - val_loss: 0.4113 - val_mse: 0.4113 - lr: 0.0010 - 658ms/epoch - 165ms/step\n",
            "Epoch 138/1000\n",
            "4/4 - 1s - loss: 0.4986 - mse: 0.4726 - val_loss: 0.4112 - val_mse: 0.4112 - lr: 0.0010 - 664ms/epoch - 166ms/step\n",
            "Epoch 139/1000\n",
            "4/4 - 1s - loss: 0.4975 - mse: 0.4715 - val_loss: 0.4110 - val_mse: 0.4110 - lr: 0.0010 - 652ms/epoch - 163ms/step\n",
            "Epoch 140/1000\n",
            "4/4 - 1s - loss: 0.4979 - mse: 0.4719 - val_loss: 0.4109 - val_mse: 0.4109 - lr: 0.0010 - 656ms/epoch - 164ms/step\n",
            "Epoch 141/1000\n",
            "4/4 - 1s - loss: 0.4981 - mse: 0.4722 - val_loss: 0.4108 - val_mse: 0.4108 - lr: 0.0010 - 675ms/epoch - 169ms/step\n",
            "Epoch 142/1000\n",
            "4/4 - 1s - loss: 0.4952 - mse: 0.4694 - val_loss: 0.4109 - val_mse: 0.4109 - lr: 0.0010 - 657ms/epoch - 164ms/step\n",
            "Epoch 143/1000\n",
            "4/4 - 1s - loss: 0.4956 - mse: 0.4697 - val_loss: 0.4109 - val_mse: 0.4109 - lr: 0.0010 - 658ms/epoch - 165ms/step\n",
            "Epoch 144/1000\n",
            "4/4 - 1s - loss: 0.4945 - mse: 0.4687 - val_loss: 0.4109 - val_mse: 0.4109 - lr: 0.0010 - 665ms/epoch - 166ms/step\n",
            "Epoch 145/1000\n",
            "4/4 - 1s - loss: 0.4939 - mse: 0.4682 - val_loss: 0.4109 - val_mse: 0.4109 - lr: 0.0010 - 654ms/epoch - 163ms/step\n",
            "Epoch 146/1000\n",
            "4/4 - 1s - loss: 0.4934 - mse: 0.4677 - val_loss: 0.4108 - val_mse: 0.4108 - lr: 0.0010 - 642ms/epoch - 161ms/step\n",
            "Epoch 147/1000\n",
            "4/4 - 1s - loss: 0.4927 - mse: 0.4670 - val_loss: 0.4106 - val_mse: 0.4106 - lr: 0.0010 - 658ms/epoch - 164ms/step\n",
            "Epoch 148/1000\n",
            "4/4 - 1s - loss: 0.4908 - mse: 0.4651 - val_loss: 0.4105 - val_mse: 0.4105 - lr: 0.0010 - 657ms/epoch - 164ms/step\n",
            "Epoch 149/1000\n",
            "4/4 - 1s - loss: 0.4918 - mse: 0.4660 - val_loss: 0.4105 - val_mse: 0.4105 - lr: 0.0010 - 662ms/epoch - 165ms/step\n",
            "Epoch 150/1000\n",
            "4/4 - 1s - loss: 0.4901 - mse: 0.4646 - val_loss: 0.4107 - val_mse: 0.4107 - lr: 0.0010 - 668ms/epoch - 167ms/step\n",
            "Epoch 151/1000\n",
            "4/4 - 1s - loss: 0.4886 - mse: 0.4631 - val_loss: 0.4111 - val_mse: 0.4111 - lr: 0.0010 - 653ms/epoch - 163ms/step\n",
            "Epoch 152/1000\n",
            "4/4 - 1s - loss: 0.4895 - mse: 0.4639 - val_loss: 0.4113 - val_mse: 0.4113 - lr: 0.0010 - 651ms/epoch - 163ms/step\n",
            "Epoch 153/1000\n",
            "4/4 - 1s - loss: 0.4877 - mse: 0.4622 - val_loss: 0.4112 - val_mse: 0.4112 - lr: 0.0010 - 682ms/epoch - 171ms/step\n",
            "Epoch 154/1000\n",
            "\n",
            "Epoch 154: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "4/4 - 1s - loss: 0.4874 - mse: 0.4620 - val_loss: 0.4109 - val_mse: 0.4109 - lr: 0.0010 - 653ms/epoch - 163ms/step\n",
            "Epoch 155/1000\n",
            "4/4 - 1s - loss: 0.4881 - mse: 0.4626 - val_loss: 0.4110 - val_mse: 0.4110 - lr: 1.0000e-04 - 665ms/epoch - 166ms/step\n",
            "Epoch 156/1000\n",
            "4/4 - 1s - loss: 0.4870 - mse: 0.4615 - val_loss: 0.4110 - val_mse: 0.4110 - lr: 1.0000e-04 - 653ms/epoch - 163ms/step\n",
            "Epoch 157/1000\n",
            "4/4 - 1s - loss: 0.4862 - mse: 0.4609 - val_loss: 0.4111 - val_mse: 0.4111 - lr: 1.0000e-04 - 652ms/epoch - 163ms/step\n",
            "Epoch 158/1000\n",
            "4/4 - 1s - loss: 0.4877 - mse: 0.4622 - val_loss: 0.4112 - val_mse: 0.4112 - lr: 1.0000e-04 - 666ms/epoch - 166ms/step\n",
            "Epoch 158: early stopping\n",
            "==================================================\n",
            "Step 14\n",
            "==================================================\n",
            "Epoch 1/1000\n",
            "4/4 - 4s - loss: 4.3948 - mse: 4.1700 - val_loss: 0.9236 - val_mse: 0.9236 - lr: 0.0010 - 4s/epoch - 973ms/step\n",
            "Epoch 2/1000\n",
            "4/4 - 1s - loss: 2.5839 - mse: 2.4635 - val_loss: 0.8563 - val_mse: 0.8563 - lr: 0.0010 - 671ms/epoch - 168ms/step\n",
            "Epoch 3/1000\n",
            "4/4 - 1s - loss: 1.9588 - mse: 1.8640 - val_loss: 0.8340 - val_mse: 0.8340 - lr: 0.0010 - 665ms/epoch - 166ms/step\n",
            "Epoch 4/1000\n",
            "4/4 - 1s - loss: 1.6413 - mse: 1.5594 - val_loss: 0.8388 - val_mse: 0.8388 - lr: 0.0010 - 673ms/epoch - 168ms/step\n",
            "Epoch 5/1000\n",
            "4/4 - 1s - loss: 1.4597 - mse: 1.3853 - val_loss: 0.8529 - val_mse: 0.8529 - lr: 0.0010 - 655ms/epoch - 164ms/step\n",
            "Epoch 6/1000\n",
            "4/4 - 1s - loss: 1.3671 - mse: 1.2961 - val_loss: 0.8604 - val_mse: 0.8604 - lr: 0.0010 - 658ms/epoch - 164ms/step\n",
            "Epoch 7/1000\n",
            "4/4 - 1s - loss: 1.2846 - mse: 1.2171 - val_loss: 0.8578 - val_mse: 0.8578 - lr: 0.0010 - 674ms/epoch - 168ms/step\n",
            "Epoch 8/1000\n",
            "4/4 - 1s - loss: 1.2250 - mse: 1.1596 - val_loss: 0.8482 - val_mse: 0.8482 - lr: 0.0010 - 658ms/epoch - 164ms/step\n",
            "Epoch 9/1000\n",
            "4/4 - 1s - loss: 1.1691 - mse: 1.1055 - val_loss: 0.8386 - val_mse: 0.8386 - lr: 0.0010 - 685ms/epoch - 171ms/step\n",
            "Epoch 10/1000\n",
            "4/4 - 1s - loss: 1.1269 - mse: 1.0666 - val_loss: 0.8322 - val_mse: 0.8322 - lr: 0.0010 - 662ms/epoch - 166ms/step\n",
            "Epoch 11/1000\n",
            "4/4 - 1s - loss: 1.0911 - mse: 1.0320 - val_loss: 0.8302 - val_mse: 0.8302 - lr: 0.0010 - 667ms/epoch - 167ms/step\n",
            "Epoch 12/1000\n",
            "4/4 - 1s - loss: 1.0635 - mse: 1.0057 - val_loss: 0.8321 - val_mse: 0.8321 - lr: 0.0010 - 662ms/epoch - 166ms/step\n",
            "Epoch 13/1000\n",
            "4/4 - 1s - loss: 1.0360 - mse: 0.9802 - val_loss: 0.8375 - val_mse: 0.8375 - lr: 0.0010 - 663ms/epoch - 166ms/step\n",
            "Epoch 14/1000\n",
            "4/4 - 1s - loss: 1.0177 - mse: 0.9629 - val_loss: 0.8418 - val_mse: 0.8418 - lr: 0.0010 - 656ms/epoch - 164ms/step\n",
            "Epoch 15/1000\n",
            "4/4 - 1s - loss: 1.0023 - mse: 0.9480 - val_loss: 0.8439 - val_mse: 0.8439 - lr: 0.0010 - 680ms/epoch - 170ms/step\n",
            "Epoch 16/1000\n",
            "4/4 - 1s - loss: 0.9854 - mse: 0.9325 - val_loss: 0.8425 - val_mse: 0.8425 - lr: 0.0010 - 665ms/epoch - 166ms/step\n",
            "Epoch 17/1000\n",
            "4/4 - 1s - loss: 0.9645 - mse: 0.9134 - val_loss: 0.8415 - val_mse: 0.8415 - lr: 0.0010 - 677ms/epoch - 169ms/step\n",
            "Epoch 18/1000\n",
            "\n",
            "Epoch 18: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "4/4 - 1s - loss: 0.9482 - mse: 0.8981 - val_loss: 0.8417 - val_mse: 0.8417 - lr: 0.0010 - 670ms/epoch - 168ms/step\n",
            "Epoch 19/1000\n",
            "4/4 - 1s - loss: 0.9395 - mse: 0.8893 - val_loss: 0.8479 - val_mse: 0.8479 - lr: 1.0000e-04 - 690ms/epoch - 172ms/step\n",
            "Epoch 20/1000\n",
            "4/4 - 1s - loss: 0.9410 - mse: 0.8913 - val_loss: 0.8544 - val_mse: 0.8544 - lr: 1.0000e-04 - 671ms/epoch - 168ms/step\n",
            "Epoch 21/1000\n",
            "4/4 - 1s - loss: 0.9359 - mse: 0.8861 - val_loss: 0.8608 - val_mse: 0.8608 - lr: 1.0000e-04 - 664ms/epoch - 166ms/step\n",
            "Epoch 21: early stopping\n",
            "==================================================\n",
            "Step 15\n",
            "==================================================\n",
            "Epoch 1/1000\n",
            "4/4 - 4s - loss: 3.2087 - mse: 3.0044 - val_loss: 0.9396 - val_mse: 0.9396 - lr: 0.0010 - 4s/epoch - 954ms/step\n",
            "Epoch 2/1000\n",
            "4/4 - 1s - loss: 1.9680 - mse: 1.8469 - val_loss: 0.8691 - val_mse: 0.8691 - lr: 0.0010 - 1s/epoch - 261ms/step\n",
            "Epoch 3/1000\n",
            "4/4 - 1s - loss: 1.7556 - mse: 1.6481 - val_loss: 0.8479 - val_mse: 0.8479 - lr: 0.0010 - 1s/epoch - 257ms/step\n",
            "Epoch 4/1000\n",
            "4/4 - 1s - loss: 1.5623 - mse: 1.4671 - val_loss: 0.8550 - val_mse: 0.8550 - lr: 0.0010 - 854ms/epoch - 213ms/step\n",
            "Epoch 5/1000\n",
            "4/4 - 1s - loss: 1.3928 - mse: 1.3110 - val_loss: 0.8714 - val_mse: 0.8714 - lr: 0.0010 - 716ms/epoch - 179ms/step\n",
            "Epoch 6/1000\n",
            "4/4 - 1s - loss: 1.3085 - mse: 1.2329 - val_loss: 0.8801 - val_mse: 0.8801 - lr: 0.0010 - 691ms/epoch - 173ms/step\n",
            "Epoch 7/1000\n",
            "4/4 - 1s - loss: 1.2483 - mse: 1.1759 - val_loss: 0.8761 - val_mse: 0.8761 - lr: 0.0010 - 695ms/epoch - 174ms/step\n",
            "Epoch 8/1000\n",
            "4/4 - 1s - loss: 1.1982 - mse: 1.1281 - val_loss: 0.8642 - val_mse: 0.8642 - lr: 0.0010 - 702ms/epoch - 176ms/step\n",
            "Epoch 9/1000\n",
            "4/4 - 1s - loss: 1.1503 - mse: 1.0829 - val_loss: 0.8508 - val_mse: 0.8508 - lr: 0.0010 - 748ms/epoch - 187ms/step\n",
            "Epoch 10/1000\n",
            "4/4 - 1s - loss: 1.1251 - mse: 1.0591 - val_loss: 0.8406 - val_mse: 0.8406 - lr: 0.0010 - 695ms/epoch - 174ms/step\n",
            "Epoch 11/1000\n",
            "4/4 - 1s - loss: 1.0919 - mse: 1.0287 - val_loss: 0.8346 - val_mse: 0.8346 - lr: 0.0010 - 697ms/epoch - 174ms/step\n",
            "Epoch 12/1000\n",
            "4/4 - 1s - loss: 1.0641 - mse: 1.0019 - val_loss: 0.8310 - val_mse: 0.8310 - lr: 0.0010 - 696ms/epoch - 174ms/step\n",
            "Epoch 13/1000\n",
            "4/4 - 1s - loss: 1.0410 - mse: 0.9815 - val_loss: 0.8277 - val_mse: 0.8277 - lr: 0.0010 - 674ms/epoch - 168ms/step\n",
            "Epoch 14/1000\n",
            "4/4 - 1s - loss: 1.0247 - mse: 0.9660 - val_loss: 0.8234 - val_mse: 0.8234 - lr: 0.0010 - 690ms/epoch - 173ms/step\n",
            "Epoch 15/1000\n",
            "4/4 - 1s - loss: 1.0053 - mse: 0.9478 - val_loss: 0.8181 - val_mse: 0.8181 - lr: 0.0010 - 699ms/epoch - 175ms/step\n",
            "Epoch 16/1000\n",
            "4/4 - 1s - loss: 0.9831 - mse: 0.9271 - val_loss: 0.8125 - val_mse: 0.8125 - lr: 0.0010 - 700ms/epoch - 175ms/step\n",
            "Epoch 17/1000\n",
            "4/4 - 1s - loss: 0.9751 - mse: 0.9198 - val_loss: 0.8081 - val_mse: 0.8081 - lr: 0.0010 - 696ms/epoch - 174ms/step\n",
            "Epoch 18/1000\n",
            "4/4 - 1s - loss: 0.9571 - mse: 0.9028 - val_loss: 0.8043 - val_mse: 0.8043 - lr: 0.0010 - 701ms/epoch - 175ms/step\n",
            "Epoch 19/1000\n",
            "4/4 - 1s - loss: 0.9393 - mse: 0.8867 - val_loss: 0.8005 - val_mse: 0.8005 - lr: 0.0010 - 696ms/epoch - 174ms/step\n",
            "Epoch 20/1000\n",
            "4/4 - 1s - loss: 0.9312 - mse: 0.8794 - val_loss: 0.7973 - val_mse: 0.7973 - lr: 0.0010 - 685ms/epoch - 171ms/step\n",
            "Epoch 21/1000\n",
            "4/4 - 1s - loss: 0.9205 - mse: 0.8693 - val_loss: 0.7932 - val_mse: 0.7932 - lr: 0.0010 - 691ms/epoch - 173ms/step\n",
            "Epoch 22/1000\n",
            "4/4 - 1s - loss: 0.9040 - mse: 0.8540 - val_loss: 0.7875 - val_mse: 0.7875 - lr: 0.0010 - 688ms/epoch - 172ms/step\n",
            "Epoch 23/1000\n",
            "4/4 - 1s - loss: 0.8929 - mse: 0.8435 - val_loss: 0.7817 - val_mse: 0.7817 - lr: 0.0010 - 705ms/epoch - 176ms/step\n",
            "Epoch 24/1000\n",
            "4/4 - 1s - loss: 0.8861 - mse: 0.8371 - val_loss: 0.7769 - val_mse: 0.7769 - lr: 0.0010 - 735ms/epoch - 184ms/step\n",
            "Epoch 25/1000\n",
            "4/4 - 1s - loss: 0.8721 - mse: 0.8242 - val_loss: 0.7724 - val_mse: 0.7724 - lr: 0.0010 - 688ms/epoch - 172ms/step\n",
            "Epoch 26/1000\n",
            "4/4 - 1s - loss: 0.8595 - mse: 0.8125 - val_loss: 0.7678 - val_mse: 0.7678 - lr: 0.0010 - 696ms/epoch - 174ms/step\n",
            "Epoch 27/1000\n",
            "4/4 - 1s - loss: 0.8506 - mse: 0.8042 - val_loss: 0.7622 - val_mse: 0.7622 - lr: 0.0010 - 698ms/epoch - 174ms/step\n",
            "Epoch 28/1000\n",
            "4/4 - 1s - loss: 0.8412 - mse: 0.7952 - val_loss: 0.7563 - val_mse: 0.7563 - lr: 0.0010 - 694ms/epoch - 173ms/step\n",
            "Epoch 29/1000\n",
            "4/4 - 1s - loss: 0.8297 - mse: 0.7848 - val_loss: 0.7496 - val_mse: 0.7496 - lr: 0.0010 - 686ms/epoch - 171ms/step\n",
            "Epoch 30/1000\n",
            "4/4 - 1s - loss: 0.8177 - mse: 0.7734 - val_loss: 0.7443 - val_mse: 0.7443 - lr: 0.0010 - 701ms/epoch - 175ms/step\n",
            "Epoch 31/1000\n",
            "4/4 - 1s - loss: 0.8151 - mse: 0.7707 - val_loss: 0.7400 - val_mse: 0.7400 - lr: 0.0010 - 700ms/epoch - 175ms/step\n",
            "Epoch 32/1000\n",
            "4/4 - 1s - loss: 0.7995 - mse: 0.7566 - val_loss: 0.7356 - val_mse: 0.7356 - lr: 0.0010 - 687ms/epoch - 172ms/step\n",
            "Epoch 33/1000\n",
            "4/4 - 1s - loss: 0.7952 - mse: 0.7528 - val_loss: 0.7309 - val_mse: 0.7309 - lr: 0.0010 - 681ms/epoch - 170ms/step\n",
            "Epoch 34/1000\n",
            "4/4 - 1s - loss: 0.7873 - mse: 0.7451 - val_loss: 0.7243 - val_mse: 0.7243 - lr: 0.0010 - 704ms/epoch - 176ms/step\n",
            "Epoch 35/1000\n",
            "4/4 - 1s - loss: 0.7801 - mse: 0.7382 - val_loss: 0.7182 - val_mse: 0.7182 - lr: 0.0010 - 699ms/epoch - 175ms/step\n",
            "Epoch 36/1000\n",
            "4/4 - 1s - loss: 0.7734 - mse: 0.7319 - val_loss: 0.7123 - val_mse: 0.7123 - lr: 0.0010 - 693ms/epoch - 173ms/step\n",
            "Epoch 37/1000\n",
            "4/4 - 1s - loss: 0.7648 - mse: 0.7238 - val_loss: 0.7066 - val_mse: 0.7066 - lr: 0.0010 - 687ms/epoch - 172ms/step\n",
            "Epoch 38/1000\n",
            "4/4 - 1s - loss: 0.7548 - mse: 0.7143 - val_loss: 0.7005 - val_mse: 0.7005 - lr: 0.0010 - 712ms/epoch - 178ms/step\n",
            "Epoch 39/1000\n",
            "4/4 - 1s - loss: 0.7489 - mse: 0.7089 - val_loss: 0.6947 - val_mse: 0.6947 - lr: 0.0010 - 716ms/epoch - 179ms/step\n",
            "Epoch 40/1000\n",
            "4/4 - 1s - loss: 0.7427 - mse: 0.7033 - val_loss: 0.6887 - val_mse: 0.6887 - lr: 0.0010 - 667ms/epoch - 167ms/step\n",
            "Epoch 41/1000\n",
            "4/4 - 1s - loss: 0.7364 - mse: 0.6972 - val_loss: 0.6816 - val_mse: 0.6816 - lr: 0.0010 - 695ms/epoch - 174ms/step\n",
            "Epoch 42/1000\n",
            "4/4 - 1s - loss: 0.7297 - mse: 0.6908 - val_loss: 0.6755 - val_mse: 0.6755 - lr: 0.0010 - 695ms/epoch - 174ms/step\n",
            "Epoch 43/1000\n",
            "4/4 - 1s - loss: 0.7232 - mse: 0.6848 - val_loss: 0.6695 - val_mse: 0.6695 - lr: 0.0010 - 700ms/epoch - 175ms/step\n",
            "Epoch 44/1000\n",
            "4/4 - 1s - loss: 0.7176 - mse: 0.6797 - val_loss: 0.6636 - val_mse: 0.6636 - lr: 0.0010 - 711ms/epoch - 178ms/step\n",
            "Epoch 45/1000\n",
            "4/4 - 1s - loss: 0.7101 - mse: 0.6726 - val_loss: 0.6575 - val_mse: 0.6575 - lr: 0.0010 - 703ms/epoch - 176ms/step\n",
            "Epoch 46/1000\n",
            "4/4 - 1s - loss: 0.7040 - mse: 0.6667 - val_loss: 0.6523 - val_mse: 0.6523 - lr: 0.0010 - 715ms/epoch - 179ms/step\n",
            "Epoch 47/1000\n",
            "4/4 - 1s - loss: 0.6959 - mse: 0.6591 - val_loss: 0.6475 - val_mse: 0.6475 - lr: 0.0010 - 720ms/epoch - 180ms/step\n",
            "Epoch 48/1000\n",
            "4/4 - 1s - loss: 0.6949 - mse: 0.6582 - val_loss: 0.6423 - val_mse: 0.6423 - lr: 0.0010 - 719ms/epoch - 180ms/step\n",
            "Epoch 49/1000\n",
            "4/4 - 1s - loss: 0.6881 - mse: 0.6520 - val_loss: 0.6359 - val_mse: 0.6359 - lr: 0.0010 - 679ms/epoch - 170ms/step\n",
            "Epoch 50/1000\n",
            "4/4 - 1s - loss: 0.6840 - mse: 0.6478 - val_loss: 0.6283 - val_mse: 0.6283 - lr: 0.0010 - 700ms/epoch - 175ms/step\n",
            "Epoch 51/1000\n",
            "4/4 - 1s - loss: 0.6775 - mse: 0.6417 - val_loss: 0.6212 - val_mse: 0.6212 - lr: 0.0010 - 715ms/epoch - 179ms/step\n",
            "Epoch 52/1000\n",
            "4/4 - 1s - loss: 0.6711 - mse: 0.6358 - val_loss: 0.6156 - val_mse: 0.6156 - lr: 0.0010 - 712ms/epoch - 178ms/step\n",
            "Epoch 53/1000\n",
            "4/4 - 1s - loss: 0.6711 - mse: 0.6358 - val_loss: 0.6096 - val_mse: 0.6096 - lr: 0.0010 - 721ms/epoch - 180ms/step\n",
            "Epoch 54/1000\n",
            "4/4 - 1s - loss: 0.6639 - mse: 0.6290 - val_loss: 0.6044 - val_mse: 0.6044 - lr: 0.0010 - 683ms/epoch - 171ms/step\n",
            "Epoch 55/1000\n",
            "4/4 - 1s - loss: 0.6577 - mse: 0.6232 - val_loss: 0.5992 - val_mse: 0.5992 - lr: 0.0010 - 701ms/epoch - 175ms/step\n",
            "Epoch 56/1000\n",
            "4/4 - 1s - loss: 0.6510 - mse: 0.6170 - val_loss: 0.5936 - val_mse: 0.5936 - lr: 0.0010 - 711ms/epoch - 178ms/step\n",
            "Epoch 57/1000\n",
            "4/4 - 1s - loss: 0.6514 - mse: 0.6171 - val_loss: 0.5872 - val_mse: 0.5872 - lr: 0.0010 - 701ms/epoch - 175ms/step\n",
            "Epoch 58/1000\n",
            "4/4 - 1s - loss: 0.6459 - mse: 0.6119 - val_loss: 0.5809 - val_mse: 0.5809 - lr: 0.0010 - 709ms/epoch - 177ms/step\n",
            "Epoch 59/1000\n",
            "4/4 - 1s - loss: 0.6429 - mse: 0.6091 - val_loss: 0.5752 - val_mse: 0.5752 - lr: 0.0010 - 697ms/epoch - 174ms/step\n",
            "Epoch 60/1000\n",
            "4/4 - 1s - loss: 0.6335 - mse: 0.6001 - val_loss: 0.5696 - val_mse: 0.5696 - lr: 0.0010 - 690ms/epoch - 173ms/step\n",
            "Epoch 61/1000\n",
            "4/4 - 1s - loss: 0.6296 - mse: 0.5966 - val_loss: 0.5646 - val_mse: 0.5646 - lr: 0.0010 - 698ms/epoch - 174ms/step\n",
            "Epoch 62/1000\n",
            "4/4 - 1s - loss: 0.6286 - mse: 0.5958 - val_loss: 0.5597 - val_mse: 0.5597 - lr: 0.0010 - 712ms/epoch - 178ms/step\n",
            "Epoch 63/1000\n",
            "4/4 - 1s - loss: 0.6240 - mse: 0.5912 - val_loss: 0.5541 - val_mse: 0.5541 - lr: 0.0010 - 700ms/epoch - 175ms/step\n",
            "Epoch 64/1000\n",
            "4/4 - 1s - loss: 0.6215 - mse: 0.5890 - val_loss: 0.5497 - val_mse: 0.5497 - lr: 0.0010 - 689ms/epoch - 172ms/step\n",
            "Epoch 65/1000\n",
            "4/4 - 1s - loss: 0.6167 - mse: 0.5841 - val_loss: 0.5450 - val_mse: 0.5450 - lr: 0.0010 - 714ms/epoch - 178ms/step\n",
            "Epoch 66/1000\n",
            "4/4 - 1s - loss: 0.6120 - mse: 0.5798 - val_loss: 0.5399 - val_mse: 0.5399 - lr: 0.0010 - 727ms/epoch - 182ms/step\n",
            "Epoch 67/1000\n",
            "4/4 - 1s - loss: 0.6091 - mse: 0.5770 - val_loss: 0.5345 - val_mse: 0.5345 - lr: 0.0010 - 743ms/epoch - 186ms/step\n",
            "Epoch 68/1000\n",
            "4/4 - 1s - loss: 0.6078 - mse: 0.5759 - val_loss: 0.5300 - val_mse: 0.5300 - lr: 0.0010 - 706ms/epoch - 176ms/step\n",
            "Epoch 69/1000\n",
            "4/4 - 1s - loss: 0.6053 - mse: 0.5736 - val_loss: 0.5258 - val_mse: 0.5258 - lr: 0.0010 - 707ms/epoch - 177ms/step\n",
            "Epoch 70/1000\n",
            "4/4 - 1s - loss: 0.6017 - mse: 0.5701 - val_loss: 0.5216 - val_mse: 0.5216 - lr: 0.0010 - 706ms/epoch - 176ms/step\n",
            "Epoch 71/1000\n",
            "4/4 - 1s - loss: 0.5978 - mse: 0.5665 - val_loss: 0.5179 - val_mse: 0.5179 - lr: 0.0010 - 681ms/epoch - 170ms/step\n",
            "Epoch 72/1000\n",
            "4/4 - 1s - loss: 0.5927 - mse: 0.5615 - val_loss: 0.5136 - val_mse: 0.5136 - lr: 0.0010 - 698ms/epoch - 174ms/step\n",
            "Epoch 73/1000\n",
            "4/4 - 1s - loss: 0.5914 - mse: 0.5604 - val_loss: 0.5087 - val_mse: 0.5087 - lr: 0.0010 - 718ms/epoch - 179ms/step\n",
            "Epoch 74/1000\n",
            "4/4 - 1s - loss: 0.5881 - mse: 0.5571 - val_loss: 0.5037 - val_mse: 0.5037 - lr: 0.0010 - 711ms/epoch - 178ms/step\n",
            "Epoch 75/1000\n",
            "4/4 - 1s - loss: 0.5850 - mse: 0.5543 - val_loss: 0.4989 - val_mse: 0.4989 - lr: 0.0010 - 698ms/epoch - 175ms/step\n",
            "Epoch 76/1000\n",
            "4/4 - 1s - loss: 0.5841 - mse: 0.5536 - val_loss: 0.4947 - val_mse: 0.4947 - lr: 0.0010 - 716ms/epoch - 179ms/step\n",
            "Epoch 77/1000\n",
            "4/4 - 1s - loss: 0.5806 - mse: 0.5502 - val_loss: 0.4908 - val_mse: 0.4908 - lr: 0.0010 - 714ms/epoch - 178ms/step\n",
            "Epoch 78/1000\n",
            "4/4 - 1s - loss: 0.5765 - mse: 0.5462 - val_loss: 0.4877 - val_mse: 0.4877 - lr: 0.0010 - 712ms/epoch - 178ms/step\n",
            "Epoch 79/1000\n",
            "4/4 - 1s - loss: 0.5740 - mse: 0.5440 - val_loss: 0.4847 - val_mse: 0.4847 - lr: 0.0010 - 707ms/epoch - 177ms/step\n",
            "Epoch 80/1000\n",
            "4/4 - 1s - loss: 0.5712 - mse: 0.5410 - val_loss: 0.4815 - val_mse: 0.4815 - lr: 0.0010 - 704ms/epoch - 176ms/step\n",
            "Epoch 81/1000\n",
            "4/4 - 1s - loss: 0.5673 - mse: 0.5375 - val_loss: 0.4781 - val_mse: 0.4781 - lr: 0.0010 - 696ms/epoch - 174ms/step\n",
            "Epoch 82/1000\n",
            "4/4 - 1s - loss: 0.5658 - mse: 0.5359 - val_loss: 0.4746 - val_mse: 0.4746 - lr: 0.0010 - 762ms/epoch - 190ms/step\n",
            "Epoch 83/1000\n",
            "4/4 - 1s - loss: 0.5635 - mse: 0.5336 - val_loss: 0.4711 - val_mse: 0.4711 - lr: 0.0010 - 723ms/epoch - 181ms/step\n",
            "Epoch 84/1000\n",
            "4/4 - 1s - loss: 0.5608 - mse: 0.5311 - val_loss: 0.4675 - val_mse: 0.4675 - lr: 0.0010 - 708ms/epoch - 177ms/step\n",
            "Epoch 85/1000\n",
            "4/4 - 1s - loss: 0.5602 - mse: 0.5304 - val_loss: 0.4646 - val_mse: 0.4646 - lr: 0.0010 - 703ms/epoch - 176ms/step\n",
            "Epoch 86/1000\n",
            "4/4 - 1s - loss: 0.5589 - mse: 0.5295 - val_loss: 0.4620 - val_mse: 0.4620 - lr: 0.0010 - 705ms/epoch - 176ms/step\n",
            "Epoch 87/1000\n",
            "4/4 - 1s - loss: 0.5540 - mse: 0.5250 - val_loss: 0.4594 - val_mse: 0.4594 - lr: 0.0010 - 711ms/epoch - 178ms/step\n",
            "Epoch 88/1000\n",
            "4/4 - 1s - loss: 0.5520 - mse: 0.5228 - val_loss: 0.4566 - val_mse: 0.4566 - lr: 0.0010 - 696ms/epoch - 174ms/step\n",
            "Epoch 89/1000\n",
            "4/4 - 1s - loss: 0.5503 - mse: 0.5212 - val_loss: 0.4541 - val_mse: 0.4541 - lr: 0.0010 - 716ms/epoch - 179ms/step\n",
            "Epoch 90/1000\n",
            "4/4 - 1s - loss: 0.5493 - mse: 0.5204 - val_loss: 0.4514 - val_mse: 0.4514 - lr: 0.0010 - 699ms/epoch - 175ms/step\n",
            "Epoch 91/1000\n",
            "4/4 - 1s - loss: 0.5469 - mse: 0.5181 - val_loss: 0.4490 - val_mse: 0.4490 - lr: 0.0010 - 702ms/epoch - 176ms/step\n",
            "Epoch 92/1000\n",
            "4/4 - 1s - loss: 0.5447 - mse: 0.5159 - val_loss: 0.4464 - val_mse: 0.4464 - lr: 0.0010 - 696ms/epoch - 174ms/step\n",
            "Epoch 93/1000\n",
            "4/4 - 1s - loss: 0.5425 - mse: 0.5137 - val_loss: 0.4442 - val_mse: 0.4442 - lr: 0.0010 - 678ms/epoch - 170ms/step\n",
            "Epoch 94/1000\n",
            "4/4 - 1s - loss: 0.5409 - mse: 0.5121 - val_loss: 0.4420 - val_mse: 0.4420 - lr: 0.0010 - 698ms/epoch - 174ms/step\n",
            "Epoch 95/1000\n",
            "4/4 - 1s - loss: 0.5392 - mse: 0.5106 - val_loss: 0.4399 - val_mse: 0.4399 - lr: 0.0010 - 687ms/epoch - 172ms/step\n",
            "Epoch 96/1000\n",
            "4/4 - 1s - loss: 0.5369 - mse: 0.5085 - val_loss: 0.4381 - val_mse: 0.4381 - lr: 0.0010 - 733ms/epoch - 183ms/step\n",
            "Epoch 97/1000\n",
            "4/4 - 1s - loss: 0.5343 - mse: 0.5059 - val_loss: 0.4363 - val_mse: 0.4363 - lr: 0.0010 - 696ms/epoch - 174ms/step\n",
            "Epoch 98/1000\n",
            "4/4 - 1s - loss: 0.5332 - mse: 0.5048 - val_loss: 0.4345 - val_mse: 0.4345 - lr: 0.0010 - 715ms/epoch - 179ms/step\n",
            "Epoch 99/1000\n",
            "4/4 - 1s - loss: 0.5317 - mse: 0.5034 - val_loss: 0.4327 - val_mse: 0.4327 - lr: 0.0010 - 690ms/epoch - 173ms/step\n",
            "Epoch 100/1000\n",
            "4/4 - 1s - loss: 0.5292 - mse: 0.5011 - val_loss: 0.4308 - val_mse: 0.4308 - lr: 0.0010 - 707ms/epoch - 177ms/step\n",
            "Epoch 101/1000\n",
            "4/4 - 1s - loss: 0.5281 - mse: 0.5000 - val_loss: 0.4289 - val_mse: 0.4289 - lr: 0.0010 - 713ms/epoch - 178ms/step\n",
            "Epoch 102/1000\n",
            "4/4 - 1s - loss: 0.5285 - mse: 0.5005 - val_loss: 0.4272 - val_mse: 0.4272 - lr: 0.0010 - 696ms/epoch - 174ms/step\n",
            "Epoch 103/1000\n",
            "4/4 - 1s - loss: 0.5259 - mse: 0.4979 - val_loss: 0.4258 - val_mse: 0.4258 - lr: 0.0010 - 716ms/epoch - 179ms/step\n",
            "Epoch 104/1000\n",
            "4/4 - 1s - loss: 0.5224 - mse: 0.4946 - val_loss: 0.4243 - val_mse: 0.4243 - lr: 0.0010 - 684ms/epoch - 171ms/step\n",
            "Epoch 105/1000\n",
            "4/4 - 1s - loss: 0.5227 - mse: 0.4948 - val_loss: 0.4230 - val_mse: 0.4230 - lr: 0.0010 - 702ms/epoch - 176ms/step\n",
            "Epoch 106/1000\n",
            "4/4 - 1s - loss: 0.5213 - mse: 0.4935 - val_loss: 0.4215 - val_mse: 0.4215 - lr: 0.0010 - 701ms/epoch - 175ms/step\n",
            "Epoch 107/1000\n",
            "4/4 - 1s - loss: 0.5205 - mse: 0.4928 - val_loss: 0.4202 - val_mse: 0.4202 - lr: 0.0010 - 690ms/epoch - 172ms/step\n",
            "Epoch 108/1000\n",
            "4/4 - 1s - loss: 0.5190 - mse: 0.4914 - val_loss: 0.4192 - val_mse: 0.4192 - lr: 0.0010 - 716ms/epoch - 179ms/step\n",
            "Epoch 109/1000\n",
            "4/4 - 1s - loss: 0.5163 - mse: 0.4888 - val_loss: 0.4180 - val_mse: 0.4180 - lr: 0.0010 - 695ms/epoch - 174ms/step\n",
            "Epoch 110/1000\n",
            "4/4 - 1s - loss: 0.5146 - mse: 0.4871 - val_loss: 0.4170 - val_mse: 0.4170 - lr: 0.0010 - 714ms/epoch - 178ms/step\n",
            "Epoch 111/1000\n",
            "4/4 - 1s - loss: 0.5137 - mse: 0.4863 - val_loss: 0.4162 - val_mse: 0.4162 - lr: 0.0010 - 717ms/epoch - 179ms/step\n",
            "Epoch 112/1000\n",
            "4/4 - 1s - loss: 0.5132 - mse: 0.4858 - val_loss: 0.4154 - val_mse: 0.4154 - lr: 0.0010 - 684ms/epoch - 171ms/step\n",
            "Epoch 113/1000\n",
            "4/4 - 1s - loss: 0.5115 - mse: 0.4841 - val_loss: 0.4144 - val_mse: 0.4144 - lr: 0.0010 - 699ms/epoch - 175ms/step\n",
            "Epoch 114/1000\n",
            "4/4 - 1s - loss: 0.5086 - mse: 0.4814 - val_loss: 0.4133 - val_mse: 0.4133 - lr: 0.0010 - 708ms/epoch - 177ms/step\n",
            "Epoch 115/1000\n",
            "4/4 - 1s - loss: 0.5092 - mse: 0.4819 - val_loss: 0.4124 - val_mse: 0.4124 - lr: 0.0010 - 704ms/epoch - 176ms/step\n",
            "Epoch 116/1000\n",
            "4/4 - 1s - loss: 0.5082 - mse: 0.4810 - val_loss: 0.4116 - val_mse: 0.4116 - lr: 0.0010 - 711ms/epoch - 178ms/step\n",
            "Epoch 117/1000\n",
            "4/4 - 1s - loss: 0.5066 - mse: 0.4794 - val_loss: 0.4109 - val_mse: 0.4109 - lr: 0.0010 - 719ms/epoch - 180ms/step\n",
            "Epoch 118/1000\n",
            "4/4 - 1s - loss: 0.5061 - mse: 0.4790 - val_loss: 0.4102 - val_mse: 0.4102 - lr: 0.0010 - 704ms/epoch - 176ms/step\n",
            "Epoch 119/1000\n",
            "4/4 - 1s - loss: 0.5050 - mse: 0.4779 - val_loss: 0.4095 - val_mse: 0.4095 - lr: 0.0010 - 695ms/epoch - 174ms/step\n",
            "Epoch 120/1000\n",
            "4/4 - 1s - loss: 0.5025 - mse: 0.4756 - val_loss: 0.4088 - val_mse: 0.4088 - lr: 0.0010 - 700ms/epoch - 175ms/step\n",
            "Epoch 121/1000\n",
            "4/4 - 1s - loss: 0.5028 - mse: 0.4757 - val_loss: 0.4081 - val_mse: 0.4081 - lr: 0.0010 - 720ms/epoch - 180ms/step\n",
            "Epoch 122/1000\n",
            "4/4 - 1s - loss: 0.5014 - mse: 0.4744 - val_loss: 0.4075 - val_mse: 0.4075 - lr: 0.0010 - 738ms/epoch - 184ms/step\n",
            "Epoch 123/1000\n",
            "4/4 - 1s - loss: 0.5001 - mse: 0.4732 - val_loss: 0.4070 - val_mse: 0.4070 - lr: 0.0010 - 734ms/epoch - 183ms/step\n",
            "Epoch 124/1000\n",
            "4/4 - 1s - loss: 0.4979 - mse: 0.4713 - val_loss: 0.4065 - val_mse: 0.4065 - lr: 0.0010 - 719ms/epoch - 180ms/step\n",
            "Epoch 125/1000\n",
            "4/4 - 1s - loss: 0.4982 - mse: 0.4715 - val_loss: 0.4060 - val_mse: 0.4060 - lr: 0.0010 - 764ms/epoch - 191ms/step\n",
            "Epoch 126/1000\n",
            "4/4 - 1s - loss: 0.4965 - mse: 0.4699 - val_loss: 0.4056 - val_mse: 0.4056 - lr: 0.0010 - 694ms/epoch - 174ms/step\n",
            "Epoch 127/1000\n",
            "4/4 - 1s - loss: 0.4956 - mse: 0.4691 - val_loss: 0.4051 - val_mse: 0.4051 - lr: 0.0010 - 703ms/epoch - 176ms/step\n",
            "Epoch 128/1000\n",
            "4/4 - 1s - loss: 0.4944 - mse: 0.4678 - val_loss: 0.4048 - val_mse: 0.4048 - lr: 0.0010 - 705ms/epoch - 176ms/step\n",
            "Epoch 129/1000\n",
            "4/4 - 1s - loss: 0.4943 - mse: 0.4678 - val_loss: 0.4044 - val_mse: 0.4044 - lr: 0.0010 - 707ms/epoch - 177ms/step\n",
            "Epoch 130/1000\n",
            "4/4 - 1s - loss: 0.4941 - mse: 0.4676 - val_loss: 0.4039 - val_mse: 0.4039 - lr: 0.0010 - 711ms/epoch - 178ms/step\n",
            "Epoch 131/1000\n",
            "4/4 - 1s - loss: 0.4917 - mse: 0.4653 - val_loss: 0.4035 - val_mse: 0.4035 - lr: 0.0010 - 702ms/epoch - 176ms/step\n",
            "Epoch 132/1000\n",
            "4/4 - 1s - loss: 0.4918 - mse: 0.4654 - val_loss: 0.4031 - val_mse: 0.4031 - lr: 0.0010 - 724ms/epoch - 181ms/step\n",
            "Epoch 133/1000\n",
            "4/4 - 1s - loss: 0.4919 - mse: 0.4654 - val_loss: 0.4029 - val_mse: 0.4029 - lr: 0.0010 - 692ms/epoch - 173ms/step\n",
            "Epoch 134/1000\n",
            "4/4 - 1s - loss: 0.4902 - mse: 0.4638 - val_loss: 0.4026 - val_mse: 0.4026 - lr: 0.0010 - 686ms/epoch - 172ms/step\n",
            "Epoch 135/1000\n",
            "4/4 - 1s - loss: 0.4888 - mse: 0.4624 - val_loss: 0.4024 - val_mse: 0.4024 - lr: 0.0010 - 704ms/epoch - 176ms/step\n",
            "Epoch 136/1000\n",
            "4/4 - 1s - loss: 0.4894 - mse: 0.4630 - val_loss: 0.4022 - val_mse: 0.4022 - lr: 0.0010 - 704ms/epoch - 176ms/step\n",
            "Epoch 137/1000\n",
            "4/4 - 1s - loss: 0.4888 - mse: 0.4623 - val_loss: 0.4019 - val_mse: 0.4019 - lr: 0.0010 - 683ms/epoch - 171ms/step\n",
            "Epoch 138/1000\n",
            "4/4 - 1s - loss: 0.4864 - mse: 0.4602 - val_loss: 0.4016 - val_mse: 0.4016 - lr: 0.0010 - 710ms/epoch - 178ms/step\n",
            "Epoch 139/1000\n",
            "4/4 - 1s - loss: 0.4864 - mse: 0.4601 - val_loss: 0.4014 - val_mse: 0.4014 - lr: 0.0010 - 772ms/epoch - 193ms/step\n",
            "Epoch 140/1000\n",
            "4/4 - 1s - loss: 0.4854 - mse: 0.4592 - val_loss: 0.4012 - val_mse: 0.4012 - lr: 0.0010 - 709ms/epoch - 177ms/step\n",
            "Epoch 141/1000\n",
            "4/4 - 1s - loss: 0.4842 - mse: 0.4580 - val_loss: 0.4010 - val_mse: 0.4010 - lr: 0.0010 - 685ms/epoch - 171ms/step\n",
            "Epoch 142/1000\n",
            "4/4 - 1s - loss: 0.4843 - mse: 0.4583 - val_loss: 0.4006 - val_mse: 0.4006 - lr: 0.0010 - 713ms/epoch - 178ms/step\n",
            "Epoch 143/1000\n",
            "4/4 - 1s - loss: 0.4828 - mse: 0.4568 - val_loss: 0.4003 - val_mse: 0.4003 - lr: 0.0010 - 711ms/epoch - 178ms/step\n",
            "Epoch 144/1000\n",
            "4/4 - 1s - loss: 0.4816 - mse: 0.4556 - val_loss: 0.4000 - val_mse: 0.4000 - lr: 0.0010 - 728ms/epoch - 182ms/step\n",
            "Epoch 145/1000\n",
            "4/4 - 1s - loss: 0.4816 - mse: 0.4555 - val_loss: 0.3999 - val_mse: 0.3999 - lr: 0.0010 - 734ms/epoch - 184ms/step\n",
            "Epoch 146/1000\n",
            "4/4 - 1s - loss: 0.4817 - mse: 0.4556 - val_loss: 0.3997 - val_mse: 0.3997 - lr: 0.0010 - 724ms/epoch - 181ms/step\n",
            "Epoch 147/1000\n",
            "4/4 - 1s - loss: 0.4809 - mse: 0.4547 - val_loss: 0.3996 - val_mse: 0.3996 - lr: 0.0010 - 721ms/epoch - 180ms/step\n",
            "Epoch 148/1000\n",
            "4/4 - 1s - loss: 0.4804 - mse: 0.4543 - val_loss: 0.3996 - val_mse: 0.3996 - lr: 0.0010 - 708ms/epoch - 177ms/step\n",
            "Epoch 149/1000\n",
            "4/4 - 1s - loss: 0.4785 - mse: 0.4526 - val_loss: 0.3995 - val_mse: 0.3995 - lr: 0.0010 - 714ms/epoch - 178ms/step\n",
            "Epoch 150/1000\n",
            "4/4 - 1s - loss: 0.4786 - mse: 0.4527 - val_loss: 0.3993 - val_mse: 0.3993 - lr: 0.0010 - 733ms/epoch - 183ms/step\n",
            "Epoch 151/1000\n",
            "4/4 - 1s - loss: 0.4774 - mse: 0.4516 - val_loss: 0.3991 - val_mse: 0.3991 - lr: 0.0010 - 722ms/epoch - 180ms/step\n",
            "Epoch 152/1000\n",
            "4/4 - 1s - loss: 0.4777 - mse: 0.4518 - val_loss: 0.3990 - val_mse: 0.3990 - lr: 0.0010 - 750ms/epoch - 187ms/step\n",
            "Epoch 153/1000\n",
            "4/4 - 1s - loss: 0.4775 - mse: 0.4516 - val_loss: 0.3989 - val_mse: 0.3989 - lr: 0.0010 - 739ms/epoch - 185ms/step\n",
            "Epoch 154/1000\n",
            "4/4 - 1s - loss: 0.4758 - mse: 0.4500 - val_loss: 0.3987 - val_mse: 0.3987 - lr: 0.0010 - 738ms/epoch - 185ms/step\n",
            "Epoch 155/1000\n",
            "4/4 - 1s - loss: 0.4754 - mse: 0.4496 - val_loss: 0.3986 - val_mse: 0.3986 - lr: 0.0010 - 693ms/epoch - 173ms/step\n",
            "Epoch 156/1000\n",
            "4/4 - 1s - loss: 0.4740 - mse: 0.4483 - val_loss: 0.3985 - val_mse: 0.3985 - lr: 0.0010 - 723ms/epoch - 181ms/step\n",
            "Epoch 157/1000\n",
            "4/4 - 1s - loss: 0.4748 - mse: 0.4491 - val_loss: 0.3983 - val_mse: 0.3983 - lr: 0.0010 - 712ms/epoch - 178ms/step\n",
            "Epoch 158/1000\n",
            "4/4 - 1s - loss: 0.4737 - mse: 0.4480 - val_loss: 0.3980 - val_mse: 0.3980 - lr: 0.0010 - 729ms/epoch - 182ms/step\n",
            "Epoch 159/1000\n",
            "4/4 - 1s - loss: 0.4743 - mse: 0.4486 - val_loss: 0.3979 - val_mse: 0.3979 - lr: 0.0010 - 736ms/epoch - 184ms/step\n",
            "Epoch 160/1000\n",
            "4/4 - 1s - loss: 0.4739 - mse: 0.4481 - val_loss: 0.3978 - val_mse: 0.3978 - lr: 0.0010 - 715ms/epoch - 179ms/step\n",
            "Epoch 161/1000\n",
            "4/4 - 1s - loss: 0.4716 - mse: 0.4461 - val_loss: 0.3977 - val_mse: 0.3977 - lr: 0.0010 - 691ms/epoch - 173ms/step\n",
            "Epoch 162/1000\n",
            "4/4 - 1s - loss: 0.4726 - mse: 0.4469 - val_loss: 0.3977 - val_mse: 0.3977 - lr: 0.0010 - 698ms/epoch - 175ms/step\n",
            "Epoch 163/1000\n",
            "4/4 - 1s - loss: 0.4707 - mse: 0.4451 - val_loss: 0.3975 - val_mse: 0.3975 - lr: 0.0010 - 700ms/epoch - 175ms/step\n",
            "Epoch 164/1000\n",
            "4/4 - 1s - loss: 0.4703 - mse: 0.4447 - val_loss: 0.3974 - val_mse: 0.3974 - lr: 0.0010 - 716ms/epoch - 179ms/step\n",
            "Epoch 165/1000\n",
            "4/4 - 1s - loss: 0.4713 - mse: 0.4457 - val_loss: 0.3973 - val_mse: 0.3973 - lr: 0.0010 - 719ms/epoch - 180ms/step\n",
            "Epoch 166/1000\n",
            "4/4 - 1s - loss: 0.4708 - mse: 0.4452 - val_loss: 0.3972 - val_mse: 0.3972 - lr: 0.0010 - 728ms/epoch - 182ms/step\n",
            "Epoch 167/1000\n",
            "4/4 - 1s - loss: 0.4698 - mse: 0.4443 - val_loss: 0.3971 - val_mse: 0.3971 - lr: 0.0010 - 748ms/epoch - 187ms/step\n",
            "Epoch 168/1000\n",
            "4/4 - 1s - loss: 0.4700 - mse: 0.4445 - val_loss: 0.3969 - val_mse: 0.3969 - lr: 0.0010 - 722ms/epoch - 180ms/step\n",
            "Epoch 169/1000\n",
            "4/4 - 1s - loss: 0.4705 - mse: 0.4448 - val_loss: 0.3967 - val_mse: 0.3967 - lr: 0.0010 - 745ms/epoch - 186ms/step\n",
            "Epoch 170/1000\n",
            "4/4 - 1s - loss: 0.4688 - mse: 0.4433 - val_loss: 0.3966 - val_mse: 0.3966 - lr: 0.0010 - 718ms/epoch - 180ms/step\n",
            "Epoch 171/1000\n",
            "4/4 - 1s - loss: 0.4685 - mse: 0.4430 - val_loss: 0.3965 - val_mse: 0.3965 - lr: 0.0010 - 720ms/epoch - 180ms/step\n",
            "Epoch 172/1000\n",
            "4/4 - 1s - loss: 0.4675 - mse: 0.4420 - val_loss: 0.3965 - val_mse: 0.3965 - lr: 0.0010 - 714ms/epoch - 179ms/step\n",
            "Epoch 173/1000\n",
            "4/4 - 1s - loss: 0.4675 - mse: 0.4420 - val_loss: 0.3964 - val_mse: 0.3964 - lr: 0.0010 - 709ms/epoch - 177ms/step\n",
            "Epoch 174/1000\n",
            "4/4 - 1s - loss: 0.4681 - mse: 0.4426 - val_loss: 0.3963 - val_mse: 0.3963 - lr: 0.0010 - 731ms/epoch - 183ms/step\n",
            "Epoch 175/1000\n",
            "4/4 - 1s - loss: 0.4666 - mse: 0.4412 - val_loss: 0.3962 - val_mse: 0.3962 - lr: 0.0010 - 734ms/epoch - 183ms/step\n",
            "Epoch 176/1000\n",
            "4/4 - 1s - loss: 0.4667 - mse: 0.4412 - val_loss: 0.3962 - val_mse: 0.3962 - lr: 0.0010 - 719ms/epoch - 180ms/step\n",
            "Epoch 177/1000\n",
            "4/4 - 1s - loss: 0.4654 - mse: 0.4400 - val_loss: 0.3961 - val_mse: 0.3961 - lr: 0.0010 - 724ms/epoch - 181ms/step\n",
            "Epoch 178/1000\n",
            "4/4 - 1s - loss: 0.4663 - mse: 0.4408 - val_loss: 0.3960 - val_mse: 0.3960 - lr: 0.0010 - 726ms/epoch - 182ms/step\n",
            "Epoch 179/1000\n",
            "4/4 - 1s - loss: 0.4654 - mse: 0.4400 - val_loss: 0.3960 - val_mse: 0.3960 - lr: 0.0010 - 730ms/epoch - 183ms/step\n",
            "Epoch 180/1000\n",
            "4/4 - 1s - loss: 0.4661 - mse: 0.4407 - val_loss: 0.3959 - val_mse: 0.3959 - lr: 0.0010 - 718ms/epoch - 180ms/step\n",
            "Epoch 181/1000\n",
            "4/4 - 1s - loss: 0.4649 - mse: 0.4395 - val_loss: 0.3958 - val_mse: 0.3958 - lr: 0.0010 - 746ms/epoch - 187ms/step\n",
            "Epoch 182/1000\n",
            "4/4 - 1s - loss: 0.4638 - mse: 0.4384 - val_loss: 0.3958 - val_mse: 0.3958 - lr: 0.0010 - 710ms/epoch - 177ms/step\n",
            "Epoch 183/1000\n",
            "4/4 - 1s - loss: 0.4639 - mse: 0.4386 - val_loss: 0.3957 - val_mse: 0.3957 - lr: 0.0010 - 707ms/epoch - 177ms/step\n",
            "Epoch 184/1000\n",
            "4/4 - 1s - loss: 0.4638 - mse: 0.4385 - val_loss: 0.3956 - val_mse: 0.3956 - lr: 0.0010 - 725ms/epoch - 181ms/step\n",
            "Epoch 185/1000\n",
            "4/4 - 1s - loss: 0.4648 - mse: 0.4394 - val_loss: 0.3955 - val_mse: 0.3955 - lr: 0.0010 - 719ms/epoch - 180ms/step\n",
            "Epoch 186/1000\n",
            "4/4 - 1s - loss: 0.4632 - mse: 0.4380 - val_loss: 0.3955 - val_mse: 0.3955 - lr: 0.0010 - 694ms/epoch - 173ms/step\n",
            "Epoch 187/1000\n",
            "4/4 - 1s - loss: 0.4622 - mse: 0.4370 - val_loss: 0.3955 - val_mse: 0.3955 - lr: 0.0010 - 718ms/epoch - 179ms/step\n",
            "Epoch 188/1000\n",
            "4/4 - 1s - loss: 0.4623 - mse: 0.4372 - val_loss: 0.3955 - val_mse: 0.3955 - lr: 0.0010 - 700ms/epoch - 175ms/step\n",
            "Epoch 189/1000\n",
            "4/4 - 1s - loss: 0.4620 - mse: 0.4369 - val_loss: 0.3954 - val_mse: 0.3954 - lr: 0.0010 - 689ms/epoch - 172ms/step\n",
            "Epoch 190/1000\n",
            "4/4 - 1s - loss: 0.4623 - mse: 0.4370 - val_loss: 0.3953 - val_mse: 0.3953 - lr: 0.0010 - 712ms/epoch - 178ms/step\n",
            "Epoch 191/1000\n",
            "4/4 - 1s - loss: 0.4619 - mse: 0.4366 - val_loss: 0.3953 - val_mse: 0.3953 - lr: 0.0010 - 697ms/epoch - 174ms/step\n",
            "Epoch 192/1000\n",
            "4/4 - 1s - loss: 0.4613 - mse: 0.4360 - val_loss: 0.3954 - val_mse: 0.3954 - lr: 0.0010 - 719ms/epoch - 180ms/step\n",
            "Epoch 193/1000\n",
            "4/4 - 1s - loss: 0.4608 - mse: 0.4356 - val_loss: 0.3953 - val_mse: 0.3953 - lr: 0.0010 - 704ms/epoch - 176ms/step\n",
            "Epoch 194/1000\n",
            "4/4 - 1s - loss: 0.4609 - mse: 0.4358 - val_loss: 0.3952 - val_mse: 0.3952 - lr: 0.0010 - 728ms/epoch - 182ms/step\n",
            "Epoch 195/1000\n",
            "4/4 - 1s - loss: 0.4603 - mse: 0.4351 - val_loss: 0.3951 - val_mse: 0.3951 - lr: 0.0010 - 692ms/epoch - 173ms/step\n",
            "Epoch 196/1000\n",
            "4/4 - 1s - loss: 0.4609 - mse: 0.4358 - val_loss: 0.3951 - val_mse: 0.3951 - lr: 0.0010 - 708ms/epoch - 177ms/step\n",
            "Epoch 197/1000\n",
            "4/4 - 1s - loss: 0.4596 - mse: 0.4345 - val_loss: 0.3951 - val_mse: 0.3951 - lr: 0.0010 - 702ms/epoch - 176ms/step\n",
            "Epoch 198/1000\n",
            "4/4 - 1s - loss: 0.4607 - mse: 0.4355 - val_loss: 0.3950 - val_mse: 0.3950 - lr: 0.0010 - 705ms/epoch - 176ms/step\n",
            "Epoch 199/1000\n",
            "4/4 - 1s - loss: 0.4602 - mse: 0.4351 - val_loss: 0.3950 - val_mse: 0.3950 - lr: 0.0010 - 700ms/epoch - 175ms/step\n",
            "Epoch 200/1000\n",
            "4/4 - 1s - loss: 0.4590 - mse: 0.4340 - val_loss: 0.3951 - val_mse: 0.3951 - lr: 0.0010 - 687ms/epoch - 172ms/step\n",
            "Epoch 201/1000\n",
            "4/4 - 1s - loss: 0.4598 - mse: 0.4348 - val_loss: 0.3951 - val_mse: 0.3951 - lr: 0.0010 - 696ms/epoch - 174ms/step\n",
            "Epoch 202/1000\n",
            "4/4 - 1s - loss: 0.4590 - mse: 0.4339 - val_loss: 0.3950 - val_mse: 0.3950 - lr: 0.0010 - 706ms/epoch - 177ms/step\n",
            "Epoch 203/1000\n",
            "4/4 - 1s - loss: 0.4591 - mse: 0.4340 - val_loss: 0.3948 - val_mse: 0.3948 - lr: 0.0010 - 692ms/epoch - 173ms/step\n",
            "Epoch 204/1000\n",
            "4/4 - 1s - loss: 0.4583 - mse: 0.4332 - val_loss: 0.3948 - val_mse: 0.3948 - lr: 0.0010 - 696ms/epoch - 174ms/step\n",
            "Epoch 205/1000\n",
            "4/4 - 1s - loss: 0.4576 - mse: 0.4326 - val_loss: 0.3948 - val_mse: 0.3948 - lr: 0.0010 - 700ms/epoch - 175ms/step\n",
            "Epoch 206/1000\n",
            "4/4 - 1s - loss: 0.4585 - mse: 0.4335 - val_loss: 0.3948 - val_mse: 0.3948 - lr: 0.0010 - 700ms/epoch - 175ms/step\n",
            "Epoch 207/1000\n",
            "4/4 - 1s - loss: 0.4595 - mse: 0.4344 - val_loss: 0.3950 - val_mse: 0.3950 - lr: 0.0010 - 716ms/epoch - 179ms/step\n",
            "Epoch 208/1000\n",
            "4/4 - 1s - loss: 0.4580 - mse: 0.4329 - val_loss: 0.3950 - val_mse: 0.3950 - lr: 0.0010 - 686ms/epoch - 171ms/step\n",
            "Epoch 209/1000\n",
            "4/4 - 1s - loss: 0.4584 - mse: 0.4334 - val_loss: 0.3949 - val_mse: 0.3949 - lr: 0.0010 - 703ms/epoch - 176ms/step\n",
            "Epoch 210/1000\n",
            "\n",
            "Epoch 210: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "4/4 - 1s - loss: 0.4576 - mse: 0.4326 - val_loss: 0.3948 - val_mse: 0.3948 - lr: 0.0010 - 707ms/epoch - 177ms/step\n",
            "Epoch 211/1000\n",
            "4/4 - 1s - loss: 0.4574 - mse: 0.4325 - val_loss: 0.3949 - val_mse: 0.3949 - lr: 1.0000e-04 - 707ms/epoch - 177ms/step\n",
            "Epoch 212/1000\n",
            "4/4 - 1s - loss: 0.4576 - mse: 0.4325 - val_loss: 0.3950 - val_mse: 0.3950 - lr: 1.0000e-04 - 694ms/epoch - 173ms/step\n",
            "Epoch 213/1000\n",
            "4/4 - 1s - loss: 0.4567 - mse: 0.4318 - val_loss: 0.3950 - val_mse: 0.3950 - lr: 1.0000e-04 - 704ms/epoch - 176ms/step\n",
            "Epoch 214/1000\n",
            "4/4 - 1s - loss: 0.4576 - mse: 0.4326 - val_loss: 0.3951 - val_mse: 0.3951 - lr: 1.0000e-04 - 709ms/epoch - 177ms/step\n",
            "Epoch 214: early stopping\n",
            "==================================================\n",
            "Step 16\n",
            "==================================================\n",
            "Epoch 1/1000\n",
            "4/4 - 4s - loss: 6.5563 - mse: 6.1439 - val_loss: 0.9118 - val_mse: 0.9118 - lr: 0.0010 - 4s/epoch - 980ms/step\n",
            "Epoch 2/1000\n",
            "4/4 - 1s - loss: 3.5204 - mse: 3.3008 - val_loss: 0.8157 - val_mse: 0.8157 - lr: 0.0010 - 711ms/epoch - 178ms/step\n",
            "Epoch 3/1000\n",
            "4/4 - 1s - loss: 2.5080 - mse: 2.3670 - val_loss: 0.7777 - val_mse: 0.7777 - lr: 0.0010 - 693ms/epoch - 173ms/step\n",
            "Epoch 4/1000\n",
            "4/4 - 1s - loss: 2.0640 - mse: 1.9523 - val_loss: 0.7756 - val_mse: 0.7756 - lr: 0.0010 - 700ms/epoch - 175ms/step\n",
            "Epoch 5/1000\n",
            "4/4 - 1s - loss: 1.7772 - mse: 1.6768 - val_loss: 0.7913 - val_mse: 0.7913 - lr: 0.0010 - 678ms/epoch - 169ms/step\n",
            "Epoch 6/1000\n",
            "4/4 - 1s - loss: 1.6061 - mse: 1.5122 - val_loss: 0.8092 - val_mse: 0.8092 - lr: 0.0010 - 706ms/epoch - 176ms/step\n",
            "Epoch 7/1000\n",
            "4/4 - 1s - loss: 1.4999 - mse: 1.4127 - val_loss: 0.8196 - val_mse: 0.8196 - lr: 0.0010 - 691ms/epoch - 173ms/step\n",
            "Epoch 8/1000\n",
            "4/4 - 1s - loss: 1.4284 - mse: 1.3464 - val_loss: 0.8196 - val_mse: 0.8196 - lr: 0.0010 - 679ms/epoch - 170ms/step\n",
            "Epoch 9/1000\n",
            "4/4 - 1s - loss: 1.3615 - mse: 1.2847 - val_loss: 0.8120 - val_mse: 0.8120 - lr: 0.0010 - 670ms/epoch - 168ms/step\n",
            "Epoch 10/1000\n",
            "4/4 - 1s - loss: 1.3034 - mse: 1.2303 - val_loss: 0.8029 - val_mse: 0.8029 - lr: 0.0010 - 676ms/epoch - 169ms/step\n",
            "Epoch 11/1000\n",
            "\n",
            "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "4/4 - 1s - loss: 1.2604 - mse: 1.1907 - val_loss: 0.7968 - val_mse: 0.7968 - lr: 0.0010 - 666ms/epoch - 167ms/step\n",
            "Epoch 12/1000\n",
            "4/4 - 1s - loss: 1.2320 - mse: 1.1634 - val_loss: 0.8024 - val_mse: 0.8024 - lr: 1.0000e-04 - 689ms/epoch - 172ms/step\n",
            "Epoch 13/1000\n",
            "4/4 - 1s - loss: 1.2275 - mse: 1.1596 - val_loss: 0.8091 - val_mse: 0.8091 - lr: 1.0000e-04 - 686ms/epoch - 172ms/step\n",
            "Epoch 14/1000\n",
            "4/4 - 1s - loss: 1.2236 - mse: 1.1567 - val_loss: 0.8165 - val_mse: 0.8165 - lr: 1.0000e-04 - 684ms/epoch - 171ms/step\n",
            "Epoch 14: early stopping\n"
          ]
        }
      ],
      "source": [
        "N_EPOCHS = 1000\n",
        "\n",
        "val_pred = []\n",
        "test_pred = []\n",
        "\n",
        "sample_weights = np.array(pd.concat([items_reindexed[\"perishable\"]] * 4) * 0.25 + 1)\n",
        "for i in range(16):\n",
        "    print(\"=\" * 50)\n",
        "    print(\"Step %d\" % (i+1))\n",
        "    print(\"=\" * 50)\n",
        "\n",
        "    y = y_train[:, i]\n",
        "    y_mean = y.mean()\n",
        "    xv = X_val\n",
        "    yv = y_val[:, i]\n",
        "\n",
        "    model = build_model()\n",
        "    opt = optimizers.Adam(lr=0.001)\n",
        "    model.compile(loss='mse', optimizer=opt, metrics=['mse'])\n",
        "\n",
        "    callbacks = [\n",
        "        EarlyStopping(monitor='val_loss', patience=10, verbose=1),\n",
        "        ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=7, verbose=1, min_delta=1e-4, mode='min')\n",
        "        ]\n",
        "\n",
        "    model.fit(X_train, y - y_mean, batch_size = 65536, epochs = N_EPOCHS, verbose=2,\n",
        "               sample_weight=sample_weights, validation_data=(xv,yv-y_mean), callbacks=callbacks )\n",
        "    \n",
        "    val_pred.append(model.predict(X_val)+y_mean)\n",
        "    test_pred.append(model.predict(X_test)+y_mean)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TSoFp2WYvwGa",
        "outputId": "51628411-e3a1-4016-aba5-1995a4486ac6"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_15\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_15 (LSTM)              (None, 32)                8448      \n",
            "                                                                 \n",
            " batch_normalization_30 (Bat  (None, 32)               128       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dropout_30 (Dropout)        (None, 32)                0         \n",
            "                                                                 \n",
            " dense_30 (Dense)            (None, 32)                1056      \n",
            "                                                                 \n",
            " batch_normalization_31 (Bat  (None, 32)               128       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dropout_31 (Dropout)        (None, 32)                0         \n",
            "                                                                 \n",
            " dense_31 (Dense)            (None, 1)                 33        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 9,793\n",
            "Trainable params: 9,665\n",
            "Non-trainable params: 128\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qngdHFL0vCb8",
        "outputId": "60ceedc4-95c3-4f84-dcaf-457118020f22"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nwrmsle = 0.7050890938252905\n"
          ]
        }
      ],
      "source": [
        "weight = items_reindexed[\"perishable\"] * 0.25 + 1\n",
        "err = (y_val - np.array(val_pred).transpose()[0])**2\n",
        "err = err.sum(axis=1) * weight\n",
        "err = np.sqrt(err.sum() / weight.sum() / 16)\n",
        "print('nwrmsle = {}'.format(err))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RahjyQtivCfJ",
        "outputId": "8de08963-8d7c-4e5e-8736-34ed4d231994"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation mse: 90.84143182378779\n",
            "Test mse: 97.6309833629742\n"
          ]
        }
      ],
      "source": [
        "print(\"Validation mse:\", mean_squared_error(np.clip(np.expm1(y_val), 0, 1000), np.clip(np.expm1(np.array(val_pred).transpose()[0]), 0, 1000), sample_weight=(items_reindexed[\"perishable\"].values * 0.25 + 1)))\n",
        "print(\"Test mse:\", mean_squared_error(np.clip(np.expm1(y_test), 0, 1000), np.clip(np.expm1(np.array(test_pred).transpose()[0]), 0, 1000), sample_weight=(items_reindexed[\"perishable\"].values * 0.25 + 1)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f0294a5d-49f8-4105-e264-d64261f22839",
        "id": "LHPursBivj8j"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Combine with the test data split...\n"
          ]
        }
      ],
      "source": [
        "print(\"Combine with the test data split...\")\n",
        "\n",
        "df_preds_lg = pd.DataFrame(\n",
        "    np.array(test_pred).transpose()[0], index=train_selected_sales.index,\n",
        "    columns=pd.date_range(\"2017-07-31\", periods=16)\n",
        ").stack().to_frame(\"log_predicted_unit_sales\")\n",
        "df_preds_lg.index.set_names([\"store_nbr\", \"item_nbr\", \"date\"], inplace=True)\n",
        "\n",
        "df_test_lg = pd.DataFrame(\n",
        "    y_test, index=train_selected_sales.index,\n",
        "    columns=pd.date_range(\"2017-07-31\", periods=16)\n",
        ").stack().to_frame(\"log_actual_unit_sales\")\n",
        "df_test_lg.index.set_names([\"store_nbr\", \"item_nbr\", \"date\"], inplace=True)\n",
        "\n",
        "\n",
        "comb_df = pd.concat([df_preds_lg, df_test_lg], axis=1)\n",
        "comb_df['predicted_unit_sales'] = np.clip(np.expm1(comb_df[\"log_predicted_unit_sales\"]), 0, 1000)\n",
        "comb_df['actual_unit_sales'] = np.clip(np.expm1(comb_df[\"log_actual_unit_sales\"]), 0, 1000)\n",
        "# comb_df['perishable'] = df_items_2017[\"perishable\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "dvvltP6evj8j"
      },
      "outputs": [],
      "source": [
        "# save data to file\n",
        "out_filename = 'drive/My Drive/favorita/model_outputs/' + 'nn_log_scaled_out_fe_model.pkl'\n",
        "merge_df = pd.merge(comb_df.reset_index(), items.reset_index(), on='item_nbr',how=\"left\")\n",
        "merge_df.to_pickle(out_filename)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "weights = merge_df[\"perishable\"].values * 0.25 + 1\n",
        "print('Unit', get_error(weights, merge_df['actual_unit_sales'].values, merge_df[\"predicted_unit_sales\"].values))\n",
        "print('Log', get_error(weights, merge_df['log_actual_unit_sales'].values, merge_df[\"log_predicted_unit_sales\"].values))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb57c77c-530c-430a-8e19-67e7ef0292df",
        "id": "d8gi6l3uvj8k"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unit (97.63098336297423, 9.88083920337611, 9.88083920337611, 2.844475173770585, nan)\n",
            "Log (0.48935365637718176, 0.699538173638281, 0.699538173638281, 0.5359076404017681, inf)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:10: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  # Remove the CWD from sys.path while we load stuff.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:10: RuntimeWarning: invalid value encountered in true_divide\n",
            "  # Remove the CWD from sys.path while we load stuff.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:10: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  # Remove the CWD from sys.path while we load stuff.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Ensemble"
      ],
      "metadata": {
        "id": "z3-_tIXWzkqJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_outcome_folder = 'drive/MyDrive/favorita/model_outputs'\n",
        "models_files = [join(model_outcome_folder, f) for f in listdir(model_outcome_folder) ]"
      ],
      "metadata": {
        "id": "oWLxd2kxzjxp"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "models_files = [ file for file in models_files if  file.endswith( ('.pkl') ) ]"
      ],
      "metadata": {
        "id": "CDqXuIxnDdJL"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "models_files"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dco242w0ClaT",
        "outputId": "c70eb6ac-9950-42b2-b015-e997460f1b2f"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['drive/MyDrive/favorita/model_outputs/MA_log_scaled_out_base.pkl',\n",
              " 'drive/MyDrive/favorita/model_outputs/lgbm_log_scaled_out_base.pkl',\n",
              " 'drive/MyDrive/favorita/model_outputs/lgbm_log_scaled_out_fe_model.pkl',\n",
              " 'drive/MyDrive/favorita/model_outputs/nn_log_scaled_out_fe_model.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_df = pd.read_pickle(models_files[1])"
      ],
      "metadata": {
        "id": "y4se6AxNEyGI"
      },
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_df.rename(columns={'actual_unit_sales': 'actual', 'predicted_unit_sales': 'pred_m1'}, inplace=True)"
      ],
      "metadata": {
        "id": "f2RFioSCE4g3"
      },
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(2,len(models_files)):\n",
        "  print(models_files[i])\n",
        "  model_secondary = pd.read_pickle(models_files[i])\n",
        "  col_name = f\"pred_m{i}\"\n",
        "  print(col_name)\n",
        "  model_secondary.rename(columns={'predicted_unit_sales': col_name}, inplace=True)\n",
        "  model_df[col_name] = model_secondary[col_name]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s3Pvu4XMFE_w",
        "outputId": "0b902204-b1e0-4927-a8ca-426ed8f13761"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "drive/MyDrive/favorita/model_outputs/lgbm_log_scaled_out_fe_model.pkl\n",
            "pred_m2\n",
            "drive/MyDrive/favorita/model_outputs/nn_log_scaled_out_fe_model.pkl\n",
            "pred_m3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MA_test_set = pd.read_pickle(models_files[0])\n",
        "model_df_base = pd.merge(model_df,MA_test_set[[\"date\",\"unit_sales_pred_actual\"]],on=[\"store_nbr\",\"item_nbr\",\"date\"],how=\"left\")\n",
        "model_df_base[\"unit_sales_pred_actual\"].fillna(0,inplace=True)\n",
        "model_df_base.rename(columns={'unit_sales_pred_actual': 'pred_m0'}, inplace=True)"
      ],
      "metadata": {
        "id": "UB7SeyHpFxpk"
      },
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "types = {'store_nbr': 'int8',\n",
        "                'item_nbr': 'int32',\n",
        "                'class': 'int8',\n",
        "                'unit_sales': 'float32',\n",
        "         'perishable': 'int8'\n",
        "            }\n",
        "\n",
        "model_df = pd.read_csv(models_files[2], parse_dates = ['date'], dtype = types, low_memory = True)\n",
        "model_df.rename(columns={'actual_unit_sales': 'actual', 'predicted_unit_sales': 'pred_m1'}, inplace=True)\n",
        "\n",
        "model_secondary = pd.read_csv(models_files[3], parse_dates = ['date'], dtype = types, low_memory = True)\n",
        "model_secondary.rename(columns={'actual_unit_sales': 'actual', 'predicted_unit_sales': 'pred_m2'}, inplace=True)\n",
        "\n",
        "model_df['pred_m2'] = model_secondary['pred_m2']\n"
      ],
      "metadata": {
        "id": "Y9xAfdA7zuy2"
      },
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_df_base = pd.merge(model_df,MA_test_set[[\"date\",\"unit_sales_pred_actual\"]],on=[\"store_nbr\",\"item_nbr\",\"date\"],how=\"left\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "yo_QansfgFal"
      },
      "execution_count": 153,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# three models MSE values\n",
        "for i in range(1,len(models_files)):\n",
        "  col_name = f\"pred_m{i}\"\n",
        "  print(col_name)\n",
        "  print('normal',get_error(model_df_base[\"perishable\"].values * 0.25 + 1, model_df_base['actual'].values, model_df_base[col_name].values))\n",
        "  print('Log', get_error(model_df_base[\"perishable\"].values * 0.25 + 1, np.log1p(model_df_base['actual'].values), np.log1p(model_df_base[col_name].values)))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VjKw-gRkk5wF",
        "outputId": "a8c13262-5090-4296-ce52-7baccb1bd29d"
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pred_m1\n",
            "normal (147.6646126170308, 12.151732905928718, 12.151732905928718, 3.59257736530841, nan)\n",
            "Log (0.641971898967885, 0.8012314890017023, 0.8012314890017023, 0.6208258709452846, nan)\n",
            "pred_m2\n",
            "normal (76.3608225257157, 8.738467973604738, 8.738467973604738, 2.4528014516036087, nan)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:10: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  # Remove the CWD from sys.path while we load stuff.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:10: RuntimeWarning: invalid value encountered in true_divide\n",
            "  # Remove the CWD from sys.path while we load stuff.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:10: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  # Remove the CWD from sys.path while we load stuff.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:10: RuntimeWarning: invalid value encountered in true_divide\n",
            "  # Remove the CWD from sys.path while we load stuff.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:10: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  # Remove the CWD from sys.path while we load stuff.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:10: RuntimeWarning: invalid value encountered in true_divide\n",
            "  # Remove the CWD from sys.path while we load stuff.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:10: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  # Remove the CWD from sys.path while we load stuff.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:10: RuntimeWarning: invalid value encountered in true_divide\n",
            "  # Remove the CWD from sys.path while we load stuff.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Log (0.37768822273665525, 0.6145634407745512, 0.6145634407745512, 0.4610393459011156, nan)\n",
            "pred_m3\n",
            "normal (97.63098336297423, 9.88083920337611, 9.88083920337611, 2.844475173770585, nan)\n",
            "Log (0.48931800723514135, 0.6995126926905196, 0.6995126926905196, 0.5358638775503591, nan)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:10: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  # Remove the CWD from sys.path while we load stuff.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:10: RuntimeWarning: invalid value encountered in true_divide\n",
            "  # Remove the CWD from sys.path while we load stuff.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:10: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  # Remove the CWD from sys.path while we load stuff.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:10: RuntimeWarning: invalid value encountered in true_divide\n",
            "  # Remove the CWD from sys.path while we load stuff.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "weights = model_df[\"perishable\"].values * 0.25 + 1"
      ],
      "metadata": {
        "id": "nRyFRCiBDrUD"
      },
      "execution_count": 128,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ensemble"
      ],
      "metadata": {
        "id": "TAdWk0L3mlYA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# model_df[\"pred_final\"] = model_df[[\"pred_m1\", \"pred_m2\"]].max(axis=1)\n",
        "model_df_base[\"pred_final\"] = 0.0*model_df_base[\"pred_m1\"] + 0.8*model_df_base[\"pred_m2\"] + + 0.2*model_df_base[\"pred_m3\"]"
      ],
      "metadata": {
        "id": "nEiwjslaWMG9"
      },
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('normal',get_error(model_df_base[\"perishable\"].values * 0.25 + 1, model_df_base['actual'].values, model_df_base[\"pred_final\"].values))\n",
        "print('Log', get_error(model_df_base[\"perishable\"].values * 0.25 + 1, np.log1p(model_df_base['actual'].values), np.log1p(model_df_base[\"pred_final\"].values)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gsAQ2_5p0QYz",
        "outputId": "9a1baeba-e9fd-4b25-ef9c-4611482e9670"
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "normal (77.85133794288427, 8.823340520623937, 8.823340520623937, 2.4827067696568483, nan)\n",
            "Log (0.38243477316035657, 0.618413108819951, 0.618413108819951, 0.4714159256935679, nan)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:10: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  # Remove the CWD from sys.path while we load stuff.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:10: RuntimeWarning: invalid value encountered in true_divide\n",
            "  # Remove the CWD from sys.path while we load stuff.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:10: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  # Remove the CWD from sys.path while we load stuff.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:10: RuntimeWarning: invalid value encountered in true_divide\n",
            "  # Remove the CWD from sys.path while we load stuff.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Result Analysis"
      ],
      "metadata": {
        "id": "Dob5L01NAm-6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "store_mse = {}\n",
        "for i in model_df_base.store_nbr.unique():\n",
        "  store_mse[i] = get_error(model_df_base[model_df_base[\"store_nbr\"]==i][\"perishable\"].values * 0.25 + 1, model_df_base[model_df_base[\"store_nbr\"]==i]['actual'].values, model_df_base[model_df_base[\"store_nbr\"]==i][\"pred_final\"].values)\n",
        "df_store_mse =pd.DataFrame(store_mse)\n",
        "plt.figure(figsize=(20, 5))\n",
        "df_store_mse.iloc[0,:].plot.bar()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        },
        "id": "JIKxuHAfRaFz",
        "outputId": "5b961127-485f-476e-ced4-59da43d3ef00"
      },
      "execution_count": 175,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f977a8fc350>"
            ]
          },
          "metadata": {},
          "execution_count": 175
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1440x360 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABH8AAAE5CAYAAAAJEoxUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3dfYxV9Z0G8GfkxSl2lIIMFFehaVWM8lrRUgstoDKYteIrSoWYZXcxC/W1IhKrtFhr0W3XF1oE6xtuU9bJatmuBlZbraaKBlaLJlVbkbgC46AoKNiKzv7BOimLFhjuzGXO/XwSEzn3zvy+zznDcOeZc86tampqagoAAAAAhbRPuQcAAAAAoPUofwAAAAAKTPkDAAAAUGDKHwAAAIACU/4AAAAAFJjyBwAAAKDAOu7Kk+bMmZPly5dn69atmTJlSn71q1/l+eefT9euXZMkkydPzte+9rUsXrw4d911V/bZZ5+cddZZOfPMM1t1eAAAAAD+up2WP08++WReeumlLFq0KBs2bMipp56aL33pS7nkkksycuTI5udt3rw5c+fOTX19fTp16pQzzjgjJ5xwQnNBBAAAAEDb22n5M3To0AwYMCBJsv/++2fLli354IMPdnjes88+m/79+6empiZJMmTIkKxYsSKjRo0q8cgAAAAA7Kqd3vOnQ4cO6dKlS5Kkvr4+I0aMSIcOHXLPPfdk0qRJufjii/Pmm29m/fr16datW/PHdevWLY2Nja03OQAAAAA7tUv3/EmShx56KPX19bn99tvz3HPPpWvXrjniiCMyf/783HLLLRk8ePB2z29qair5sAAAAADsnl0qfx577LHMmzcvt912W2pqajJs2LDmx0aNGpVZs2ZlzJgxWb9+ffP2119/PYMGDdrhcy1fvrwEYwMAAADwl774xS9+7Padlj+bNm3KnDlzcueddzbfvPmb3/xmpk+fnoMPPjjLli3LoYcemoEDB+bKK6/Mxo0b06FDh6xYsSIzZ87crWFay5o1a9K7d+82XbNcZC2mSslaKTkTWYuqUrJWSs5E1qKqlKyVkjORtYgqJWcia1GVI+tfO9lmp+XPAw88kA0bNuSiiy5q3nbaaafloosuyqc+9al06dIl3//+91NdXZ1LL700kydPTlVVVaZOndp882cAAAAAymOn5c/48eMzfvz4HbafeuqpO2yrq6tLXV1daSYDAAAAYI/t9N2+AAAAAGi/lD8AAAAABab8AQAAACgw5Q8AAABAgSl/AAAAAApM+QMAAABQYMofAAAAgAJT/gAAAAAUmPIHAAAAoMCUPwAAAAAFpvwBAAAAKDDlDwAAAECBKX8AAAAACkz5AwAAAFBgyh8AAACAAlP+AAAAABSY8gcAAACgwJQ/AAAAAAWm/AEAAAAoMOUPAAAAQIEpfwAAAAAKTPkDAAAAUGDKHwAAAIACU/4AAAAAFJjyBwAAAKDAlD8AAAAABab8AQAAACgw5Q8AAABAgSl/AAAAAApM+QMAAABQYMofAAAAgAJT/gAAAAAUmPIHAAAAoMCUPwAAAAAF1rHcA1DZevXqm4aG1W2+bs+efbJu3Sttvi4AAAC0NeUPZbWt+Gkqw7pVbb4mAAAAlIPLvgAAAAAKTPkDAAAAUGDKHwAAAIACU/4AAAAAFJjyBwAAAKDAlD8AAAAABab8AQAAACgw5Q8AAABAgSl/AAAAAApM+QMAAABQYB3LPQAAAECvXn3T0LC6zdft2bNP1q17pc3XBWhLu1T+zJkzJ8uXL8/WrVszZcqU9O/fP9OnT88HH3yQHj165Prrr0/nzp2zePHi3HXXXdlnn31y1lln5cwzz2zt+QEAgALYVvw0lWHdqjZfE6Ct7bT8efLJJ/PSSy9l0aJF2bBhQ0499dQMGzYsEyZMyNixY/PDH/4w9fX1GTduXObOnZv6+vp06tQpZ5xxRk444YR07dq1LXIAAAAA8DF2es+foUOH5sYbb0yS7L///tmyZUuWLVuW0aNHJ0lGjhyZJ554Is8++2z69++fmpqaVFdXZ8iQIVmxYkXrTg8AAADAX7XT8qdDhw7p0qVLkqS+vj4jRozIli1b0rlz5yRJ9+7d09jYmPXr16dbt27NH9etW7c0Nja20tgAAAAA7IpdvuHzQw89lPr6+tx+++058cQTm7c3NX38dbmftD1J1qxZsxsj7rlNmza1+ZrlUklZ91R72k+VclwrJWcia1FVStZKyZnIWlSVkrVScpZCe9pPlXJcKyVnImtR7W1Zd6n8eeyxxzJv3rzcdtttqampSZcuXfLee++luro6DQ0Nqa2tTW1tbdavX9/8Ma+//noGDRr0sZ+vd+/epZl+F61Zs6bN1yyXSsq6p9rTfqqU41opORNZi6pSslZKzkTWoqqUrJWSsxTa036qlONaKTkTWYuqHFnXrl37iY/t9LKvTZs2Zc6cObn11lubb9785S9/OUuWLEmSLF26NMOHD8/AgQOzcuXKbNy4Me+++25WrFiRo48+ukQRAAAAAGiJnZ7588ADD2TDhg256KKLmrddd911ufLKK7No0aL07t0748aNS6dOnXLppZdm8uTJqaqqytSpU1NTU9OqwwMAAADw1+20/Bk/fnzGjx+/w/Y77rhjh211dXWpq6srzWQAAAAA7LGdXvYFAAAAQPul/AEAAAAoMOUPAAAAQIEpfwAAAAAKTPkDAAAAUGDKHwAAAIACU/4AAAAAFJjyBwAAAKDAlD8AAAAABab8AQAAACgw5Q8AAABAgXUs9wAAAJRGr15909Cwuk3X7NmzT9ate6VN1wQAdo/yBwCgILYVP01tvGZVm64HAOw+l30BAAAAFJjyBwAAAKDAlD8AAAAABab8AQAAACgw5Q8AAABAgSl/AAAAAApM+QMAAABQYMofAAAAgAJT/gAAAAAUmPIHAAAAoMCUPwAAAAAFpvwBAAAAKDDlDwAAAECBKX8AAAAACkz5AwAAAFBgyh8AAACAAlP+AAAAABSY8gcAAACgwJQ/AAAAAAWm/AEAAAAoMOUPAAAAQIEpfwAAAAAKTPkDAAAAUGDKHwAAAIACU/4AAAAAFJjyBwAAAKDAlD8AAAAABab8AQAAACgw5Q8AAABAgSl/AAAAAApM+QMAAABQYMofAAAAgAJT/gAAAAAUmPIHAAAAoMB2qfx58cUXc/zxx+eee+5JksyYMSMnn3xyJk6cmIkTJ+aRRx5JkixevDinn356zjzzzNx7772tNjQAAAAAu6bjzp6wefPmzJ49O8OGDdtu+yWXXJKRI0du97y5c+emvr4+nTp1yhlnnJETTjghXbt2Lf3UAAAAAOySnZ7507lz5yxYsCC1tbV/9XnPPvts+vfvn5qamlRXV2fIkCFZsWJFyQYFAAAAYPfttPzp2LFjqqurd9h+zz33ZNKkSbn44ovz5ptvZv369enWrVvz4926dUtjY2NppwUAAABgt+z0sq+Pc8opp6Rr16454ogjMn/+/Nxyyy0ZPHjwds9pamr6xI9fs2ZNS5ZtsU2bNrX5muVSSVn3VHvaT5VyXCslZyJrUVVK1krJmVRW1j3R3vZRpRzXSslZCu1pP1XKca2UnImsRbW3ZW1R+fOX9/8ZNWpUZs2alTFjxmT9+vXN219//fUMGjToYz++d+/eLVm2xdasWdPma5ZLJWXdU+1pP1XKca2UnImsRVUpWSslZ1JZWfdEe9tHlXJcKyVnKbSn/VQpx7VSciayFlU5sq5du/YTH2vRW71/85vfzKuvvpokWbZsWQ499NAMHDgwK1euzMaNG/Puu+9mxYoVOfroo1s2MQAAAAAlsdMzf5577rn84Ac/yGuvvZaOHTtmyZIlOffcc3PRRRflU5/6VLp06ZLvf//7qa6uzqWXXprJkyenqqoqU6dOTU1NTVtkAAAAAOAT7LT8Oeqoo7Jw4cIdto8ZM2aHbXV1damrqyvNZAAAAADssRZd9gUAAABA+6D8AQAAACgw5Q8AAABAgbXord4BgPavV6++aWhY3aZr9uzZJ+vWvdKmawIAVDrlDwBUqG3FT1Mbr1nVpusBAOCyLwAAAIBCU/4AAAAAFJjyBwAAAKDAlD8AAAAABab8AQAAACgw5Q8AAABAgSl/AAAAAApM+QMAAABQYMofAAAAgAJT/gAAAAAUmPIHAAAAoMCUPwAAAAAFpvwBAAAAKDDlDwAAAECBKX8AAAAACkz5AwAAAFBgyh8AAACAAlP+AAAAABSY8gcAAACgwJQ/AAAAAAWm/AEAAAAoMOUPAAAAQIEpfwAAAAAKTPkDAAAAUGDKHwAAAIACU/4AAAAAFJjyBwAAAKDAlD8AAAAABab8AQAAACgw5Q8AAABAgSl/AAAAAApM+QMAAABQYMofAAAAgAJT/gAAAAAUmPIHAAAAoMCUPwAAAAAFpvwBAAAAKDDlDwAAAECBKX8AAAAACkz5AwAAAFBgyh8AAACAAlP+AAAAABTYLpU/L774Yo4//vjcc889SZK1a9dm4sSJmTBhQi688ML8+c9/TpIsXrw4p59+es4888zce++9rTc1AAAAALtkp+XP5s2bM3v27AwbNqx520033ZQJEybkZz/7Wfr06ZP6+vps3rw5c+fOzZ133pmFCxfmrrvuyltvvdWqwwMAAADw1+20/OncuXMWLFiQ2tra5m3Lli3L6NGjkyQjR47ME088kWeffTb9+/dPTU1NqqurM2TIkKxYsaL1JgcAAABgpzru9AkdO6Zjx+2ftmXLlnTu3DlJ0r179zQ2Nmb9+vXp1q1b83O6deuWxsbGEo8LAAAAwO7YafmzM01NTbu1PUnWrFmzp8vulk2bNrX5muVSSVn3VHvaT5VyXCslZyJrUVVS1j3RnvaRY7pr2ts+qpTjWik5S6E97adKOa6VkjORtaj2tqwtKn+6dOmS9957L9XV1WloaEhtbW1qa2uzfv365ue8/vrrGTRo0Md+fO/evVs2bQutWbOmzdcsl0rKuqfa036qlONaKTkTWYuqkrLuifa0jxzTXdPe9lGlHNdKyVkK7Wk/VcpxrZSciaxFVY6sa9eu/cTHWvRW71/+8pezZMmSJMnSpUszfPjwDBw4MCtXrszGjRvz7rvvZsWKFTn66KNbNjEAAAAAJbHTM3+ee+65/OAHP8hrr72Wjh07ZsmSJbnhhhsyY8aMLFq0KL179864cePSqVOnXHrppZk8eXKqqqoyderU1NTUtEUGAAAAAD7BTsufo446KgsXLtxh+x133LHDtrq6utTV1ZVmMgAA+AS9evVNQ8PqNl2zZ88+WbfulTZdEwBKYY9v+AwAAG1tW/HzyW8w0jprVrXpegBQKi265w8AAAAA7YPyBwAAAKDAlD8AAAAABab8AQAAACgw5Q8AAABAgSl/AAAAAApM+QMAAABQYMofAAAAgAJT/gAAAAAUmPIHAAAAoMCUPwAAAAAFpvwBAAAAKDDlDwAAAECBKX8AAAAACkz5AwAAAFBgyh8AAACAAlP+AAAAABSY8gcAAACgwJQ/AAAAAAWm/AEAAAAoMOUPAAAAQIEpfwAAAAAKTPkDAAAAUGDKHwAAAIACU/4AAAAAFJjyBwAAAKDAOpZ7AAAA4JP16tU3DQ2r23TNnj37ZN26V9p0TQBaj/IHAAD2YtuKn6Y2XrOqTdeDIlDUsjdT/gAAAMAeUtSyN1P+AMBf8Fs7AACKRvkDAH/Bb+0AACga7/YFAAAAUGDKHwAAAIACU/4AAAAAFJjyBwAAAKDAlD8AAAAABebdvgCAQuvVq+//vYtb2+rZs0/WrXulzdcF2JuU43uw77+wI+UPAFBo237oaCrDulVtvibA3qYc34N9/4UduewLAAAAoMCc+QPATrlsBgAA2i/lDwA75bIZAABov5Q/AAAAAP9PkW5YrvwBAAAA+H+KdMNyN3wGAAAAKDDlDwAAAECBteiyr2XLluXCCy/MoYcemiQ57LDD8vd///eZPn16Pvjgg/To0SPXX399OnfuXNJhAQAAANg9Lb7nzzHHHJObbrqp+c9XXHFFJkyYkLFjx+aHP/xh6uvrM2HChJIMCQAAAEDLlOyyr2XLlmX06NFJkpEjR+aJJ54o1acGAAAAoIVafObPH/7wh5x//vl5++23M23atGzZsqX5Mq/u3bunsbGxZEMCAAAA0DItKn/69u2badOmZezYsXn11VczadKkfPDBB82PNzW17VuhAQAAAPDxWlT+9OzZMyeddFKS5JBDDsmBBx6YlStX5r333kt1dXUaGhpSW1v7iR+/Zs2alk3bQps2bWrzNculkrLuqfa0nyrluFZKzqSysu6pStlPlZIzkbWIKiVnImtRtaesXkPsmkraR+0pq6/fXdMa+6hF5c/ixYvT2NiYyZMnp7GxMW+88UZOO+20LFmyJKecckqWLl2a4cOHf+LH9+7du8UDt8SaNWvafM1yqaSse6o97adKOa6VkjOprKx7qlL2U6XkTGQtokrJmchaVO0pq9cQu6aS9lF7yurrd9e0dB+tXbv2Ex9rUfkzatSofOtb38rDDz+c999/P7NmzcoRRxyRyy+/PIsWLUrv3r0zbty4Fg0LAAAAQOm0qPz59Kc/nXnz5u2w/Y477tjjgUh69eqbhobVbb5uz559sm7dK22+LgAAANB6WvxuX7SebcVP2980u6Ghqs3XBAAAAFrXPuUeAAAAAIDWo/wBAAAAKDDlDwAAAECBKX8AAAAACkz5AwAAAFBgyh8AAACAAlP+AAAAABSY8gcAAACgwJQ/AAAAAAWm/AEAAAAoMOUPAAAAQIEpfwAAAAAKTPkDAAAAUGAdyz0AAABAJenVq28aGla36Zo9e/bJunWvtOmawN5D+QMAANCGthU/TW28ZlWbrgfsXVz2BQAAAFBgzvwBaKFynLKdOG0bAADYPcofgBYqxynb29Z12jYAAOXhF6Dtk/IHAAAA2CV+Ado+KX+gjXhXBwAAAMpB+QNtxLs6AAAAUA7e7QsAAACgwJQ/AAAAAAWm/AEAAAAoMOUPAAAAQIEpfwAAAAAKTPkDAAAAUGDKHwAAAIAC61juAXZHr15909Cwuk3X7NmzT9ate6VN1wQAAAAolXZV/mwrfpraeM2qNl0PAAAAoJRc9gUAAABQYMofAAAAgAJT/gAAAAAUWLu65w/QPrg5OwAAwN5D+QOUnJuzAwAA7D1c9gUAAABQYMofAAAAgAJT/gAAAAAUmPIHAAAAoMCUPwAAAAAFpvwBAAAAKDDlDwAAAECBKX8AAAAACkz5AwAAAFBgyh8AAACAAlP+AAAAABRYx1J/wmuvvTbPPvtsqqqqMnPmzAwYMKDUSwAAAACwi0pa/jz11FNZvXp1Fi1alD/+8Y+ZOXNmFi1aVMolAAAAANgNJb3s64knnsjxxx+fJPn85z+ft99+O++8804plwAAAABgN5S0/Fm/fn0+85nPNP+5W7duaWxsLOUSAAAAAOyGVr3hc1NTU2t+egAAAAB2oqqphA3NzTffnB49euTss89OkowePTq/+MUv8ulPf7r5OcuXLy/VcgAAAAD8ny9+8Ysfu72kN3w+7rjjcvPNN+fss8/O888/n9ra2u2Kn782CAAAAAClV9LyZ8iQITnyyCNz9tlnp6qqKldffXUpPz0AAAAAu6mkl30BAAAAsHdp1Rs+AwAAAFBeFVX+bNy4sdwjtIqPO3lr3bp1ZZik7bz55pvlHqHNPPHEE+UeoU1s3bo1r732WrZu3VruUdpEJX0NV4qin0jb1NSUN998M2+88Ua5RwEAYDdVVPkzbdq0co9QUv/1X/+VkSNHZtiwYbn88svzzjvvND82ffr0Mk5WWo888kjGjBmT8847Ly+++GK+/vWvZ+LEiRk1alQeffTRco9XUvfff/92/9133325+uqrm/9cJNdcc03z///2t7/NCSeckIsuuignnnhiHnvssTJOVnqPPvporrrqqiTbyryRI0dm0qRJGTVqVB555JHyDldCQ4YMyezZsyuiHHj88cczduzYfOMb38jvfve7nH766RkxYkTq6ury1FNPlXu8klq1alXOP//8fP3rX8/o0aMzZcqU5r+vDQ0N5R6vpN5///38/Oc/zwUXXJBzzjkn55xzTi688MLU19fngw8+KPd4beaGG24o9wgl88Ybb+T666/PlVdemSeffHK7x7773e+WaarWsWHDhsyfPz+/+MUvkiS33nprpkyZkuuuu64ifuEwceLEco9Qcn/5Ovett97K7NmzM3HixMyePbtwx3TTpk359a9/nWTbL+znzJlT2K/fq666KitXriz3GG1i06ZNWbBgQerr6/Phhx9m4cKFmTFjRn7yk59s97Nre/fhhx/mP//zP3PFFVfkH//xH/MP//APmTVr1l73s2pJb/i8N/jXf/3XT3ysaC9S58+fn/vuuy/7779/7r333kyePDm33XZbampqCvUb6J/85Ce54447smbNmpx//vn58Y9/nH79+mX9+vU5//zz89WvfrXcI5bM3Llz07Vr1+0y/elPf8r//M//lHGq1vHCCy80///cuXNz99135+CDD05jY2OmTZuW4cOHl3G60rrpppty6623Jtk+64YNGzJlypR87WtfK++AJXLkkUemrq4ul156aT772c/mtNNOy+DBg9OxY+H+qcncuXNz11135e23387EiRNz5513pl+/fnnttddy2WWX5Wc/+1m5RyyZq6++Ot/73vdy8MEH5+WXX87ChQtz9dVX5ze/+U2+9a1vZeHCheUesWSmT5+eQw45JH/3d3+X7t27p6mpKQ0NDVmyZEmuuOKKzJkzp9wjlsyWLVs+8bFnnnmmDSdpXZdddllGjx6do446KnPnzs3y5cszderUJMkf/vCHMk9XWtOnT8/AgQOzfPnyLF26NJ/73OcyderU/O53v8v06dNz2223lXvEkunXr19qa2vTqVOn5te8jY2NGTVqVKqqqvLwww+XecLS+OlPf9r8mnD27Nk5/PDDM2HChCxbtiwzZ87MvHnzyjxh6VxwwQU56aSTkiTf+c538oUvfCHTpk3L888/n8svvzwLFiwo84Sl88wzz2Tr1q1ZsGBBzj333BxzzDHlHqnVXHbZZRk8eHBefvnlTJgwIUOGDMnf/u3fZuXKlZk5c2Zuuummco9YErNmzcpnP/vZnHPOOXn88cfT1NSUgQMH5t///d/z5JNP5vLLLy/3iEkKWP7ceeedGTZsWGpra3d4rGiXk3To0CFdu3ZNkowfPz7du3fP5MmTM2/evFRVVZV5utLp3Llzevfund69e6e2tjb9+vVLkhx44IHZd999yzxdaf3yl7/Mj3/847zwwguZMWNGDjrooDz22GOFO2styXZfowcccEAOPvjgJEmPHj0KVxZs3bo1++23X5KkpqYmf/M3f5Mk6dq1a6GK2qqqqgwdOjR33nlnVq5cmXvvvTff/va3s99++6V79+6ZP39+uUcsmU6dOqW2tja1tbXZf//9m78vHXTQQenQoUOZpyutP//5z81/P/v27dtc3I4YMSI333xzOUcrucbGxvzoRz/abtshhxySoUOH5txzzy3TVK1j6NChO7xWqqqqSlNTU6HO3nv//ffzjW98I0kyZsyYXHbZZbnlllsybdq0Qn3/Tbb9suijXHV1dZk7d26SZMCAAVmyZEmZpyutBQsWZP78+Tn33HMzZsyYJNteCy9atKjMk7We9evX55//+Z+TJJ///Ofz4IMPlnmi0nrnnXdy5plnJklef/315qz9+/fP4sWLyzlayR1wwAG59tprs2rVqtx999353ve+lwEDBqRfv37p1q1bxo4dW+4RS2bz5s2ZMmVKkmTs2LHNV6d85StfyaRJk8o5WkmtWrWq+WzSAQMG5LzzzsvUqVPzla98pfnrem9QrJ+wsu23sddcc02uvPLKdO7cebvHli1bVqapWseQIUMyZcqU3Hjjjamurs7xxx+ffffdN+edd17eeuutco9XMt27d89Pf/rTTJ48OT//+c+TbLun0e23355evXqVebrS2nfffXPxxRfn5Zdfzne/+90MHjw4H374YbnHahUvvfRSLrzwwjQ1NWX16tV58MEHM3bs2Nx+++2pqakp93glNXny5IwbNy7HHXdcunbtmn/6p3/K4MGDs2zZsr3qH4Q99Zc/SPXv3z/9+/dPsu1FXGNjY7nGahUHHHBAfvSjH2XDhg055JBDctVVV2X48OF55pln0r1793KPV1KHHXZYLrnkkgwYMCCPPfZYjj322CTJzJkz84UvfKHM05VWVVVVli5dmpEjR6ZTp05JtpVfS5Ys2eE1RXs3ffr0vPHGG7n44ot3eKxIl8907NgxS5YsyYknnph99tkn119/fa644op8+9vfzrvvvlvu8Urqo3vnHXTQQbnyyiubt//+97/P+++/X8bJSm/48OE59thjM2/evCxevDgzZswo1C8+P7Jhw4bmy0Y6d+6c3//+9+nXr19effXVv3r2Xnt0yCGH5Nprr83JJ5+cY489Ng8++GCGDh2a3/zmN+nRo0e5xyupj75WP/e5z+Xqq6/O+++/n6effjorV67MqlWrClX+bN26NatXr86bb76Zt99+O88880wGDRqUP/7xj4X6vtTU1JTHH388/fv3zyOPPJLq6uok2esu+yrkW71v2bIl++67b/bZZ/tbGj3//PM58sgjyzRV61i2bFmOOeaY7f7Be+edd/LAAw/krLPOKuNkpfPee+/lV7/6VfOpoMm2Y/n000/nnHPOKdzZP3/p/vvvz6OPPrrDb6KL4P/fF6VPnz7p2bNn/uM//iOjRo1qPlOmKN5666389re/zWuvvZampqYceOCBOe6449KzZ89yj1Yy9fX1OeOMM8o9RpvYvHlz7rvvvnzmM5/JSSedlMWLF2fFihXp06dPxo8fny5dupR7xJJpamrKww8/nFdeeSWHHXZYRowYkWTbD5SHH354oX7gWrduXW688cY89dRTzT9Y7bfffhk2bFimTZv2sWcVt2f3339/TjzxxB2+Xj+6V0wRrF27NjfeeGNmzZrV/GI8SRYvXpz58+fnl7/8ZRmnK63//u//zl133ZV/+Zd/ad720EMP5eabb8411+WlhvQAAAG2SURBVFzTXMgXzapVq3Lddddl1apVWbp0aTZu3Jj999+/3GOVxBVXXLHdn0855ZR86UtfygUXXJCTTz45J5xwQpkmK72tW7fm3/7t3/LrX/96u9dKI0aMyLhx4wpVAF144YW58cYbP/axIn39JsnTTz+d6667Lt26dcuMGTNyzTXX5IUXXkiPHj3yne98J4MGDSr3iCXx8ssv54Ybbsjq1atz+OGHZ/r06enVq1duvvnmfPWrX82AAQPKPWKSgpY/AAClNGnSpNx9993lHqNNVErWSsmZVEbWhoaG9OzZsyKyJpVxTD8iazFVSta9KWfhLvsCAGiJSnrTiErJWik5E1k/UqSslZIzkfUjsrZP7SWn8gcAIJX1phGVkrVSciayfqRIWSslZyLrR2Rtn9pNziYAAJpeeOGFpokTJzb96U9/2uGxc889twwTtZ5KyVopOZuaZP1IkbJWSs6mJlk/Imv71F5yuucPAMD/qaQ3jaiUrJWSM5E1KV7WSsmZyJrI2p61h5zKHwAAAIAC22fnTwEAAACgvVL+AAAAABSY8gcAAACgwJQ/AAAAAAWm/AEAAAAosP8FmGFnoEIIvyEAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stores[stores[\"store_nbr\"].isin([3,9,11,14])]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "cavcMuwdKIY-",
        "outputId": "5df5fd0e-904b-47fd-f41c-92911321266b"
      },
      "execution_count": 166,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    store_nbr      city       state type  cluster  city_en  state_en  type_en\n",
              "2           3     quito   Pichincha    D        8       18        12        3\n",
              "8           9     quito   Pichincha    B        6       18        12        1\n",
              "10         11   cayambe   Pichincha    B        6        2        12        1\n",
              "13         14  riobamba  Chimborazo    C        7       19         2        2"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6fb99ddd-b867-4299-85a0-bf1560229c75\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>store_nbr</th>\n",
              "      <th>city</th>\n",
              "      <th>state</th>\n",
              "      <th>type</th>\n",
              "      <th>cluster</th>\n",
              "      <th>city_en</th>\n",
              "      <th>state_en</th>\n",
              "      <th>type_en</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>quito</td>\n",
              "      <td>Pichincha</td>\n",
              "      <td>D</td>\n",
              "      <td>8</td>\n",
              "      <td>18</td>\n",
              "      <td>12</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>9</td>\n",
              "      <td>quito</td>\n",
              "      <td>Pichincha</td>\n",
              "      <td>B</td>\n",
              "      <td>6</td>\n",
              "      <td>18</td>\n",
              "      <td>12</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>11</td>\n",
              "      <td>cayambe</td>\n",
              "      <td>Pichincha</td>\n",
              "      <td>B</td>\n",
              "      <td>6</td>\n",
              "      <td>2</td>\n",
              "      <td>12</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>14</td>\n",
              "      <td>riobamba</td>\n",
              "      <td>Chimborazo</td>\n",
              "      <td>C</td>\n",
              "      <td>7</td>\n",
              "      <td>19</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6fb99ddd-b867-4299-85a0-bf1560229c75')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6fb99ddd-b867-4299-85a0-bf1560229c75 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6fb99ddd-b867-4299-85a0-bf1560229c75');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 166
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stores[stores[\"type\"].isin([\"D\",\"B\"])]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 865
        },
        "id": "0ub1YM4yLzz_",
        "outputId": "17b3698b-8454-4a75-9fc8-1050f07f92fc"
      },
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    store_nbr           city                           state type  cluster  \\\n",
              "0           1          quito                       Pichincha    D       13   \n",
              "1           2          quito                       Pichincha    D       13   \n",
              "2           3          quito                       Pichincha    D        8   \n",
              "3           4          quito                       Pichincha    D        9   \n",
              "4           5  santo domingo  Santo Domingo de los Tsachilas    D        4   \n",
              "5           6          quito                       Pichincha    D       13   \n",
              "6           7          quito                       Pichincha    D        8   \n",
              "7           8          quito                       Pichincha    D        8   \n",
              "8           9          quito                       Pichincha    B        6   \n",
              "10         11        cayambe                       Pichincha    B        6   \n",
              "17         18          quito                       Pichincha    B       16   \n",
              "19         20          quito                       Pichincha    B        6   \n",
              "20         21  santo domingo  Santo Domingo de los Tsachilas    B        6   \n",
              "22         23         ambato                      Tungurahua    D        9   \n",
              "23         24      guayaquil                          Guayas    D        1   \n",
              "24         25        salinas                     Santa Elena    D        1   \n",
              "25         26      guayaquil                          Guayas    D       10   \n",
              "26         27          daule                          Guayas    D        1   \n",
              "30         31       babahoyo                        Los Rios    B       10   \n",
              "33         34      guayaquil                          Guayas    B        6   \n",
              "36         37         cuenca                           Azuay    D        2   \n",
              "37         38           loja                            Loja    D        4   \n",
              "38         39         cuenca                           Azuay    B        6   \n",
              "40         41        machala                          El Oro    D        4   \n",
              "41         42         cuenca                           Azuay    D        2   \n",
              "52         53          manta                          Manabi    D       13   \n",
              "\n",
              "    city_en  state_en  type_en  \n",
              "0        18        12        3  \n",
              "1        18        12        3  \n",
              "2        18        12        3  \n",
              "3        18        12        3  \n",
              "4        21        14        3  \n",
              "5        18        12        3  \n",
              "6        18        12        3  \n",
              "7        18        12        3  \n",
              "8        18        12        1  \n",
              "10        2        12        1  \n",
              "17       18        12        1  \n",
              "19       18        12        1  \n",
              "20       21        14        1  \n",
              "22        0        15        3  \n",
              "23        8         6        3  \n",
              "24       20        13        3  \n",
              "25        8         6        3  \n",
              "26        4         6        3  \n",
              "30        1         9        1  \n",
              "33        8         6        1  \n",
              "36        3         0        3  \n",
              "37       12         8        3  \n",
              "38        3         0        1  \n",
              "40       13         4        3  \n",
              "41        3         0        3  \n",
              "52       14        10        3  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-89af8ce9-88e5-40fe-a616-a4064e0e638f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>store_nbr</th>\n",
              "      <th>city</th>\n",
              "      <th>state</th>\n",
              "      <th>type</th>\n",
              "      <th>cluster</th>\n",
              "      <th>city_en</th>\n",
              "      <th>state_en</th>\n",
              "      <th>type_en</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>quito</td>\n",
              "      <td>Pichincha</td>\n",
              "      <td>D</td>\n",
              "      <td>13</td>\n",
              "      <td>18</td>\n",
              "      <td>12</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>quito</td>\n",
              "      <td>Pichincha</td>\n",
              "      <td>D</td>\n",
              "      <td>13</td>\n",
              "      <td>18</td>\n",
              "      <td>12</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>quito</td>\n",
              "      <td>Pichincha</td>\n",
              "      <td>D</td>\n",
              "      <td>8</td>\n",
              "      <td>18</td>\n",
              "      <td>12</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>quito</td>\n",
              "      <td>Pichincha</td>\n",
              "      <td>D</td>\n",
              "      <td>9</td>\n",
              "      <td>18</td>\n",
              "      <td>12</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>santo domingo</td>\n",
              "      <td>Santo Domingo de los Tsachilas</td>\n",
              "      <td>D</td>\n",
              "      <td>4</td>\n",
              "      <td>21</td>\n",
              "      <td>14</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>6</td>\n",
              "      <td>quito</td>\n",
              "      <td>Pichincha</td>\n",
              "      <td>D</td>\n",
              "      <td>13</td>\n",
              "      <td>18</td>\n",
              "      <td>12</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>7</td>\n",
              "      <td>quito</td>\n",
              "      <td>Pichincha</td>\n",
              "      <td>D</td>\n",
              "      <td>8</td>\n",
              "      <td>18</td>\n",
              "      <td>12</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>8</td>\n",
              "      <td>quito</td>\n",
              "      <td>Pichincha</td>\n",
              "      <td>D</td>\n",
              "      <td>8</td>\n",
              "      <td>18</td>\n",
              "      <td>12</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>9</td>\n",
              "      <td>quito</td>\n",
              "      <td>Pichincha</td>\n",
              "      <td>B</td>\n",
              "      <td>6</td>\n",
              "      <td>18</td>\n",
              "      <td>12</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>11</td>\n",
              "      <td>cayambe</td>\n",
              "      <td>Pichincha</td>\n",
              "      <td>B</td>\n",
              "      <td>6</td>\n",
              "      <td>2</td>\n",
              "      <td>12</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>18</td>\n",
              "      <td>quito</td>\n",
              "      <td>Pichincha</td>\n",
              "      <td>B</td>\n",
              "      <td>16</td>\n",
              "      <td>18</td>\n",
              "      <td>12</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>20</td>\n",
              "      <td>quito</td>\n",
              "      <td>Pichincha</td>\n",
              "      <td>B</td>\n",
              "      <td>6</td>\n",
              "      <td>18</td>\n",
              "      <td>12</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>21</td>\n",
              "      <td>santo domingo</td>\n",
              "      <td>Santo Domingo de los Tsachilas</td>\n",
              "      <td>B</td>\n",
              "      <td>6</td>\n",
              "      <td>21</td>\n",
              "      <td>14</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>23</td>\n",
              "      <td>ambato</td>\n",
              "      <td>Tungurahua</td>\n",
              "      <td>D</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>15</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>24</td>\n",
              "      <td>guayaquil</td>\n",
              "      <td>Guayas</td>\n",
              "      <td>D</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>6</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>25</td>\n",
              "      <td>salinas</td>\n",
              "      <td>Santa Elena</td>\n",
              "      <td>D</td>\n",
              "      <td>1</td>\n",
              "      <td>20</td>\n",
              "      <td>13</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>26</td>\n",
              "      <td>guayaquil</td>\n",
              "      <td>Guayas</td>\n",
              "      <td>D</td>\n",
              "      <td>10</td>\n",
              "      <td>8</td>\n",
              "      <td>6</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>27</td>\n",
              "      <td>daule</td>\n",
              "      <td>Guayas</td>\n",
              "      <td>D</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>6</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>31</td>\n",
              "      <td>babahoyo</td>\n",
              "      <td>Los Rios</td>\n",
              "      <td>B</td>\n",
              "      <td>10</td>\n",
              "      <td>1</td>\n",
              "      <td>9</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>34</td>\n",
              "      <td>guayaquil</td>\n",
              "      <td>Guayas</td>\n",
              "      <td>B</td>\n",
              "      <td>6</td>\n",
              "      <td>8</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>37</td>\n",
              "      <td>cuenca</td>\n",
              "      <td>Azuay</td>\n",
              "      <td>D</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>38</td>\n",
              "      <td>loja</td>\n",
              "      <td>Loja</td>\n",
              "      <td>D</td>\n",
              "      <td>4</td>\n",
              "      <td>12</td>\n",
              "      <td>8</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>39</td>\n",
              "      <td>cuenca</td>\n",
              "      <td>Azuay</td>\n",
              "      <td>B</td>\n",
              "      <td>6</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>41</td>\n",
              "      <td>machala</td>\n",
              "      <td>El Oro</td>\n",
              "      <td>D</td>\n",
              "      <td>4</td>\n",
              "      <td>13</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>42</td>\n",
              "      <td>cuenca</td>\n",
              "      <td>Azuay</td>\n",
              "      <td>D</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52</th>\n",
              "      <td>53</td>\n",
              "      <td>manta</td>\n",
              "      <td>Manabi</td>\n",
              "      <td>D</td>\n",
              "      <td>13</td>\n",
              "      <td>14</td>\n",
              "      <td>10</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-89af8ce9-88e5-40fe-a616-a4064e0e638f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-89af8ce9-88e5-40fe-a616-a4064e0e638f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-89af8ce9-88e5-40fe-a616-a4064e0e638f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 134
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stores[stores[\"cluster\"].isin([6,7,8])]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "id": "2_SrcmaoKkuf",
        "outputId": "d0075731-8a93-49ab-9e14-a439aea86c70"
      },
      "execution_count": 167,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    store_nbr           city                           state type  cluster  \\\n",
              "2           3          quito                       Pichincha    D        8   \n",
              "6           7          quito                       Pichincha    D        8   \n",
              "7           8          quito                       Pichincha    D        8   \n",
              "8           9          quito                       Pichincha    B        6   \n",
              "10         11        cayambe                       Pichincha    B        6   \n",
              "13         14       riobamba                      Chimborazo    C        7   \n",
              "19         20          quito                       Pichincha    B        6   \n",
              "20         21  santo domingo  Santo Domingo de los Tsachilas    B        6   \n",
              "21         22           puyo                         Pastaza    C        7   \n",
              "33         34      guayaquil                          Guayas    B        6   \n",
              "38         39         cuenca                           Azuay    B        6   \n",
              "\n",
              "    city_en  state_en  type_en  \n",
              "2        18        12        3  \n",
              "6        18        12        3  \n",
              "7        18        12        3  \n",
              "8        18        12        1  \n",
              "10        2        12        1  \n",
              "13       19         2        2  \n",
              "19       18        12        1  \n",
              "20       21        14        1  \n",
              "21       16        11        2  \n",
              "33        8         6        1  \n",
              "38        3         0        1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-084ba1ff-54be-44a7-a375-b7302f8ab41c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>store_nbr</th>\n",
              "      <th>city</th>\n",
              "      <th>state</th>\n",
              "      <th>type</th>\n",
              "      <th>cluster</th>\n",
              "      <th>city_en</th>\n",
              "      <th>state_en</th>\n",
              "      <th>type_en</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>quito</td>\n",
              "      <td>Pichincha</td>\n",
              "      <td>D</td>\n",
              "      <td>8</td>\n",
              "      <td>18</td>\n",
              "      <td>12</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>7</td>\n",
              "      <td>quito</td>\n",
              "      <td>Pichincha</td>\n",
              "      <td>D</td>\n",
              "      <td>8</td>\n",
              "      <td>18</td>\n",
              "      <td>12</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>8</td>\n",
              "      <td>quito</td>\n",
              "      <td>Pichincha</td>\n",
              "      <td>D</td>\n",
              "      <td>8</td>\n",
              "      <td>18</td>\n",
              "      <td>12</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>9</td>\n",
              "      <td>quito</td>\n",
              "      <td>Pichincha</td>\n",
              "      <td>B</td>\n",
              "      <td>6</td>\n",
              "      <td>18</td>\n",
              "      <td>12</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>11</td>\n",
              "      <td>cayambe</td>\n",
              "      <td>Pichincha</td>\n",
              "      <td>B</td>\n",
              "      <td>6</td>\n",
              "      <td>2</td>\n",
              "      <td>12</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>14</td>\n",
              "      <td>riobamba</td>\n",
              "      <td>Chimborazo</td>\n",
              "      <td>C</td>\n",
              "      <td>7</td>\n",
              "      <td>19</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>20</td>\n",
              "      <td>quito</td>\n",
              "      <td>Pichincha</td>\n",
              "      <td>B</td>\n",
              "      <td>6</td>\n",
              "      <td>18</td>\n",
              "      <td>12</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>21</td>\n",
              "      <td>santo domingo</td>\n",
              "      <td>Santo Domingo de los Tsachilas</td>\n",
              "      <td>B</td>\n",
              "      <td>6</td>\n",
              "      <td>21</td>\n",
              "      <td>14</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>22</td>\n",
              "      <td>puyo</td>\n",
              "      <td>Pastaza</td>\n",
              "      <td>C</td>\n",
              "      <td>7</td>\n",
              "      <td>16</td>\n",
              "      <td>11</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>34</td>\n",
              "      <td>guayaquil</td>\n",
              "      <td>Guayas</td>\n",
              "      <td>B</td>\n",
              "      <td>6</td>\n",
              "      <td>8</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>39</td>\n",
              "      <td>cuenca</td>\n",
              "      <td>Azuay</td>\n",
              "      <td>B</td>\n",
              "      <td>6</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-084ba1ff-54be-44a7-a375-b7302f8ab41c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-084ba1ff-54be-44a7-a375-b7302f8ab41c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-084ba1ff-54be-44a7-a375-b7302f8ab41c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 167
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_df_base[model_df_base[\"store_nbr\"]==7][[\"date\",\"actual\",\"pred_m2\"]].groupby(\"date\").sum().plot()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 328
        },
        "outputId": "2ca86bcd-5269-4799-cde9-f707cacb3d33",
        "id": "WF6elJ3vIPfg"
      },
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f977a1e1450>"
            ]
          },
          "metadata": {},
          "execution_count": 137
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 136,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 328
        },
        "outputId": "45505e08-039a-42a6-aad0-86a9d511feb1",
        "id": "m89zOnIFIPfg"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f9773cf9bd0>"
            ]
          },
          "metadata": {},
          "execution_count": 136
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "model_df_base[model_df_base[\"store_nbr\"]==3][[\"date\",\"actual\",\"pred_m2\"]].groupby(\"date\").sum().plot()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_df_base.family.unique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NFQya5w6Mi8g",
        "outputId": "899e67b0-4ea6-476d-b11f-3e35c5c9a9d0"
      },
      "execution_count": 180,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['GROCERY I', 'BREAD/BAKERY', 'DELI', 'CLEANING', 'POULTRY',\n",
              "       'PERSONAL CARE', 'LINGERIE', 'BEVERAGES', 'AUTOMOTIVE', 'DAIRY',\n",
              "       'EGGS', 'GROCERY II', 'MEATS', 'FROZEN FOODS', 'HOME APPLIANCES',\n",
              "       'SEAFOOD', 'PREPARED FOODS', 'LIQUOR,WINE,BEER', 'BEAUTY',\n",
              "       'HARDWARE', 'LAWN AND GARDEN', 'PRODUCE', 'HOME AND KITCHEN II',\n",
              "       'HOME AND KITCHEN I', 'MAGAZINES', 'HOME CARE', 'PET SUPPLIES',\n",
              "       'PLAYERS AND ELECTRONICS', 'CELEBRATION',\n",
              "       'SCHOOL AND OFFICE SUPPLIES', 'LADIESWEAR', 'BOOKS', 'BABY CARE'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 180
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "store_mse = {}\n",
        "for i in model_df_base.family.unique():\n",
        "  store_mse[i] = get_error(model_df_base[model_df_base[\"family\"]==i][\"perishable\"].values * 0.25 + 1, model_df_base[model_df_base[\"family\"]==i]['actual'].values, model_df_base[model_df_base[\"family\"]==i][\"pred_final\"].values)\n",
        "df_store_mse =pd.DataFrame(store_mse)\n",
        "plt.figure(figsize=(20, 5))\n",
        "df_store_mse.iloc[0,:].plot.bar()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        },
        "id": "aDpeWkVbMw1H",
        "outputId": "6aaa9928-51a4-40d9-971d-e94e00001e59"
      },
      "execution_count": 176,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f9776b59c10>"
            ]
          },
          "metadata": {},
          "execution_count": 176
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1440x360 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "store_mse = {}\n",
        "for i in model_df_base.perishable.unique():\n",
        "  store_mse[i] = get_error(model_df_base[model_df_base[\"perishable\"]==i][\"perishable\"].values * 0.25 + 1, model_df_base[model_df_base[\"perishable\"]==i]['actual'].values, model_df_base[model_df_base[\"perishable\"]==i][\"pred_final\"].values)\n",
        "df_store_mse =pd.DataFrame(store_mse)\n",
        "plt.figure(figsize=(5, 3))\n",
        "df_store_mse.iloc[0,:].plot.bar()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 230
        },
        "id": "4R2LIAVZTmYE",
        "outputId": "c520771f-ebc2-4b8e-a6f2-beaaa6f72cff"
      },
      "execution_count": 178,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f9778107350>"
            ]
          },
          "metadata": {},
          "execution_count": 178
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 360x216 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "CVx2nAWMfWwp",
        "bhvd0iAkHsrM",
        "C_BojhGE00PK",
        "vigPhjErBWkP",
        "GkMIWVvSPw2z",
        "3Y8KFHMfm_a9",
        "WRFoUJgrpzfA",
        "b2fcZb50vYu3",
        "z3-_tIXWzkqJ",
        "Dob5L01NAm-6"
      ],
      "machine_shape": "hm",
      "name": "favorita-predictions.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}